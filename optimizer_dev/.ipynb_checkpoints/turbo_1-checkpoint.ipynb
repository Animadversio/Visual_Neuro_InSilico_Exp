{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BO with TuRBO-1 and TS/qEI\n",
    "\n",
    "In this tutorial, we show how to implement Trust Region Bayesian Optimization (TuRBO) [1] in a closed loop in BoTorch.\n",
    "\n",
    "This implementation uses one trust region (TuRBO-1) and supports either parallel expected improvement (qEI) or Thompson sampling (TS). We optimize the $20D$ Ackley function on the domain $[-5, 10]^{20}$ and show that TuRBO-1 outperforms qEI as well as Sobol.\n",
    "\n",
    "Since botorch assumes a maximization problem, we will attempt to maximize $-f(x)$ to achieve $\\max_x -f(x)=0$.\n",
    "\n",
    "[1]: [Eriksson, David, et al. Scalable global optimization via local Bayesian optimization. Advances in Neural Information Processing Systems. 2019](https://proceedings.neurips.cc/paper/2019/file/6c990b7aca7bc7058f5e98ea909e924b-Paper.pdf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import torch\n",
    "from botorch.acquisition import qExpectedImprovement\n",
    "from botorch.fit import fit_gpytorch_model\n",
    "from botorch.generation import MaxPosteriorSampling\n",
    "from botorch.models import SingleTaskGP\n",
    "from botorch.optim import optimize_acqf\n",
    "from botorch.test_functions import Ackley\n",
    "from botorch.utils.transforms import unnormalize\n",
    "from torch.quasirandom import SobolEngine\n",
    "\n",
    "import gpytorch\n",
    "from gpytorch.constraints import Interval\n",
    "from gpytorch.kernels import MaternKernel, ScaleKernel\n",
    "from gpytorch.likelihoods import GaussianLikelihood\n",
    "from gpytorch.mlls import ExactMarginalLogLikelihood\n",
    "from gpytorch.priors import HorseshoePrior\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "dtype = torch.double\n",
    "SMOKE_TEST = os.environ.get(\"SMOKE_TEST\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimize the 20-dimensional Ackley function\n",
    "\n",
    "The goal is to minimize the popular Ackley function:\n",
    "\n",
    "$f(x_1,\\ldots,x_d) = -20\\exp\\left(-0.2 \\sqrt{\\frac{1}{d} \\sum_{j=1}^d x_j^2} \\right) -\\exp \\left( \\frac{1}{d} \\sum_{j=1}^d \\cos(2 \\pi x_j) \\right) + 20 + e$\n",
    "\n",
    "over the domain  $[-5, 10]^{20}$.  The global optimal value of $0$ is attained at $x_1 = \\ldots = x_d = 0$.\n",
    "\n",
    "As mentioned above, since botorch assumes a maximization problem, we instead maximize $-f(x)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fun = Ackley(dim=20, negate=True).to(dtype=dtype, device=device)\n",
    "fun.bounds[0, :].fill_(-5)\n",
    "fun.bounds[1, :].fill_(10)\n",
    "dim = fun.dim\n",
    "lb, ub = fun.bounds\n",
    "\n",
    "batch_size = 4\n",
    "n_init = 2 * dim\n",
    "max_cholesky_size = float(\"inf\")  # Always use Cholesky\n",
    "\n",
    "\n",
    "def eval_objective(x):\n",
    "    \"\"\"This is a helper function we use to unnormalize and evalaute a point\"\"\"\n",
    "    return fun(unnormalize(x, fun.bounds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maintain the TuRBO state\n",
    "TuRBO needs to maintain a state, which includes the length of the trust region, success and failure counters, success and failure tolerance, etc. \n",
    "\n",
    "In this tutorial we store the state in a dataclass and update the state of TuRBO after each batch evaluation. \n",
    "\n",
    "**Note**: These settings assume that the domain has been scaled to $[0, 1]^d$ and that the same batch size is used for each iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class TurboState:\n",
    "    dim: int\n",
    "    batch_size: int\n",
    "    length: float = 0.8\n",
    "    length_min: float = 0.5 ** 7\n",
    "    length_max: float = 1.6\n",
    "    failure_counter: int = 0\n",
    "    failure_tolerance: int = float(\"nan\")  # Note: Post-initialized\n",
    "    success_counter: int = 0\n",
    "    success_tolerance: int = 10  # Note: The original paper uses 3\n",
    "    best_value: float = -float(\"inf\")\n",
    "    restart_triggered: bool = False\n",
    "\n",
    "    def __post_init__(self):\n",
    "        self.failure_tolerance = math.ceil(\n",
    "            max([4.0 / self.batch_size, float(self.dim) / self.batch_size])\n",
    "        )\n",
    "\n",
    "\n",
    "def update_state(state, Y_next):\n",
    "    if max(Y_next) > state.best_value + 1e-3 * math.fabs(state.best_value):\n",
    "        state.success_counter += 1\n",
    "        state.failure_counter = 0\n",
    "    else:\n",
    "        state.success_counter = 0\n",
    "        state.failure_counter += 1\n",
    "\n",
    "    if state.success_counter == state.success_tolerance:  # Expand trust region\n",
    "        state.length = min(2.0 * state.length, state.length_max)\n",
    "        state.success_counter = 0\n",
    "    elif state.failure_counter == state.failure_tolerance:  # Shrink trust region\n",
    "        state.length /= 2.0\n",
    "        state.failure_counter = 0\n",
    "\n",
    "    state.best_value = max(state.best_value, max(Y_next).item())\n",
    "    if state.length < state.length_min:\n",
    "        state.restart_triggered = True\n",
    "    return state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Take a look at the state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TurboState(dim=20, batch_size=4, length=0.8, length_min=0.0078125, length_max=1.6, failure_counter=0, failure_tolerance=5, success_counter=0, success_tolerance=10, best_value=-inf, restart_triggered=False)\n"
     ]
    }
   ],
   "source": [
    "state = TurboState(dim=dim, batch_size=batch_size)\n",
    "print(state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate initial points\n",
    "This generates an initial set of Sobol points that we use to start of the BO loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_initial_points(dim, n_pts, seed=0):\n",
    "    sobol = SobolEngine(dimension=dim, scramble=True, seed=seed)\n",
    "    X_init = sobol.draw(n=n_pts).to(dtype=dtype, device=device)\n",
    "    return X_init"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate new batch\n",
    "Given the current `state` and a probabilistic (GP) `model` built from observations `X` and `Y`, we generate a new batch of points.  \n",
    "\n",
    "This method works on the domain $[0, 1]^d$, so make sure to not pass in observations from the true domain.  `unnormalize` is called before the true function is evaluated which will first map the points back to the original domain.\n",
    "\n",
    "We support either TS and qEI which can be specified via the `acqf` argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batch(\n",
    "    state,\n",
    "    model,  # GP model\n",
    "    X,  # Evaluated points on the domain [0, 1]^d\n",
    "    Y,  # Function values\n",
    "    batch_size,\n",
    "    n_candidates=None,  # Number of candidates for Thompson sampling\n",
    "    num_restarts=10,\n",
    "    raw_samples=512,\n",
    "    acqf=\"ts\",  # \"ei\" or \"ts\"\n",
    "):\n",
    "    assert acqf in (\"ts\", \"ei\")\n",
    "    assert X.min() >= 0.0 and X.max() <= 1.0 and torch.all(torch.isfinite(Y))\n",
    "    if n_candidates is None:\n",
    "        n_candidates = min(5000, max(2000, 200 * X.shape[-1]))\n",
    "\n",
    "    # Scale the TR to be proportional to the lengthscales\n",
    "    x_center = X[Y.argmax(), :].clone()\n",
    "    weights = model.covar_module.base_kernel.lengthscale.squeeze().detach()\n",
    "    weights = weights / weights.mean()\n",
    "    weights = weights / torch.prod(weights.pow(1.0 / len(weights)))\n",
    "    tr_lb = torch.clamp(x_center - weights * state.length / 2.0, 0.0, 1.0)\n",
    "    tr_ub = torch.clamp(x_center + weights * state.length / 2.0, 0.0, 1.0)\n",
    "\n",
    "    if acqf == \"ts\":\n",
    "        dim = X.shape[-1]\n",
    "        sobol = SobolEngine(dim, scramble=True)\n",
    "        pert = sobol.draw(n_candidates).to(dtype=dtype, device=device)\n",
    "        pert = tr_lb + (tr_ub - tr_lb) * pert\n",
    "\n",
    "        # Create a perturbation mask\n",
    "        prob_perturb = min(20.0 / dim, 1.0)\n",
    "        mask = (\n",
    "            torch.rand(n_candidates, dim, dtype=dtype, device=device)\n",
    "            <= prob_perturb\n",
    "        )\n",
    "        ind = torch.where(mask.sum(dim=1) == 0)[0]\n",
    "        mask[ind, torch.randint(0, dim - 1, size=(len(ind),), device=device)] = 1\n",
    "\n",
    "        # Create candidate points from the perturbations and the mask        \n",
    "        X_cand = x_center.expand(n_candidates, dim).clone()\n",
    "        X_cand[mask] = pert[mask]\n",
    "\n",
    "        # Sample on the candidate points\n",
    "        thompson_sampling = MaxPosteriorSampling(model=model, replacement=False)\n",
    "        with torch.no_grad():  # We don't need gradients when using TS\n",
    "            X_next = thompson_sampling(X_cand, num_samples=batch_size)\n",
    "\n",
    "    elif acqf == \"ei\":\n",
    "        ei = qExpectedImprovement(model, train_Y.max(), maximize=True)\n",
    "        X_next, acq_value = optimize_acqf(\n",
    "            ei,\n",
    "            bounds=torch.stack([tr_lb, tr_ub]),\n",
    "            q=batch_size,\n",
    "            num_restarts=num_restarts,\n",
    "            raw_samples=raw_samples,\n",
    "        )\n",
    "\n",
    "    return X_next"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization loop\n",
    "This simple loop runs one instance of TuRBO-1 with Thompson sampling until convergence.\n",
    "\n",
    "TuRBO-1 is a local optimizer that can be used for a fixed evaluation budget in a multi-start fashion.  Once TuRBO converges, `state[\"restart_triggered\"]` will be set to true and the run should be aborted.  If you want to run more evaluations with TuRBO, you simply generate a new set of initial points and then keep generating batches until convergence or when the evaluation budget has been exceeded.  It's important to note that evaluations from previous instances are discarded when TuRBO restarts.\n",
    "\n",
    "NOTE: We use a `SingleTaskGP` with a noise constraint to keep the noise from getting too large as the problem is noise-free. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44) Best value: -1.15e+01, TR length: 8.00e-01\n",
      "48) Best value: -1.06e+01, TR length: 8.00e-01\n",
      "52) Best value: -1.06e+01, TR length: 8.00e-01\n",
      "56) Best value: -1.06e+01, TR length: 8.00e-01\n",
      "60) Best value: -1.06e+01, TR length: 8.00e-01\n",
      "64) Best value: -1.06e+01, TR length: 8.00e-01\n",
      "68) Best value: -1.06e+01, TR length: 4.00e-01\n",
      "72) Best value: -9.79e+00, TR length: 4.00e-01\n",
      "76) Best value: -9.79e+00, TR length: 4.00e-01\n",
      "80) Best value: -8.76e+00, TR length: 4.00e-01\n",
      "84) Best value: -7.41e+00, TR length: 4.00e-01\n",
      "88) Best value: -7.41e+00, TR length: 4.00e-01\n",
      "92) Best value: -7.41e+00, TR length: 4.00e-01\n",
      "96) Best value: -7.23e+00, TR length: 4.00e-01\n",
      "100) Best value: -7.23e+00, TR length: 4.00e-01\n",
      "104) Best value: -6.47e+00, TR length: 4.00e-01\n",
      "108) Best value: -6.47e+00, TR length: 4.00e-01\n",
      "112) Best value: -6.47e+00, TR length: 4.00e-01\n",
      "116) Best value: -6.00e+00, TR length: 4.00e-01\n",
      "120) Best value: -6.00e+00, TR length: 4.00e-01\n",
      "124) Best value: -6.00e+00, TR length: 4.00e-01\n",
      "128) Best value: -6.00e+00, TR length: 4.00e-01\n",
      "132) Best value: -5.81e+00, TR length: 4.00e-01\n",
      "136) Best value: -5.74e+00, TR length: 4.00e-01\n",
      "140) Best value: -5.74e+00, TR length: 4.00e-01\n",
      "144) Best value: -5.74e+00, TR length: 4.00e-01\n",
      "148) Best value: -5.74e+00, TR length: 4.00e-01\n",
      "152) Best value: -5.74e+00, TR length: 4.00e-01\n",
      "156) Best value: -5.74e+00, TR length: 2.00e-01\n",
      "160) Best value: -4.90e+00, TR length: 2.00e-01\n",
      "164) Best value: -4.17e+00, TR length: 2.00e-01\n",
      "168) Best value: -3.75e+00, TR length: 2.00e-01\n",
      "172) Best value: -3.75e+00, TR length: 2.00e-01\n",
      "176) Best value: -3.75e+00, TR length: 2.00e-01\n",
      "180) Best value: -3.75e+00, TR length: 2.00e-01\n",
      "184) Best value: -3.75e+00, TR length: 2.00e-01\n",
      "188) Best value: -3.75e+00, TR length: 1.00e-01\n",
      "192) Best value: -3.64e+00, TR length: 1.00e-01\n",
      "196) Best value: -3.47e+00, TR length: 1.00e-01\n",
      "200) Best value: -2.81e+00, TR length: 1.00e-01\n",
      "204) Best value: -2.81e+00, TR length: 1.00e-01\n",
      "208) Best value: -2.81e+00, TR length: 1.00e-01\n",
      "212) Best value: -2.81e+00, TR length: 1.00e-01\n",
      "216) Best value: -2.81e+00, TR length: 1.00e-01\n",
      "220) Best value: -2.81e+00, TR length: 5.00e-02\n",
      "224) Best value: -2.68e+00, TR length: 5.00e-02\n",
      "228) Best value: -2.34e+00, TR length: 5.00e-02\n",
      "232) Best value: -2.34e+00, TR length: 5.00e-02\n",
      "236) Best value: -2.34e+00, TR length: 5.00e-02\n",
      "240) Best value: -2.34e+00, TR length: 5.00e-02\n",
      "244) Best value: -2.25e+00, TR length: 5.00e-02\n",
      "248) Best value: -2.25e+00, TR length: 5.00e-02\n",
      "252) Best value: -2.25e+00, TR length: 5.00e-02\n",
      "256) Best value: -1.98e+00, TR length: 5.00e-02\n",
      "260) Best value: -1.98e+00, TR length: 5.00e-02\n",
      "264) Best value: -1.98e+00, TR length: 5.00e-02\n",
      "268) Best value: -1.98e+00, TR length: 5.00e-02\n",
      "272) Best value: -1.98e+00, TR length: 5.00e-02\n",
      "276) Best value: -1.98e+00, TR length: 2.50e-02\n",
      "280) Best value: -1.98e+00, TR length: 2.50e-02\n",
      "284) Best value: -1.47e+00, TR length: 2.50e-02\n",
      "288) Best value: -1.32e+00, TR length: 2.50e-02\n",
      "292) Best value: -1.32e+00, TR length: 2.50e-02\n",
      "296) Best value: -1.32e+00, TR length: 2.50e-02\n",
      "300) Best value: -1.32e+00, TR length: 2.50e-02\n",
      "304) Best value: -1.32e+00, TR length: 2.50e-02\n",
      "308) Best value: -1.32e+00, TR length: 1.25e-02\n",
      "312) Best value: -1.11e+00, TR length: 1.25e-02\n",
      "316) Best value: -1.07e+00, TR length: 1.25e-02\n",
      "320) Best value: -1.07e+00, TR length: 1.25e-02\n",
      "324) Best value: -1.07e+00, TR length: 1.25e-02\n",
      "328) Best value: -1.07e+00, TR length: 1.25e-02\n",
      "332) Best value: -1.07e+00, TR length: 1.25e-02\n",
      "336) Best value: -1.07e+00, TR length: 6.25e-03\n"
     ]
    }
   ],
   "source": [
    "X_turbo = get_initial_points(dim, n_init)\n",
    "Y_turbo = torch.tensor(\n",
    "    [eval_objective(x) for x in X_turbo], dtype=dtype, device=device\n",
    ").unsqueeze(-1)\n",
    "\n",
    "state = TurboState(dim, batch_size=batch_size)\n",
    "\n",
    "NUM_RESTARTS = 10 if not SMOKE_TEST else 2\n",
    "RAW_SAMPLES = 512 if not SMOKE_TEST else 4\n",
    "N_CANDIDATES = min(5000, max(2000, 200 * dim)) if not SMOKE_TEST else 4\n",
    "\n",
    "\n",
    "while not state.restart_triggered:  # Run until TuRBO converges\n",
    "    # Fit a GP model\n",
    "    train_Y = (Y_turbo - Y_turbo.mean()) / Y_turbo.std()\n",
    "    likelihood = GaussianLikelihood(noise_constraint=Interval(1e-8, 1e-3))\n",
    "    covar_module = ScaleKernel(  # Use the same lengthscale prior as in the TuRBO paper\n",
    "        MaternKernel(nu=2.5, ard_num_dims=dim, lengthscale_constraint=Interval(0.005, 4.0))\n",
    "    )\n",
    "    model = SingleTaskGP(X_turbo, train_Y, covar_module=covar_module, likelihood=likelihood)\n",
    "    mll = ExactMarginalLogLikelihood(model.likelihood, model)\n",
    "\n",
    "    # Do the fitting and acquisition function optimization inside the Cholesky context\n",
    "    with gpytorch.settings.max_cholesky_size(max_cholesky_size):\n",
    "        # Fit the model\n",
    "        fit_gpytorch_model(mll)\n",
    "    \n",
    "        # Create a batch\n",
    "        X_next = generate_batch(\n",
    "            state=state,\n",
    "            model=model,\n",
    "            X=X_turbo,\n",
    "            Y=train_Y,\n",
    "            batch_size=batch_size,\n",
    "            n_candidates=N_CANDIDATES,\n",
    "            num_restarts=NUM_RESTARTS,\n",
    "            raw_samples=RAW_SAMPLES,\n",
    "            acqf=\"ts\",\n",
    "        )\n",
    "\n",
    "    Y_next = torch.tensor(\n",
    "        [eval_objective(x) for x in X_next], dtype=dtype, device=device\n",
    "    ).unsqueeze(-1)\n",
    "\n",
    "    # Update state\n",
    "    state = update_state(state=state, Y_next=Y_next)\n",
    "\n",
    "    # Append data\n",
    "    X_turbo = torch.cat((X_turbo, X_next), dim=0)\n",
    "    Y_turbo = torch.cat((Y_turbo, Y_next), dim=0)\n",
    "\n",
    "    # Print current status\n",
    "    print(\n",
    "        f\"{len(X_turbo)}) Best value: {state.best_value:.2e}, TR length: {state.length:.2e}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([336, 20])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_turbo.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"D:\\Github\\Visual_Neuro_InSilico_Exp\")\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pylab as plt\n",
    "from insilico_Exp_torch import TorchScorer\n",
    "from GAN_utils import upconvGAN\n",
    "from ZO_HessAware_Optimizers import CholeskyCMAES\n",
    "from layer_hook_utils import get_module_names, register_hook_by_module_names, layername_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------\n",
      "      Layer Id       inshape       outshape           Type                 ReadableStr \n",
      "==============================================================================\n",
      "        0        (3, 227, 227) (3, 227, 227)           Input                      Image\n",
      "        1        (3, 227, 227) (64, 114, 114)          Conv2d               .Conv2dconv1\n",
      "        2        (64, 114, 114) (64, 114, 114)     BatchNorm2d            .BatchNorm2dbn1\n",
      "        3        (64, 114, 114) (64, 114, 114)            ReLU                  .ReLUrelu\n",
      "        4        (64, 114, 114) (64, 57, 57)       MaxPool2d          .MaxPool2dmaxpool\n",
      "        5        (64, 57, 57) (64, 57, 57)          Conv2d      .layer1.0.Conv2dconv1\n",
      "        6        (64, 57, 57) (64, 57, 57)     BatchNorm2d   .layer1.0.BatchNorm2dbn1\n",
      "        7        (64, 57, 57) (64, 57, 57)            ReLU         .layer1.0.ReLUrelu\n",
      "        8        (64, 57, 57) (64, 57, 57)          Conv2d      .layer1.0.Conv2dconv2\n",
      "        9        (64, 57, 57) (64, 57, 57)     BatchNorm2d   .layer1.0.BatchNorm2dbn2\n",
      "        10       (64, 57, 57) (64, 57, 57)            ReLU         .layer1.0.ReLUrelu\n",
      "        11       (64, 57, 57) (256, 57, 57)          Conv2d      .layer1.0.Conv2dconv3\n",
      "        12       (256, 57, 57) (256, 57, 57)     BatchNorm2d   .layer1.0.BatchNorm2dbn3\n",
      "        13       (64, 57, 57) (256, 57, 57)          Conv2d  .layer1.0.downsample.Conv2d0\n",
      "        14       (256, 57, 57) (256, 57, 57)     BatchNorm2d  .layer1.0.downsample.BatchNorm2d1\n",
      "        15       (256, 57, 57) (256, 57, 57)            ReLU         .layer1.0.ReLUrelu\n",
      "        16       (64, 57, 57) (256, 57, 57)      Bottleneck        .layer1.Bottleneck0\n",
      "        17       (256, 57, 57) (64, 57, 57)          Conv2d      .layer1.1.Conv2dconv1\n",
      "        18       (64, 57, 57) (64, 57, 57)     BatchNorm2d   .layer1.1.BatchNorm2dbn1\n",
      "        19       (64, 57, 57) (64, 57, 57)            ReLU         .layer1.1.ReLUrelu\n",
      "        20       (64, 57, 57) (64, 57, 57)          Conv2d      .layer1.1.Conv2dconv2\n",
      "        21       (64, 57, 57) (64, 57, 57)     BatchNorm2d   .layer1.1.BatchNorm2dbn2\n",
      "        22       (64, 57, 57) (64, 57, 57)            ReLU         .layer1.1.ReLUrelu\n",
      "        23       (64, 57, 57) (256, 57, 57)          Conv2d      .layer1.1.Conv2dconv3\n",
      "        24       (256, 57, 57) (256, 57, 57)     BatchNorm2d   .layer1.1.BatchNorm2dbn3\n",
      "        25       (256, 57, 57) (256, 57, 57)            ReLU         .layer1.1.ReLUrelu\n",
      "        26       (256, 57, 57) (256, 57, 57)      Bottleneck        .layer1.Bottleneck1\n",
      "        27       (256, 57, 57) (64, 57, 57)          Conv2d      .layer1.2.Conv2dconv1\n",
      "        28       (64, 57, 57) (64, 57, 57)     BatchNorm2d   .layer1.2.BatchNorm2dbn1\n",
      "        29       (64, 57, 57) (64, 57, 57)            ReLU         .layer1.2.ReLUrelu\n",
      "        30       (64, 57, 57) (64, 57, 57)          Conv2d      .layer1.2.Conv2dconv2\n",
      "        31       (64, 57, 57) (64, 57, 57)     BatchNorm2d   .layer1.2.BatchNorm2dbn2\n",
      "        32       (64, 57, 57) (64, 57, 57)            ReLU         .layer1.2.ReLUrelu\n",
      "        33       (64, 57, 57) (256, 57, 57)          Conv2d      .layer1.2.Conv2dconv3\n",
      "        34       (256, 57, 57) (256, 57, 57)     BatchNorm2d   .layer1.2.BatchNorm2dbn3\n",
      "        35       (256, 57, 57) (256, 57, 57)            ReLU         .layer1.2.ReLUrelu\n",
      "        36       (256, 57, 57) (256, 57, 57)      Bottleneck        .layer1.Bottleneck2\n",
      "        37       (256, 57, 57) (128, 57, 57)          Conv2d      .layer2.0.Conv2dconv1\n",
      "        38       (128, 57, 57) (128, 57, 57)     BatchNorm2d   .layer2.0.BatchNorm2dbn1\n",
      "        39       (128, 57, 57) (128, 57, 57)            ReLU         .layer2.0.ReLUrelu\n",
      "        40       (128, 57, 57) (128, 29, 29)          Conv2d      .layer2.0.Conv2dconv2\n",
      "        41       (128, 29, 29) (128, 29, 29)     BatchNorm2d   .layer2.0.BatchNorm2dbn2\n",
      "        42       (128, 29, 29) (128, 29, 29)            ReLU         .layer2.0.ReLUrelu\n",
      "        43       (128, 29, 29) (512, 29, 29)          Conv2d      .layer2.0.Conv2dconv3\n",
      "        44       (512, 29, 29) (512, 29, 29)     BatchNorm2d   .layer2.0.BatchNorm2dbn3\n",
      "        45       (256, 57, 57) (512, 29, 29)          Conv2d  .layer2.0.downsample.Conv2d0\n",
      "        46       (512, 29, 29) (512, 29, 29)     BatchNorm2d  .layer2.0.downsample.BatchNorm2d1\n",
      "        47       (512, 29, 29) (512, 29, 29)            ReLU         .layer2.0.ReLUrelu\n",
      "        48       (256, 57, 57) (512, 29, 29)      Bottleneck        .layer2.Bottleneck0\n",
      "        49       (512, 29, 29) (128, 29, 29)          Conv2d      .layer2.1.Conv2dconv1\n",
      "        50       (128, 29, 29) (128, 29, 29)     BatchNorm2d   .layer2.1.BatchNorm2dbn1\n",
      "        51       (128, 29, 29) (128, 29, 29)            ReLU         .layer2.1.ReLUrelu\n",
      "        52       (128, 29, 29) (128, 29, 29)          Conv2d      .layer2.1.Conv2dconv2\n",
      "        53       (128, 29, 29) (128, 29, 29)     BatchNorm2d   .layer2.1.BatchNorm2dbn2\n",
      "        54       (128, 29, 29) (128, 29, 29)            ReLU         .layer2.1.ReLUrelu\n",
      "        55       (128, 29, 29) (512, 29, 29)          Conv2d      .layer2.1.Conv2dconv3\n",
      "        56       (512, 29, 29) (512, 29, 29)     BatchNorm2d   .layer2.1.BatchNorm2dbn3\n",
      "        57       (512, 29, 29) (512, 29, 29)            ReLU         .layer2.1.ReLUrelu\n",
      "        58       (512, 29, 29) (512, 29, 29)      Bottleneck        .layer2.Bottleneck1\n",
      "        59       (512, 29, 29) (128, 29, 29)          Conv2d      .layer2.2.Conv2dconv1\n",
      "        60       (128, 29, 29) (128, 29, 29)     BatchNorm2d   .layer2.2.BatchNorm2dbn1\n",
      "        61       (128, 29, 29) (128, 29, 29)            ReLU         .layer2.2.ReLUrelu\n",
      "        62       (128, 29, 29) (128, 29, 29)          Conv2d      .layer2.2.Conv2dconv2\n",
      "        63       (128, 29, 29) (128, 29, 29)     BatchNorm2d   .layer2.2.BatchNorm2dbn2\n",
      "        64       (128, 29, 29) (128, 29, 29)            ReLU         .layer2.2.ReLUrelu\n",
      "        65       (128, 29, 29) (512, 29, 29)          Conv2d      .layer2.2.Conv2dconv3\n",
      "        66       (512, 29, 29) (512, 29, 29)     BatchNorm2d   .layer2.2.BatchNorm2dbn3\n",
      "        67       (512, 29, 29) (512, 29, 29)            ReLU         .layer2.2.ReLUrelu\n",
      "        68       (512, 29, 29) (512, 29, 29)      Bottleneck        .layer2.Bottleneck2\n",
      "        69       (512, 29, 29) (128, 29, 29)          Conv2d      .layer2.3.Conv2dconv1\n",
      "        70       (128, 29, 29) (128, 29, 29)     BatchNorm2d   .layer2.3.BatchNorm2dbn1\n",
      "        71       (128, 29, 29) (128, 29, 29)            ReLU         .layer2.3.ReLUrelu\n",
      "        72       (128, 29, 29) (128, 29, 29)          Conv2d      .layer2.3.Conv2dconv2\n",
      "        73       (128, 29, 29) (128, 29, 29)     BatchNorm2d   .layer2.3.BatchNorm2dbn2\n",
      "        74       (128, 29, 29) (128, 29, 29)            ReLU         .layer2.3.ReLUrelu\n",
      "        75       (128, 29, 29) (512, 29, 29)          Conv2d      .layer2.3.Conv2dconv3\n",
      "        76       (512, 29, 29) (512, 29, 29)     BatchNorm2d   .layer2.3.BatchNorm2dbn3\n",
      "        77       (512, 29, 29) (512, 29, 29)            ReLU         .layer2.3.ReLUrelu\n",
      "        78       (512, 29, 29) (512, 29, 29)      Bottleneck        .layer2.Bottleneck3\n",
      "        79       (512, 29, 29) (256, 29, 29)          Conv2d      .layer3.0.Conv2dconv1\n",
      "        80       (256, 29, 29) (256, 29, 29)     BatchNorm2d   .layer3.0.BatchNorm2dbn1\n",
      "        81       (256, 29, 29) (256, 29, 29)            ReLU         .layer3.0.ReLUrelu\n",
      "        82       (256, 29, 29) (256, 15, 15)          Conv2d      .layer3.0.Conv2dconv2\n",
      "        83       (256, 15, 15) (256, 15, 15)     BatchNorm2d   .layer3.0.BatchNorm2dbn2\n",
      "        84       (256, 15, 15) (256, 15, 15)            ReLU         .layer3.0.ReLUrelu\n",
      "        85       (256, 15, 15) (1024, 15, 15)          Conv2d      .layer3.0.Conv2dconv3\n",
      "        86       (1024, 15, 15) (1024, 15, 15)     BatchNorm2d   .layer3.0.BatchNorm2dbn3\n",
      "        87       (512, 29, 29) (1024, 15, 15)          Conv2d  .layer3.0.downsample.Conv2d0\n",
      "        88       (1024, 15, 15) (1024, 15, 15)     BatchNorm2d  .layer3.0.downsample.BatchNorm2d1\n",
      "        89       (1024, 15, 15) (1024, 15, 15)            ReLU         .layer3.0.ReLUrelu\n",
      "        90       (512, 29, 29) (1024, 15, 15)      Bottleneck        .layer3.Bottleneck0\n",
      "        91       (1024, 15, 15) (256, 15, 15)          Conv2d      .layer3.1.Conv2dconv1\n",
      "        92       (256, 15, 15) (256, 15, 15)     BatchNorm2d   .layer3.1.BatchNorm2dbn1\n",
      "        93       (256, 15, 15) (256, 15, 15)            ReLU         .layer3.1.ReLUrelu\n",
      "        94       (256, 15, 15) (256, 15, 15)          Conv2d      .layer3.1.Conv2dconv2\n",
      "        95       (256, 15, 15) (256, 15, 15)     BatchNorm2d   .layer3.1.BatchNorm2dbn2\n",
      "        96       (256, 15, 15) (256, 15, 15)            ReLU         .layer3.1.ReLUrelu\n",
      "        97       (256, 15, 15) (1024, 15, 15)          Conv2d      .layer3.1.Conv2dconv3\n",
      "        98       (1024, 15, 15) (1024, 15, 15)     BatchNorm2d   .layer3.1.BatchNorm2dbn3\n",
      "        99       (1024, 15, 15) (1024, 15, 15)            ReLU         .layer3.1.ReLUrelu\n",
      "        100      (1024, 15, 15) (1024, 15, 15)      Bottleneck        .layer3.Bottleneck1\n",
      "        101      (1024, 15, 15) (256, 15, 15)          Conv2d      .layer3.2.Conv2dconv1\n",
      "        102      (256, 15, 15) (256, 15, 15)     BatchNorm2d   .layer3.2.BatchNorm2dbn1\n",
      "        103      (256, 15, 15) (256, 15, 15)            ReLU         .layer3.2.ReLUrelu\n",
      "        104      (256, 15, 15) (256, 15, 15)          Conv2d      .layer3.2.Conv2dconv2\n",
      "        105      (256, 15, 15) (256, 15, 15)     BatchNorm2d   .layer3.2.BatchNorm2dbn2\n",
      "        106      (256, 15, 15) (256, 15, 15)            ReLU         .layer3.2.ReLUrelu\n",
      "        107      (256, 15, 15) (1024, 15, 15)          Conv2d      .layer3.2.Conv2dconv3\n",
      "        108      (1024, 15, 15) (1024, 15, 15)     BatchNorm2d   .layer3.2.BatchNorm2dbn3\n",
      "        109      (1024, 15, 15) (1024, 15, 15)            ReLU         .layer3.2.ReLUrelu\n",
      "        110      (1024, 15, 15) (1024, 15, 15)      Bottleneck        .layer3.Bottleneck2\n",
      "        111      (1024, 15, 15) (256, 15, 15)          Conv2d      .layer3.3.Conv2dconv1\n",
      "        112      (256, 15, 15) (256, 15, 15)     BatchNorm2d   .layer3.3.BatchNorm2dbn1\n",
      "        113      (256, 15, 15) (256, 15, 15)            ReLU         .layer3.3.ReLUrelu\n",
      "        114      (256, 15, 15) (256, 15, 15)          Conv2d      .layer3.3.Conv2dconv2\n",
      "        115      (256, 15, 15) (256, 15, 15)     BatchNorm2d   .layer3.3.BatchNorm2dbn2\n",
      "        116      (256, 15, 15) (256, 15, 15)            ReLU         .layer3.3.ReLUrelu\n",
      "        117      (256, 15, 15) (1024, 15, 15)          Conv2d      .layer3.3.Conv2dconv3\n",
      "        118      (1024, 15, 15) (1024, 15, 15)     BatchNorm2d   .layer3.3.BatchNorm2dbn3\n",
      "        119      (1024, 15, 15) (1024, 15, 15)            ReLU         .layer3.3.ReLUrelu\n",
      "        120      (1024, 15, 15) (1024, 15, 15)      Bottleneck        .layer3.Bottleneck3\n",
      "        121      (1024, 15, 15) (256, 15, 15)          Conv2d      .layer3.4.Conv2dconv1\n",
      "        122      (256, 15, 15) (256, 15, 15)     BatchNorm2d   .layer3.4.BatchNorm2dbn1\n",
      "        123      (256, 15, 15) (256, 15, 15)            ReLU         .layer3.4.ReLUrelu\n",
      "        124      (256, 15, 15) (256, 15, 15)          Conv2d      .layer3.4.Conv2dconv2\n",
      "        125      (256, 15, 15) (256, 15, 15)     BatchNorm2d   .layer3.4.BatchNorm2dbn2\n",
      "        126      (256, 15, 15) (256, 15, 15)            ReLU         .layer3.4.ReLUrelu\n",
      "        127      (256, 15, 15) (1024, 15, 15)          Conv2d      .layer3.4.Conv2dconv3\n",
      "        128      (1024, 15, 15) (1024, 15, 15)     BatchNorm2d   .layer3.4.BatchNorm2dbn3\n",
      "        129      (1024, 15, 15) (1024, 15, 15)            ReLU         .layer3.4.ReLUrelu\n",
      "        130      (1024, 15, 15) (1024, 15, 15)      Bottleneck        .layer3.Bottleneck4\n",
      "        131      (1024, 15, 15) (256, 15, 15)          Conv2d      .layer3.5.Conv2dconv1\n",
      "        132      (256, 15, 15) (256, 15, 15)     BatchNorm2d   .layer3.5.BatchNorm2dbn1\n",
      "        133      (256, 15, 15) (256, 15, 15)            ReLU         .layer3.5.ReLUrelu\n",
      "        134      (256, 15, 15) (256, 15, 15)          Conv2d      .layer3.5.Conv2dconv2\n",
      "        135      (256, 15, 15) (256, 15, 15)     BatchNorm2d   .layer3.5.BatchNorm2dbn2\n",
      "        136      (256, 15, 15) (256, 15, 15)            ReLU         .layer3.5.ReLUrelu\n",
      "        137      (256, 15, 15) (1024, 15, 15)          Conv2d      .layer3.5.Conv2dconv3\n",
      "        138      (1024, 15, 15) (1024, 15, 15)     BatchNorm2d   .layer3.5.BatchNorm2dbn3\n",
      "        139      (1024, 15, 15) (1024, 15, 15)            ReLU         .layer3.5.ReLUrelu\n",
      "        140      (1024, 15, 15) (1024, 15, 15)      Bottleneck        .layer3.Bottleneck5\n",
      "        141      (1024, 15, 15) (512, 15, 15)          Conv2d      .layer4.0.Conv2dconv1\n",
      "        142      (512, 15, 15) (512, 15, 15)     BatchNorm2d   .layer4.0.BatchNorm2dbn1\n",
      "        143      (512, 15, 15) (512, 15, 15)            ReLU         .layer4.0.ReLUrelu\n",
      "        144      (512, 15, 15)  (512, 8, 8)          Conv2d      .layer4.0.Conv2dconv2\n",
      "        145       (512, 8, 8)  (512, 8, 8)     BatchNorm2d   .layer4.0.BatchNorm2dbn2\n",
      "        146       (512, 8, 8)  (512, 8, 8)            ReLU         .layer4.0.ReLUrelu\n",
      "        147       (512, 8, 8) (2048, 8, 8)          Conv2d      .layer4.0.Conv2dconv3\n",
      "        148      (2048, 8, 8) (2048, 8, 8)     BatchNorm2d   .layer4.0.BatchNorm2dbn3\n",
      "        149      (1024, 15, 15) (2048, 8, 8)          Conv2d  .layer4.0.downsample.Conv2d0\n",
      "        150      (2048, 8, 8) (2048, 8, 8)     BatchNorm2d  .layer4.0.downsample.BatchNorm2d1\n",
      "        151      (2048, 8, 8) (2048, 8, 8)            ReLU         .layer4.0.ReLUrelu\n",
      "        152      (1024, 15, 15) (2048, 8, 8)      Bottleneck        .layer4.Bottleneck0\n",
      "        153      (2048, 8, 8)  (512, 8, 8)          Conv2d      .layer4.1.Conv2dconv1\n",
      "        154       (512, 8, 8)  (512, 8, 8)     BatchNorm2d   .layer4.1.BatchNorm2dbn1\n",
      "        155       (512, 8, 8)  (512, 8, 8)            ReLU         .layer4.1.ReLUrelu\n",
      "        156       (512, 8, 8)  (512, 8, 8)          Conv2d      .layer4.1.Conv2dconv2\n",
      "        157       (512, 8, 8)  (512, 8, 8)     BatchNorm2d   .layer4.1.BatchNorm2dbn2\n",
      "        158       (512, 8, 8)  (512, 8, 8)            ReLU         .layer4.1.ReLUrelu\n",
      "        159       (512, 8, 8) (2048, 8, 8)          Conv2d      .layer4.1.Conv2dconv3\n",
      "        160      (2048, 8, 8) (2048, 8, 8)     BatchNorm2d   .layer4.1.BatchNorm2dbn3\n",
      "        161      (2048, 8, 8) (2048, 8, 8)            ReLU         .layer4.1.ReLUrelu\n",
      "        162      (2048, 8, 8) (2048, 8, 8)      Bottleneck        .layer4.Bottleneck1\n",
      "        163      (2048, 8, 8)  (512, 8, 8)          Conv2d      .layer4.2.Conv2dconv1\n",
      "        164       (512, 8, 8)  (512, 8, 8)     BatchNorm2d   .layer4.2.BatchNorm2dbn1\n",
      "        165       (512, 8, 8)  (512, 8, 8)            ReLU         .layer4.2.ReLUrelu\n",
      "        166       (512, 8, 8)  (512, 8, 8)          Conv2d      .layer4.2.Conv2dconv2\n",
      "        167       (512, 8, 8)  (512, 8, 8)     BatchNorm2d   .layer4.2.BatchNorm2dbn2\n",
      "        168       (512, 8, 8)  (512, 8, 8)            ReLU         .layer4.2.ReLUrelu\n",
      "        169       (512, 8, 8) (2048, 8, 8)          Conv2d      .layer4.2.Conv2dconv3\n",
      "        170      (2048, 8, 8) (2048, 8, 8)     BatchNorm2d   .layer4.2.BatchNorm2dbn3\n",
      "        171      (2048, 8, 8) (2048, 8, 8)            ReLU         .layer4.2.ReLUrelu\n",
      "        172      (2048, 8, 8) (2048, 8, 8)      Bottleneck        .layer4.Bottleneck2\n",
      "        173      (2048, 8, 8) (2048, 1, 1) AdaptiveAvgPool2d  .AdaptiveAvgPool2davgpool\n",
      "        174           (2048,)      (1000,)          Linear                  .Linearfc\n",
      "        175      (3, 227, 227)      (1000,)          ResNet                    .ResNet\n"
     ]
    }
   ],
   "source": [
    "G = upconvGAN(\"fc6\").cuda()\n",
    "G.requires_grad_(False)\n",
    "scorer = TorchScorer(\"resnet50_linf8\")\n",
    "module_names, module_types, module_spec = get_module_names(scorer.model, input_size=(3, 227, 227), device=\"cuda\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "scorer = TorchScorer(\"resnet50_linf8\")\n",
    "layer = \".layer3.Bottleneck0\"\n",
    "scorer.select_unit((\"resnet50_linf8\", layer, 5, 4, 4), allow_grad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.19957605, 0.13401042, 0.        , 0.20104873, 0.27269748,\n",
       "       0.1320242 , 0.94416088, 0.32531488, 0.        , 0.00650109,\n",
       "       0.        , 0.07258172, 0.07727592, 0.34789151, 0.        ,\n",
       "       0.10048866, 0.56543165, 0.58117169, 0.        , 0.        ,\n",
       "       0.74983805, 0.36718482, 0.01867732, 0.        , 0.        ,\n",
       "       0.02922987, 0.22796671, 0.1772141 , 0.00713531, 0.        ,\n",
       "       1.01237154, 0.        , 0.66683447, 0.22088432, 0.50876063,\n",
       "       0.0234718 , 0.        , 0.71578091, 0.        , 0.40342677])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgtsrs = G.visualize(torch.randn(40,4096).cuda())\n",
    "scorer.score_tsr(imgtsrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_objective(z):\n",
    "    imgtsrs = G.visualize(z.view([-1,4096]).cuda())\n",
    "    scores = scorer.score_tsr_wgrad(imgtsrs)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([336, 20])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_turbo.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_turbo = torch.randn(40,4096).cuda()\n",
    "Y_turbo = eval_objective(X_turbo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-db332a0c8651>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     39\u001b[0m             \u001b[0mnum_restarts\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNUM_RESTARTS\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m             \u001b[0mraw_samples\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mRAW_SAMPLES\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m             \u001b[0macqf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"ts\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m         )\n\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-8f93008cdec8>\u001b[0m in \u001b[0;36mgenerate_batch\u001b[1;34m(state, model, X, Y, batch_size, n_candidates, num_restarts, raw_samples, acqf)\u001b[0m\n\u001b[0;32m     11\u001b[0m ):\n\u001b[0;32m     12\u001b[0m     \u001b[1;32massert\u001b[0m \u001b[0macqf\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"ts\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ei\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[1;32massert\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m0.0\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m1.0\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misfinite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mn_candidates\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0mn_candidates\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m200\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# X_turbo = get_initial_points(dim, n_init)\n",
    "# Y_turbo = torch.tensor(\n",
    "#     [eval_objective(x) for x in X_turbo], dtype=dtype, device=device\n",
    "# ).unsqueeze(-1)\n",
    "batch_size = 40\n",
    "dim = 4096\n",
    "X_turbo = torch.randn(40,4096).cuda()\n",
    "Y_turbo = eval_objective(X_turbo).unsqueeze(-1)\n",
    "state = TurboState(dim, batch_size=batch_size)\n",
    "\n",
    "NUM_RESTARTS = 10 if not SMOKE_TEST else 2\n",
    "RAW_SAMPLES = 512 if not SMOKE_TEST else 4\n",
    "N_CANDIDATES = min(5000, max(2000, 200 * dim)) if not SMOKE_TEST else 4\n",
    "\n",
    "\n",
    "while not state.restart_triggered:  # Run until TuRBO converges\n",
    "    # Fit a GP model\n",
    "    train_Y = (Y_turbo - Y_turbo.mean()) / Y_turbo.std()\n",
    "    likelihood = GaussianLikelihood(noise_constraint=Interval(1e-8, 1e-3))\n",
    "    covar_module = ScaleKernel(  # Use the same lengthscale prior as in the TuRBO paper\n",
    "        MaternKernel(nu=2.5, ard_num_dims=dim, lengthscale_constraint=Interval(0.005, 4.0))\n",
    "    )\n",
    "    model = SingleTaskGP(X_turbo, train_Y, covar_module=covar_module, likelihood=likelihood)\n",
    "    mll = ExactMarginalLogLikelihood(model.likelihood, model)\n",
    "\n",
    "    # Do the fitting and acquisition function optimization inside the Cholesky context\n",
    "    with gpytorch.settings.max_cholesky_size(max_cholesky_size):\n",
    "        # Fit the model\n",
    "        fit_gpytorch_model(mll)\n",
    "    \n",
    "        # Create a batch\n",
    "        X_next = generate_batch(\n",
    "            state=state,\n",
    "            model=model,\n",
    "            X=X_turbo,\n",
    "            Y=train_Y,\n",
    "            batch_size=batch_size,\n",
    "            n_candidates=N_CANDIDATES,\n",
    "            num_restarts=NUM_RESTARTS,\n",
    "            raw_samples=RAW_SAMPLES,\n",
    "            acqf=\"ts\",\n",
    "        )\n",
    "\n",
    "    Y_next = eval_objective(X_next.cuda()).unsqueeze(-1)\n",
    "#     torch.tensor(\n",
    "#         [eval_objective(x) for x in X_next], dtype=dtype, device=device\n",
    "#     ).unsqueeze(-1)\n",
    "\n",
    "    # Update state\n",
    "    state = update_state(state=state, Y_next=Y_next)\n",
    "\n",
    "    # Append data\n",
    "    X_turbo = torch.cat((X_turbo, X_next), dim=0)\n",
    "    Y_turbo = torch.cat((Y_turbo, Y_next), dim=0)\n",
    "\n",
    "    # Print current status\n",
    "    print(\n",
    "        f\"{len(X_turbo)}) Best value: {state.best_value:.2e}, TR length: {state.length:.2e}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GP-EI\n",
    "As a baseline, we compare TuRBO to qEI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44) Best value: -1.16e+01\n",
      "48) Best value: -1.06e+01\n",
      "52) Best value: -9.95e+00\n",
      "56) Best value: -8.82e+00\n",
      "60) Best value: -8.82e+00\n",
      "64) Best value: -8.82e+00\n",
      "68) Best value: -8.82e+00\n",
      "72) Best value: -8.82e+00\n",
      "76) Best value: -8.82e+00\n",
      "80) Best value: -8.82e+00\n",
      "84) Best value: -8.82e+00\n",
      "88) Best value: -8.82e+00\n",
      "92) Best value: -8.82e+00\n",
      "96) Best value: -8.82e+00\n",
      "100) Best value: -8.82e+00\n",
      "104) Best value: -8.82e+00\n",
      "108) Best value: -8.82e+00\n",
      "112) Best value: -8.82e+00\n",
      "116) Best value: -8.82e+00\n",
      "120) Best value: -8.82e+00\n",
      "124) Best value: -8.82e+00\n",
      "128) Best value: -8.82e+00\n",
      "132) Best value: -8.82e+00\n",
      "136) Best value: -8.82e+00\n",
      "140) Best value: -8.82e+00\n",
      "144) Best value: -8.82e+00\n",
      "148) Best value: -8.82e+00\n",
      "152) Best value: -8.82e+00\n",
      "156) Best value: -8.82e+00\n",
      "160) Best value: -8.82e+00\n",
      "164) Best value: -8.82e+00\n",
      "168) Best value: -8.82e+00\n",
      "172) Best value: -8.82e+00\n",
      "176) Best value: -8.82e+00\n",
      "180) Best value: -8.82e+00\n",
      "184) Best value: -8.82e+00\n",
      "188) Best value: -8.82e+00\n",
      "192) Best value: -8.82e+00\n",
      "196) Best value: -8.82e+00\n",
      "200) Best value: -8.82e+00\n",
      "204) Best value: -8.82e+00\n",
      "208) Best value: -8.82e+00\n",
      "212) Best value: -8.82e+00\n",
      "216) Best value: -8.82e+00\n",
      "220) Best value: -8.82e+00\n",
      "224) Best value: -8.82e+00\n",
      "228) Best value: -8.82e+00\n",
      "232) Best value: -5.73e+00\n",
      "236) Best value: -5.73e+00\n",
      "240) Best value: -5.73e+00\n",
      "244) Best value: -5.73e+00\n",
      "248) Best value: -5.73e+00\n",
      "252) Best value: -5.73e+00\n",
      "256) Best value: -5.73e+00\n",
      "260) Best value: -5.73e+00\n",
      "264) Best value: -5.73e+00\n",
      "268) Best value: -5.73e+00\n",
      "272) Best value: -5.73e+00\n",
      "276) Best value: -5.73e+00\n",
      "280) Best value: -5.73e+00\n",
      "284) Best value: -5.73e+00\n",
      "288) Best value: -5.73e+00\n",
      "292) Best value: -5.73e+00\n",
      "296) Best value: -5.73e+00\n",
      "300) Best value: -5.73e+00\n",
      "304) Best value: -5.73e+00\n",
      "308) Best value: -5.73e+00\n",
      "312) Best value: -5.73e+00\n",
      "316) Best value: -5.73e+00\n",
      "320) Best value: -5.73e+00\n",
      "324) Best value: -5.73e+00\n",
      "328) Best value: -5.73e+00\n",
      "332) Best value: -5.73e+00\n",
      "336) Best value: -5.73e+00\n"
     ]
    }
   ],
   "source": [
    "X_ei = get_initial_points(dim, n_init)\n",
    "Y_ei = torch.tensor(\n",
    "    [eval_objective(x) for x in X_ei], dtype=dtype, device=device\n",
    ").unsqueeze(-1)\n",
    "\n",
    "while len(Y_ei) < len(Y_turbo):\n",
    "    train_Y = (Y_ei - Y_ei.mean()) / Y_ei.std()\n",
    "    likelihood = GaussianLikelihood(noise_constraint=Interval(1e-8, 1e-3))\n",
    "    model = SingleTaskGP(X_ei, train_Y, likelihood=likelihood)\n",
    "    mll = ExactMarginalLogLikelihood(model.likelihood, model)\n",
    "    fit_gpytorch_model(mll)\n",
    "\n",
    "    # Create a batch\n",
    "    ei = qExpectedImprovement(model, train_Y.max(), maximize=True)\n",
    "    candidate, acq_value = optimize_acqf(\n",
    "        ei,\n",
    "        bounds=torch.stack(\n",
    "            [\n",
    "                torch.zeros(dim, dtype=dtype, device=device),\n",
    "                torch.ones(dim, dtype=dtype, device=device),\n",
    "            ]\n",
    "        ),\n",
    "        q=batch_size,\n",
    "        num_restarts=NUM_RESTARTS,\n",
    "        raw_samples=RAW_SAMPLES,\n",
    "    )\n",
    "    Y_next = torch.tensor(\n",
    "        [eval_objective(x) for x in candidate], dtype=dtype, device=device\n",
    "    ).unsqueeze(-1)\n",
    "\n",
    "    # Append data\n",
    "    X_ei = torch.cat((X_ei, candidate), axis=0)\n",
    "    Y_ei = torch.cat((Y_ei, Y_next), axis=0)\n",
    "\n",
    "    # Print current status\n",
    "    print(f\"{len(X_ei)}) Best value: {Y_ei.max().item():.2e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sobol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Sobol = SobolEngine(dim, scramble=True, seed=0).draw(len(X_turbo)).to(dtype=dtype, device=device)\n",
    "Y_Sobol = torch.tensor([eval_objective(x) for x in X_Sobol], dtype=dtype, device=device).unsqueeze(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare the methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib import rc\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "names = [\"TuRBO-1\", \"EI\", \"Sobol\"]\n",
    "runs = [Y_turbo, Y_ei, Y_Sobol]\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "for name, run in zip(names, runs):\n",
    "    fx = np.maximum.accumulate(run.cpu())\n",
    "    plt.plot(fx, marker=\"\", lw=3)\n",
    "\n",
    "plt.plot([0, len(Y_turbo)], [fun.optimal_value, fun.optimal_value], \"k--\", lw=3)\n",
    "plt.xlabel(\"Function value\", fontsize=18)\n",
    "plt.xlabel(\"Number of evaluations\", fontsize=18)\n",
    "plt.title(\"20D Ackley\", fontsize=24)\n",
    "plt.xlim([0, len(Y_turbo)])\n",
    "plt.ylim([-15, 1])\n",
    "\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.legend(\n",
    "    names + [\"Global optimal value\"],\n",
    "    loc=\"lower center\",\n",
    "    bbox_to_anchor=(0, -0.08, 1, 1),\n",
    "    bbox_transform=plt.gcf().transFigure,\n",
    "    ncol=4,\n",
    "    fontsize=16,\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "bento_stylesheets": {
   "bento/extensions/flow/main.css": true,
   "bento/extensions/kernel_selector/main.css": true,
   "bento/extensions/kernel_ui/main.css": true,
   "bento/extensions/new_kernel/main.css": true,
   "bento/extensions/system_usage/main.css": true,
   "bento/extensions/theme/main.css": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
