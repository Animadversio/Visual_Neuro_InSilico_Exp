{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# BigGAN Hessian Computation\n",
    "This repo tries to prove whether we could compute hessian of BigGAN (activation or image similarity) by forward finite difference method."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from pytorch_pretrained_biggan import BigGAN, truncated_noise_sample\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from hessian_eigenthings.power_iter import Operator, deflated_power_iteration\n",
    "from hessian_eigenthings.lanczos import lanczos\n",
    "from lanczos_generalized import lanczos_generalized\n",
    "from GAN_hvp_operator import GANHVPOperator, GANForwardHVPOperator, compute_hessian_eigenthings, get_full_hessian\n",
    "#%\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "from time import time\n",
    "from os.path import join\n",
    "from imageio import imwrite\n",
    "from build_montages import build_montages, color_framed_montages\n",
    "import torchvision.models as tv"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "BGAN = BigGAN.from_pretrained(\"biggan-deep-256\")\n",
    "#%\n",
    "for param in BGAN.parameters():\n",
    "    param.requires_grad_(False)\n",
    "embed_mat = BGAN.embeddings.parameters().__next__().data\n",
    "BGAN.cuda()\n",
    "#%\n",
    "alexnet = tv.alexnet(pretrained=True).cuda()\n",
    "alexnet.eval() # this is important or there will be trial to trial variability due to DropOut\n",
    "for param in alexnet.parameters():\n",
    "    param.requires_grad_(False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%0\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from FeatLinModel import FeatLinModel, get_model_layers"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from torchvision.transforms import Normalize, Compose\n",
    "RGB_mean = torch.tensor([0.485, 0.456, 0.406]).view(1,-1,1,1).cuda()\n",
    "RGB_std  = torch.tensor([0.229, 0.224, 0.225]).view(1,-1,1,1).cuda()\n",
    "preprocess = Compose([lambda img: (F.interpolate(img, (224, 224), mode='bilinear', align_corners=True) - RGB_mean) / RGB_std])\n",
    "preprocess_resize = Compose([lambda img: F.interpolate(img, (224, 224), mode='bilinear', align_corners=True) ])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from hessian import hessian\n",
    "from IPython.display import clear_output\n",
    "from hessian_eigenthings.utils import progress_bar\n",
    "from GAN_hvp_operator import get_full_hessian\n",
    "def tuning_plot_BigGAN(G, preprocess, objective, feat, eigvals, eigvects, space=\"class\",\n",
    "        eig_id_arr=(0, 1, 5, 10, 15, 20, 40, 60, 80,99, 120, 127),\n",
    "        save_indiv=False, save_row=False, summary_dir=\"\", veclabel=\"eig\", titlestr=\"\", lim=(-1, 1), ticks=21,\n",
    "        pad=24, cmap=plt.cm.viridis, RND=None):\n",
    "    if RND is None: RND = np.random.randint(100)\n",
    "    vec_norm = feat.norm().item()\n",
    "\n",
    "    if space == \"class\":\n",
    "        step = 2 / (ticks - 1)\n",
    "        step_arr = torch.linspace(lim[0], lim[1], ticks)\n",
    "        ref_vect = feat.detach().clone()\n",
    "    elif space == \"full\":\n",
    "        step = 2 / (ticks - 1)\n",
    "        step_arr = torch.linspace(lim[0], lim[1], ticks)\n",
    "        ref_vect = feat.detach().clone()\n",
    "    elif space == \"noise\":\n",
    "        theta_arr_deg =  np.linspace(-90, 90, ticks) # np.arange(-5, 6)\n",
    "        theta_arr = theta_arr_deg / 180 * np.pi\n",
    "        ref_vect = (feat / vec_norm).cpu().numpy()\n",
    "    img_list_all = []\n",
    "    scores_col = [] # array version of scores\n",
    "    scores_all = [] # list version of scores\n",
    "    # eig_id_arr = [0, 1, 5, 10, 15, 20, 40, 60, 80,99,150,200,250,299,450]\n",
    "    batch = 6\n",
    "    for eig_id in eig_id_arr: #,600,799]:\n",
    "        # eig_id = 0\n",
    "        perturb_vect = eigvects[eig_id,:]  # PC_vectors[1,:]\n",
    "        if space == \"class\":\n",
    "            perturb_vecs = step_arr.unsqueeze(1) @ torch.from_numpy(perturb_vect).unsqueeze(0)\n",
    "            perturb_vecs = torch.cat((torch.zeros_like(perturb_vecs), perturb_vecs), dim=1)\n",
    "            codes_arc = perturb_vecs.cuda() + ref_vect.cuda()\n",
    "            codes_arc.requires_grad_(False)\n",
    "            csr = 0\n",
    "            with torch.no_grad():\n",
    "                img_batchs = []\n",
    "                while csr < codes_arc.size(0):\n",
    "                    csr_end = min(csr + batch, codes_arc.size(0))\n",
    "                    imgs = G.generator(codes_arc[csr:csr_end, :], 0.6)\n",
    "                    img_batchs.append(imgs)\n",
    "                    csr = csr_end\n",
    "                imgs = torch.cat(tuple(img_batchs), dim=0)\n",
    "        elif space == \"noise\":\n",
    "            codes_arc = np.array([np.cos(theta_arr),\n",
    "                              np.sin(theta_arr) ]).T @ np.array([ref_vect, perturb_vect])\n",
    "            norms = np.linalg.norm(codes_arc, axis=1)\n",
    "            codes_arc = codes_arc / norms[:, np.newaxis] * vec_norm\n",
    "            imgs = G.visualize(torch.from_numpy(codes_arc).float().cuda())\n",
    "        elif space == \"full\":\n",
    "            perturb_vecs = step_arr.unsqueeze(1) @ torch.from_numpy(perturb_vect).unsqueeze(0)\n",
    "            codes_arc = perturb_vecs.cuda() + ref_vect.cuda()\n",
    "            codes_arc.requires_grad_(False)\n",
    "            csr = 0\n",
    "            img_batchs = []\n",
    "            with torch.no_grad():\n",
    "                while csr < codes_arc.size(0):\n",
    "                    csr_end = min(csr + batch, codes_arc.size(0))\n",
    "                    imgs = G.generator(codes_arc[csr:csr_end, :], 0.6)\n",
    "                    img_batchs.append(imgs)\n",
    "                    csr = csr_end\n",
    "                imgs = torch.cat(tuple(img_batchs), dim=0)\n",
    "        scores = - objective(preprocess(imgs), scaler=False)\n",
    "        scores_col.append(scores.cpu().numpy())\n",
    "        scores_all.extend(scores.cpu().squeeze().tolist())\n",
    "        npimgs = np.clip((imgs.detach().cpu().permute([2, 3, 1, 0]).numpy() + 1) / 2, 0, 1)\n",
    "\n",
    "        if save_indiv:\n",
    "            for i in range(npimgs.shape[3]):\n",
    "                angle = theta_arr_deg[i]\n",
    "                imwrite(join(newimg_dir, \"norm%d_%s%d_ang%d.jpg\" % (vec_norm, veclabel, eig_id, angle)), npimgs[:, :, :, i])\n",
    "\n",
    "        img_list = [npimgs[:, :, :, i] for i in range(npimgs.shape[3])]\n",
    "        img_list_all.extend(img_list)\n",
    "        if save_row:\n",
    "            mtg1 = build_montages(img_list, [256, 256], [ticks, 1])[0]\n",
    "            imwrite(join(summary_dir, \"norm%d_%s_%d.jpg\" % (vec_norm, veclabel, eig_id)), mtg1)\n",
    "    mtg_all = build_montages(img_list_all, [256, 256], [ticks, int(len(img_list_all) // ticks)])[0]\n",
    "    imwrite(join(summary_dir, \"norm%d_%s_%d.jpg\" % (vec_norm, veclabel, RND)), mtg_all)\n",
    "    print(\"Write to \", join(summary_dir, \"norm%d_%s_%d.jpg\" % (vec_norm, veclabel, RND)))\n",
    "\n",
    "    mtg_frm = color_framed_montages(img_list_all, [256, 256], [ticks, int(len(img_list_all) // ticks)], scores_all, pad=pad, cmap=cmap)[0]\n",
    "    imwrite(join(summary_dir, \"norm%d_%s_framed_%d.jpg\" % (vec_norm, veclabel, RND)), mtg_frm)\n",
    "    print(\"Write to \", join(summary_dir, \"norm%d_%s_framed_%d.jpg\" % (vec_norm, veclabel, RND)))\n",
    "\n",
    "    scores_col = np.array(scores_col)\n",
    "    plt.figure(figsize=[8,10],dpi=100)\n",
    "    plt.matshow(scores_col)\n",
    "    plt.axis('image')\n",
    "    plt.title(\"Neural Tuning Towards Different Eigen Vectors of Activation\")\n",
    "    plt.xlabel(\"Angle\")\n",
    "    plt.ylabel(\"Eigen Vector #\")\n",
    "    eiglabel = [\"%d %.3f\"%(id,eig) for id, eig in zip(eig_id_arr, eigvals[list(eig_id_arr)])]\n",
    "    plt.yticks(range(len(eig_id_arr)), eiglabel) # eig_id_arr\n",
    "    plt.ylim(top=-0.5, bottom=len(eig_id_arr) - 0.5)\n",
    "    plt.colorbar()\n",
    "    plt.suptitle(titlestr)\n",
    "    plt.savefig(join(summary_dir, \"norm%d_%s_score_mat_%02d.jpg\" % (vec_norm, veclabel, RND)) , dpi=100, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    print(\"Write to \", join(summary_dir, \"norm%d_%s_score_mat_%02d.jpg\" % (vec_norm, veclabel, RND)) )\n",
    "    return img_list, scores_col"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class BigGAN_wrapper():#nn.Module\n",
    "    def __init__(self, BigGAN, space=\"class\"):\n",
    "        self.BigGAN = BigGAN\n",
    "        self.space = space\n",
    "\n",
    "    def visualize(self, code, scale=1.0):\n",
    "        imgs = self.BigGAN.generator(code, 0.6)\n",
    "        return torch.clamp((imgs + 1.0) / 2.0, 0, 1) * scale\n",
    "\n",
    "G = BigGAN_wrapper(BGAN)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%time\n",
    "feat = torch.randn(256).cuda().requires_grad_(True)\n",
    "img = BGAN.generator(feat, 0.7)\n",
    "obj = img.mean()\n",
    "# obj.backward()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%time\n",
    "from hessian import hessian\n",
    "H = hessian(obj, feat)\n",
    "\n",
    "eigval, eigvec = np.linalg.eigh(H.cpu().numpy())\n",
    "plt.plot(sorted(eigval))\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "objective = FeatLinModel(alexnet, layername=\"features_10\", type=\"neuron\", chan=10, pos=(7, 7))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "feat = torch.randn(256).cuda().requires_grad_(True)\n",
    "act = objective(preprocess(BGAN.generator(feat, 0.7)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%time\n",
    "from hessian import hessian\n",
    "H_act = hessian(act, feat)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% < 60 sec for this computation\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%time\n",
    "eigval, eigvec = np.linalg.eigh(H_act.cpu().numpy())\n",
    "plt.plot(sorted(eigval))\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.hist(eigval, bins=30, log=True)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "del objective"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Above, we have proved that we can compute hessian for BigGAN by backprop 2 times and we can find its spectrum. \n",
    "\n",
    "Next, I'd like to examine its spectrum in noise space and code space"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "onehot = torch.zeros(1, 1000).requires_grad_(False)\n",
    "onehot[0, 1] = 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "classvec = BGAN.embeddings(onehot.cuda())\n",
    "noisevec = torch.from_numpy(truncated_noise_sample(1, 128, 0.6))\n",
    "#%\n",
    "img = BGAN.generator(torch.cat((noisevec.cuda(), classvec, ), dim=1), 0.6)\n",
    "#%\n",
    "plt.imshow((img.cpu().permute(2,3,1,0).squeeze() + 1.0) / 2.0)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "classvec = BGAN.embeddings(onehot.cuda())\n",
    "noisevec = torch.from_numpy(truncated_noise_sample(1, 128, 0.6)).cuda()\n",
    "classvec.requires_grad_(True)\n",
    "img = BGAN.generator(torch.cat((noisevec, classvec, ), dim=1), 0.6)\n",
    "act = alexnet(preprocess_resize(img))[0,1]\n",
    "plt.imshow((img.detach().cpu().permute(2,3,1,0).squeeze() + 1.0) / 2.0)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%time\n",
    "H_class = hessian(act, classvec)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "act.backward()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "onehot = torch.zeros(1, 1000).requires_grad_(False)\n",
    "onehot[0, 1] = 1\n",
    "classvec = BGAN.embeddings(onehot.cuda())\n",
    "noisevec = torch.from_numpy(truncated_noise_sample(1, 128, 0.6)).cuda()\n",
    "alexnet.train(True)\n",
    "classvec.requires_grad_(True)\n",
    "print(classvec.norm())\n",
    "optimizer = optim.Adam([classvec], lr=1.5E-3)\n",
    "for step in range(200):\n",
    "    optimizer.zero_grad()\n",
    "    img = BGAN.generator(torch.cat((noisevec, classvec, ), dim=1), 0.6)\n",
    "    obj =  - alexnet(preprocess_resize(img))[0,1]\n",
    "    obj.backward()\n",
    "    optimizer.step()\n",
    "    if np.mod((step + 1), 10) == 0:\n",
    "        print(\"step %d: %.2f\"%(step, obj.item()))\n",
    "        plt.imshow((img.detach().cpu().permute(2,3,1,0).squeeze() + 1.0) / 2.0)\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "print(classvec.norm())\n",
    "img = BGAN.generator(torch.cat((noisevec, classvec, ), dim=1), 0.6)\n",
    "act = alexnet(preprocess_resize(img))[0,1]\n",
    "plt.imshow((img.detach().cpu().permute(2,3,1,0).squeeze() + 1.0) / 2.0)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "alexnet.eval()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "classvec.grad.norm() / classvec.norm()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "classvec.norm()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%time\n",
    "classvec.requires_grad_(True)\n",
    "noisevec.requires_grad_(False)\n",
    "img = BGAN.generator(torch.cat((noisevec, classvec, ), dim=1), 0.6)\n",
    "act =  - alexnet(preprocess_resize(img))[0,1]\n",
    "H_act_class = get_full_hessian(act, classvec)\n",
    "#%\n",
    "eigval_class, eigvec_class = np.linalg.eigh(H_act_class)\n",
    "plt.plot(sorted(eigval_class))\n",
    "plt.show()\n",
    "plt.hist(eigval_class, bins=30, log=True)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "savedir = r\"E:\\OneDrive - Washington University in St. Louis\\HessTune\\BigGAN\"\n",
    "# objective = lambda img, scaler: alexnet(img)[:,1].mean() if scaler else alexnet(img)[:,1]\n",
    "alexnet.eval()\n",
    "objective = FeatLinModel(alexnet, layername=\"classifier_6\", type=\"neuron\", chan=1, pos=(1,1))\n",
    "ref_vect = torch.cat((noisevec.detach(), classvec.detach(), ), dim=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "img_list, scores_col = tuning_plot_BigGAN(BGAN, preprocess_resize, objective, \n",
    "            ref_vect, eigval_class, eigvec_class, eig_id_arr=(1,2,3,4,5,6,7,8,9,10, 20, 30, 40, 50, 60, 70, 80, 100, 110, 120), \n",
    "            space=\"class\", ticks=11, lim=(-2,2), summary_dir=savedir)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sort_idx = np.argsort(eigval_class)\n",
    "img_list, scores_col = tuning_plot_BigGAN(BGAN, preprocess_resize, objective, \n",
    "            ref_vect, eigval_class, eigvec_class, eig_id_arr=sort_idx[-15:], \n",
    "            space=\"class\", ticks=15, lim=(-1,1), summary_dir=savedir)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sort_idx = np.argsort(np.abs(eigval_class))\n",
    "img_list, scores_col = tuning_plot_BigGAN(BGAN, preprocess_resize, objective, \n",
    "            ref_vect, eigval_class, eigvec_class, eig_id_arr=sort_idx[:15], \n",
    "            space=\"class\", ticks=15, lim=(-1,1), summary_dir=savedir)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "del BGAN, alexnet, objective\n",
    "torch.cuda.empty_cache()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "del act\n",
    "torch.cuda.empty_cache()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "RGB_mean = torch.tensor([0.485, 0.456, 0.406]).view(1,-1,1,1).cuda()\n",
    "RGB_std  = torch.tensor([0.229, 0.224, 0.225]).view(1,-1,1,1).cuda()\n",
    "preprocess = Compose([lambda img: (F.interpolate(img, (224, 224), mode='bilinear', align_corners=True) - RGB_mean) / RGB_std])\n",
    "objective = FeatLinModel(alexnet, layername=\"classifier_6\", type=\"neuron\", chan=1, pos=(1, 1))\n",
    "ref_vect = torch.cat((noisevec, classvec, ), dim=1).detach().clone()\n",
    "BGANHVP = GANForwardHVPOperator(G, ref_vect, objective, preprocess=preprocess)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%time\n",
    "t0 = time()\n",
    "eigvals, eigvects = lanczos(BGANHVP, num_eigenthings=128, use_gpu=True)\n",
    "print(time() - t0)  # 40 sec 146sec for 2000 eigens\n",
    "eigvals = eigvals[::-1]\n",
    "eigvects = eigvects[::-1, :]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "eigval_fullfor = eigvals\n",
    "eigvec_fullfor = eigvects\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sort_idx = np.argsort(np.abs(eigval_fullfor))\n",
    "img_list, scores_col = tuning_plot_BigGAN(BGAN, preprocess_resize, objective, \n",
    "            ref_vect, eigval_fullfor, eigvec_fullfor, eig_id_arr=sort_idx[-15:], \n",
    "            space=\"full\", ticks=15, lim=(-1,1), summary_dir=savedir, veclabel=\"eig_forward_full\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sort_idx = np.argsort(np.abs(eigval_fullfor))\n",
    "img_list, scores_col = tuning_plot_BigGAN(BGAN, preprocess_resize, objective, \n",
    "            ref_vect, eigval_fullfor, eigvec_fullfor, eig_id_arr=sort_idx[:15], \n",
    "            space=\"full\", ticks=15, lim=(-1,1), summary_dir=savedir, veclabel=\"eig_forward_full\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sort_idx = np.argsort(-np.abs(eigval_fullfor))\n",
    "img_list, scores_col = tuning_plot_BigGAN(BGAN, preprocess_resize, objective, \n",
    "            ref_vect, eigval_fullfor, eigvec_fullfor, eig_id_arr=sort_idx, \n",
    "            space=\"full\", ticks=15, lim=(-1,1), summary_dir=savedir, veclabel=\"eig_forward_full\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Finally, I'll run this analysis in multiple classes and see the tuning and invariance. For the purpose I'll extract\n",
    "the embedding matrix `embed_mat` first and generate a bunch of classes to experiment with."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "RGB_mean = torch.tensor([0.485, 0.456, 0.406]).view(1,-1,1,1).cuda()\n",
    "RGB_std  = torch.tensor([0.229, 0.224, 0.225]).view(1,-1,1,1).cuda()\n",
    "preprocess = Compose([lambda img: (F.interpolate(img, (224, 224), mode='bilinear', align_corners=True) - RGB_mean) / RGB_std])\n",
    "\n",
    "embed_mat = BGAN.embeddings.parameters().__next__()\n",
    "class_id = 1\n",
    "embed_mat[:,class_id:class_id+1].T\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "list(sorted(np.random.randint(1000, size=(20))))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Choose some random classes\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%time\n",
    "class_id = 1\n",
    "for class_id in [17, 79, 95, 107, 224, 346, 493, 542, 579, 637, 667, 754, 761, 805, 814, 847, 856, 941, 954, 968]:#[2, 10, 113, 459, 517, 663, 754, 787, 857, 998]:\n",
    "    t0 = time()\n",
    "    classvec = embed_mat[:,class_id:class_id+1].T\n",
    "    noisevec = torch.from_numpy(truncated_noise_sample(1, 128, 0.6)).cuda()\n",
    "    ref_vect = torch.cat((noisevec, classvec, ), dim=1).detach().clone()\n",
    "    objective = FeatLinModel(alexnet, layername=\"classifier_6\", type=\"neuron\", chan=class_id, pos=(1, 1))\n",
    "\n",
    "    BGANHVP = GANForwardHVPOperator(G, ref_vect, objective, preprocess=preprocess)\n",
    "    \n",
    "    eigval_fullfor, eigvec_fullfor = lanczos(BGANHVP, num_eigenthings=128, use_gpu=True)\n",
    "    print(time() - t0, \" Finish Forward Hessian Decompostion\")# 40 sec 146sec for 2000 eigens\n",
    "    eigval_fullfor = eigval_fullfor[::-1]\n",
    "    eigvec_fullfor = eigvec_fullfor[::-1, :]\n",
    "\n",
    "    sort_idx = np.argsort(-np.abs(eigval_fullfor))\n",
    "    img_list, scores_col = tuning_plot_BigGAN(BGAN, preprocess_resize, objective, \n",
    "                ref_vect, eigval_fullfor, eigvec_fullfor, eig_id_arr=sort_idx, \n",
    "                space=\"full\", ticks=15, lim=(-1.5,1.5), summary_dir=savedir, veclabel=\"eig_forward_full_cls%d\"%(class_id))\n",
    "    print(time() - t0, \" Finish output images Decompostion\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Batch processing\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sort_idx = np.argsort(np.abs(eigval_fullfor))\n",
    "img_list, scores_col = tuning_plot_BigGAN(BGAN, preprocess_resize, objective, \n",
    "            ref_vect, eigval_fullfor, eigvec_fullfor, eig_id_arr=sort_idx[-15:], \n",
    "            space=\"full\", ticks=15, lim=(-1,1), summary_dir=savedir, veclabel=\"eig_forward_full\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sort_idx = np.argsort(np.abs(eigval_fullfor))\n",
    "img_list, scores_col = tuning_plot_BigGAN(BGAN, preprocess_resize, objective, \n",
    "            ref_vect, eigval_fullfor, eigvec_fullfor, eig_id_arr=sort_idx[:15], \n",
    "            space=\"full\", ticks=15, lim=(-1,1), summary_dir=savedir, veclabel=\"eig_forward_full\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sort_idx = np.argsort(-np.abs(eigval_fullfor))\n",
    "img_list, scores_col = tuning_plot_BigGAN(BGAN, preprocess_resize, objective, \n",
    "            ref_vect, eigval_fullfor, eigvec_fullfor, eig_id_arr=sort_idx, \n",
    "            space=\"full\", ticks=15, lim=(-1,1), summary_dir=savedir, veclabel=\"eig_forward_full\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The next step is to see is there any invariance / tuning in the intermediate neurons."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "embed_mat = BGAN.embeddings.parameters().__next__()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "alexnet.eval()#train(True)\n",
    "unit_id = 12\n",
    "objective = FeatLinModel(alexnet, layername='classifier_1', type=\"neuron\", chan=unit_id, pos=(1, 1))\n",
    "\n",
    "rndclassvec = torch.randn(1, 128)\n",
    "rndclassvec = rndclassvec / rndclassvec.norm() * 0.67\n",
    "noisevec = truncated_noise_sample(batch_size=1, dim_z=128, truncation=0.6)\n",
    "noisevec = torch.from_numpy(noisevec)\n",
    "ref_vect = torch.cat((noisevec, rndclassvec), dim=1).detach().clone()\n",
    "ref_vect = ref_vect.cuda().requires_grad_(True)\n",
    "print(ref_vect[0,:128].norm().item(), \" \", ref_vect[0,128:].norm().item())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# rndclassvec.requires_grad_(True)\n",
    "# noisevec.requires_grad_(True)\n",
    "optimizer = optim.Adam([ref_vect], lr=1.5E-3)\n",
    "step = 0\n",
    "trial = 0\n",
    "MAXTRY = 100\n",
    "while step <= 200:\n",
    "    optimizer.zero_grad()\n",
    "#     img = BGAN.generator(ref_vect, 0.6)\n",
    "    img = G.visualize(ref_vect)\n",
    "    obj = objective(preprocess(img))\n",
    "    obj.backward()\n",
    "    optimizer.step()\n",
    "    if ref_vect.grad.norm() < 1E-6:\n",
    "        rndclassvec =  torch.randn(1, 128) / np.sqrt(128) * 0.67\n",
    "        noisevec = torch.from_numpy(truncated_noise_sample(batch_size=1, dim_z=128, truncation=0.6))\n",
    "        ref_vect = torch.cat((noisevec, rndclassvec), dim=1).detach().clone()\n",
    "        ref_vect = ref_vect.cuda().requires_grad_(True)\n",
    "        optimizer = optim.Adam([ref_vect], lr=1.5E-3)\n",
    "        print(\"No gradient, Restart optimizer from another spot.\")\n",
    "        step = 0\n",
    "        trial += 1\n",
    "        if trial > MAXTRY:\n",
    "            break\n",
    "    if np.mod((step + 1), 10) == 0:\n",
    "        print(\"step %d: %.2f  Norm: Noise %.1f Class %.3f\"%(step, obj.item(), \n",
    "                ref_vect[0,:128].norm().item(), ref_vect[0,128:].norm().item()))\n",
    "    step += 1\n",
    "#         plt.imshow((img.detach().cpu().permute(2,3,1,0).squeeze() + 1.0) / 2.0)\n",
    "#         plt.axis('off')\n",
    "#         plt.show()\n",
    "with torch.no_grad():\n",
    "    img = G.visualize(ref_vect)\n",
    "    act = objective(preprocess(img))\n",
    "plt.imshow(img.detach().cpu().permute(2,3,1,0).squeeze())\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "alexnet.eval()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "(rndclassvec.abs() / rndclassvec.grad.abs()).median()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "(noisevec.abs() / noisevec.grad.abs()).median()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for param in alexnet.parameters():\n",
    "    param.requires_grad_(False)\n",
    "unit_id = 12\n",
    "objective = FeatLinModel(alexnet, layername='classifier_1', type=\"neuron\", chan=unit_id, pos=(1, 1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "embed_mat[:, np.random.randint(1000)].unsqueeze(0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rndclassvec"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "success=False\n",
    "trial = 0\n",
    "MAXTRY = 100\n",
    "while not success: #  or trial < MAXTRY\n",
    "#     rndclassvec = torch.randn(1, 128).cuda() / np.sqrt(128) * 0.67\n",
    "    rndclassvec = embed_mat[:, np.random.randint(1000)].unsqueeze(0).clone().cuda()\n",
    "    noisevec = torch.from_numpy(truncated_noise_sample(batch_size=1, dim_z=128, truncation=0.6)).cuda()\n",
    "#     ref_vect = torch.cat((noisevec, rndclassvec), dim=1).detach().clone()\n",
    "    rndclassvec.requires_grad_(True)\n",
    "    noisevec.requires_grad_(True)\n",
    "    print(rndclassvec.norm().item(), \" \", noisevec.norm().item())\n",
    "    optimizer_cls = optim.Adam([rndclassvec], lr=1.5E-3, weight_decay=1E-4)\n",
    "    optimizer_noise = optim.Adam([noisevec], lr=1.5E-3, weight_decay=1E-4)\n",
    "\n",
    "    for step in range(200):\n",
    "        optimizer_cls.zero_grad()\n",
    "#         optimizer_noise.zero_grad()\n",
    "    #     img = BGAN.generator(ref_vect, 0.6)\n",
    "        img = G.visualize(torch.cat((noisevec, rndclassvec), dim=1)) # ref_vect)\n",
    "        obj = objective(preprocess(img))\n",
    "        obj.backward()\n",
    "        optimizer_cls.step()\n",
    "        optimizer_noise.step()\n",
    "        if noisevec.grad.norm() < 1E-6 and rndclassvec.grad.norm() < 1E-6:\n",
    "            print(\"No gradient, Restart optimizer from another spot.\")\n",
    "            trial += 1\n",
    "            break\n",
    "        else:\n",
    "            success = True\n",
    "        if np.mod((step + 1), 10) == 0:\n",
    "            print(\"step %d: %.2f  Norm: Noise %.1f Class %.3f\"%(step, obj.item(), \n",
    "                    noisevec.norm().item(), rndclassvec.norm().item()))\n",
    "            print(\"Grad Amp Ratio Class %.2E, Noise %.2E\"% \n",
    "            ((rndclassvec.grad.abs() / rndclassvec.abs()).median().item(), (noisevec.grad.abs() / noisevec.abs()).median().item()))\n",
    "    #         plt.imshow((img.detach().cpu().permute(2,3,1,0).squeeze() + 1.0) / 2.0)\n",
    "    #         plt.axis('off')\n",
    "    #         plt.show()\n",
    "    if trial > MAXTRY:\n",
    "        break\n",
    "\n",
    "if not success: print(\"Optimization failed too many times, have a rest! \")\n",
    "\n",
    "with torch.no_grad():\n",
    "    img = G.visualize(torch.cat((noisevec, rndclassvec), dim=1))\n",
    "    act = objective(preprocess(img))\n",
    "plt.imshow(img.detach().cpu().permute(2,3,1,0).squeeze())\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "# alexnet.eval()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "unit_id = 1\n",
    "for unit_id in [17, ]:#[2, 10, 113, 459, 517, 663, 754, 787, 857, 998]:\n",
    "    t0 = time()\n",
    "    classvec = embed_mat[:,class_id:class_id+1].T\n",
    "    noisevec = torch.from_numpy(truncated_noise_sample(1, 128, 0.6)).cuda()\n",
    "    ref_vect = torch.cat((noisevec, classvec, ), dim=1).detach().clone()\n",
    "\n",
    "    objective = FeatLinModel(alexnet, layername=\"classifier_6\", type=\"neuron\", chan=unit_id, pos=(1, 1))\n",
    "    BGANHVP = GANForwardHVPOperator(G, ref_vect, objective, preprocess=preprocess)\n",
    "\n",
    "    eigval_fullfor, eigvec_fullfor = lanczos(BGANHVP, num_eigenthings=128, use_gpu=True)\n",
    "    print(time() - t0, \" Finish Forward Hessian Decompostion\")# 40 sec 146sec for 2000 eigens\n",
    "    eigval_fullfor = eigval_fullfor[::-1]\n",
    "    eigvec_fullfor = eigvec_fullfor[::-1, :]\n",
    "\n",
    "    sort_idx = np.argsort(-np.abs(eigval_fullfor))\n",
    "    img_list, scores_col = tuning_plot_BigGAN(BGAN, preprocess_resize, objective,\n",
    "                ref_vect, eigval_fullfor, eigvec_fullfor, eig_id_arr=sort_idx,\n",
    "                space=\"full\", ticks=15, lim=(-1.5,1.5), summary_dir=savedir, veclabel=\"eig_forward_fc6_%d\"%(unit_id))\n",
    "    print(time() - t0, \" Finish output images Decompostion\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def BigGAN_optim_result(param):\n",
    "    lr_cls = 10**param[0, 0] # 1.5E-3\n",
    "    wd_cls = 10**param[0, 1]\n",
    "    lr_ns = 10**param[0, 2]\n",
    "    wd_ns = 10**param[0, 3]\n",
    "    success=False\n",
    "    trial = 0\n",
    "    MAXTRY = 100\n",
    "    while not success: #  or trial < MAXTRY\n",
    "    #     rndclassvec = torch.randn(1, 128).cuda() / np.sqrt(128) * 0.67\n",
    "        rndclassvec = embed_mat[:, np.random.randint(1000)].unsqueeze(0).clone().cuda()\n",
    "        noisevec = torch.from_numpy(truncated_noise_sample(batch_size=1, dim_z=128, truncation=0.6)).cuda()\n",
    "    #     ref_vect = torch.cat((noisevec, rndclassvec), dim=1).detach().clone()\n",
    "        rndclassvec.requires_grad_(True)\n",
    "        noisevec.requires_grad_(True)\n",
    "#         print(rndclassvec.norm().item(), \" \", noisevec.norm().item())\n",
    "        optimizer_cls = optim.Adam([rndclassvec], lr=lr_cls, weight_decay=wd_cls) \n",
    "        optimizer_noise = optim.Adam([noisevec], lr=lr_ns, weight_decay=wd_ns)\n",
    "\n",
    "        for step in range(200):\n",
    "            optimizer_cls.zero_grad()\n",
    "            img = G.visualize(torch.cat((noisevec, rndclassvec), dim=1)) # ref_vect)\n",
    "            obj = objective(preprocess(img))\n",
    "            obj.backward()\n",
    "            optimizer_cls.step()\n",
    "            optimizer_noise.step()\n",
    "            if noisevec.grad.norm() < 1E-6 and rndclassvec.grad.norm() < 1E-6:\n",
    "                print(\"No gradient, Restart optimizer from another spot.\")\n",
    "                trial += 1\n",
    "                break\n",
    "            else:\n",
    "                success = True\n",
    "            if np.mod((step + 1), 20) == 0:\n",
    "                print(\"step %d: %.2f  Norm: Noise %.1f Class %.3f\"%(step, obj.item(), \n",
    "                        noisevec.norm().item(), rndclassvec.norm().item()))\n",
    "                print(\"Grad Amp Ratio Class %.2E, Noise %.2E\"% \n",
    "                ((rndclassvec.grad.abs() / rndclassvec.abs()).median().item(), (noisevec.grad.abs() / noisevec.abs()).median().item()))\n",
    "        if trial > MAXTRY:\n",
    "            break\n",
    "    if not success: \n",
    "        print(\"Optimization failed too many times, have a rest! \")\n",
    "        return np.nan\n",
    "    else:\n",
    "        return obj.detach().cpu().item()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "BigGAN_optim_result(np.array([[-3.0,-4,-3,-4]]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import GPy\n",
    "import GPyOpt\n",
    "from GPyOpt.methods import BayesianOptimization"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import GPy\n",
    "import GPyOpt\n",
    "from GPyOpt.methods import BayesianOptimization\n",
    "mixed_domain =[{'name': 'lr_class', 'type': 'continuous', 'domain': (-4, -1.5),'dimensionality': 1},\n",
    "               {'name': 'wd_class', 'type': 'continuous', 'domain': (-6, -2),'dimensionality': 1},\n",
    "               {'name': 'lr_noise', 'type': 'continuous', 'domain': (-4, -1.5),'dimensionality': 1},\n",
    "               {'name': 'wd_noise', 'type': 'continuous', 'domain': (-6, -2),'dimensionality': 1},]\n",
    "#                {'name': 'var3', 'type': 'discrete', 'domain': (3,8,10),'dimensionality': 1},]\n",
    "#                {'name': 'var4', 'type': 'categorical', 'domain': (0,1,2),'dimensionality': 1},\n",
    "#                {'name': 'var5', 'type': 'continuous', 'domain': (-1,2),'dimensionality': 1}]\n",
    "myBopt = BayesianOptimization(f=optim_result,                     # Objective function       \n",
    "                             domain=mixed_domain,          # Box-constraints of the problem\n",
    "                             initial_design_numdata = 5,   # Number data initial design\n",
    "                             acquisition_optimizer_type='lbfgs',\n",
    "                             acquisition_type='EI',        # Expected Improvement\n",
    "                             exact_feval = False,         # True evaluations, no sample noise\n",
    "                             maximize=False)           "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "max_iter = 50       ## maximum number of iterations\n",
    "max_time = 3600      ## maximum allowed time\n",
    "eps      = 1e-6     ## tolerance, max distance between consicutive evaluations.\n",
    "myBopt.run_optimization(max_iter,eps=0,ver)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "max_iter = 50       ## maximum number of iterations\n",
    "max_time = 3600      ## maximum allowed time\n",
    "eps      = 1e-6     ## tolerance, max distance between consicutive evaluations.\n",
    "myBopt.run_optimization(max_iter,eps=0,ver)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def BigGAN_optim_result(param):\n",
    "    lr_cls = 10**param[0, 0] # 1.5E-3\n",
    "    wd_cls = 10**param[0, 1]\n",
    "    lr_ns = 10**param[0, 2]\n",
    "    wd_ns = 10**param[0, 3]\n",
    "    success=False\n",
    "    trial = 0\n",
    "    MAXTRY = 100\n",
    "    while not success: #  or trial < MAXTRY\n",
    "    #     rndclassvec = torch.randn(1, 128).cuda() / np.sqrt(128) * 0.67\n",
    "        rndclassvec = embed_mat[:, np.random.randint(1000)].unsqueeze(0).clone().cuda()\n",
    "        noisevec = torch.from_numpy(truncated_noise_sample(batch_size=1, dim_z=128, truncation=0.6)).cuda()\n",
    "    #     ref_vect = torch.cat((noisevec, rndclassvec), dim=1).detach().clone()\n",
    "        rndclassvec.requires_grad_(True)\n",
    "        noisevec.requires_grad_(True)\n",
    "#         print(rndclassvec.norm().item(), \" \", noisevec.norm().item())\n",
    "        optimizer_cls = optim.Adam([rndclassvec], lr=lr_cls, weight_decay=wd_cls) \n",
    "        optimizer_noise = optim.Adam([noisevec], lr=lr_ns, weight_decay=wd_ns)\n",
    "\n",
    "        for step in range(200):\n",
    "            optimizer_cls.zero_grad()\n",
    "            img = G.visualize(torch.cat((noisevec, rndclassvec), dim=1)) # ref_vect)\n",
    "            obj = objective(preprocess(img))\n",
    "            obj.backward()\n",
    "            optimizer_cls.step()\n",
    "            optimizer_noise.step()\n",
    "            if noisevec.grad.norm() < 1E-6 and rndclassvec.grad.norm() < 1E-6:\n",
    "                print(\"No gradient, Restart optimizer from another spot.\")\n",
    "                trial += 1\n",
    "                break\n",
    "            else:\n",
    "                success = True\n",
    "            if np.mod((step + 1), 20) == 0:\n",
    "                print(\"step %d: %.2f  Norm: Noise %.1f Class %.3f\"%(step, obj.item(), \n",
    "                        noisevec.norm().item(), rndclassvec.norm().item()))\n",
    "                print(\"Grad Amp Ratio Class %.2E, Noise %.2E\"% \n",
    "                ((rndclassvec.grad.abs() / rndclassvec.abs()).median().item(), (noisevec.grad.abs() / noisevec.abs()).median().item()))\n",
    "        if trial > MAXTRY:\n",
    "            break\n",
    "    if not success: \n",
    "        print(\"Optimization failed too many times, have a rest! \")\n",
    "        return np.nan\n",
    "    else:\n",
    "        return obj.detach().cpu().item()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "BigGAN_optim_result(np.array([[-3.0,-4,-3,-4]]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import GPy\n",
    "import GPyOpt\n",
    "from GPyOpt.methods import BayesianOptimization"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import GPy\n",
    "import GPyOpt\n",
    "from GPyOpt.methods import BayesianOptimization\n",
    "mixed_domain =[{'name': 'lr_class', 'type': 'continuous', 'domain': (-4, -1.5),'dimensionality': 1},\n",
    "               {'name': 'wd_class', 'type': 'continuous', 'domain': (-6, -2),'dimensionality': 1},\n",
    "               {'name': 'lr_noise', 'type': 'continuous', 'domain': (-4, -1.5),'dimensionality': 1},\n",
    "               {'name': 'wd_noise', 'type': 'continuous', 'domain': (-6, -2),'dimensionality': 1},]\n",
    "#                {'name': 'var3', 'type': 'discrete', 'domain': (3,8,10),'dimensionality': 1},]\n",
    "#                {'name': 'var4', 'type': 'categorical', 'domain': (0,1,2),'dimensionality': 1},\n",
    "#                {'name': 'var5', 'type': 'continuous', 'domain': (-1,2),'dimensionality': 1}]\n",
    "myBopt = BayesianOptimization(f=optim_result,                     # Objective function       \n",
    "                             domain=mixed_domain,          # Box-constraints of the problem\n",
    "                             initial_design_numdata = 5,   # Number data initial design\n",
    "                             acquisition_optimizer_type='lbfgs',\n",
    "                             acquisition_type='EI',        # Expected Improvement\n",
    "                             exact_feval = False,         # True evaluations, no sample noise\n",
    "                             maximize=False)           "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "max_iter = 50       ## maximum number of iterations\n",
    "max_time = 3600      ## maximum allowed time\n",
    "eps      = 1e-6     ## tolerance, max distance between consicutive evaluations.\n",
    "myBopt.run_optimization(max_iter,eps=0,ver)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "max_iter = 50       ## maximum number of iterations\n",
    "max_time = 3600      ## maximum allowed time\n",
    "eps      = 1e-6     ## tolerance, max distance between consicutive evaluations.\n",
    "myBopt.run_optimization(max_iter,eps=0,ver)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def BigGAN_optim_result(param):\n",
    "    lr_cls = 10**param[0, 0] # 1.5E-3\n",
    "    wd_cls = 10**param[0, 1]\n",
    "    lr_ns = 10**param[0, 2]\n",
    "    wd_ns = 10**param[0, 3]\n",
    "    success=False\n",
    "    trial = 0\n",
    "    MAXTRY = 100\n",
    "    while not success: #  or trial < MAXTRY\n",
    "    #     rndclassvec = torch.randn(1, 128).cuda() / np.sqrt(128) * 0.67\n",
    "        rndclassvec = embed_mat[:, np.random.randint(1000)].unsqueeze(0).clone().cuda()\n",
    "        noisevec = torch.from_numpy(truncated_noise_sample(batch_size=1, dim_z=128, truncation=0.6)).cuda()\n",
    "    #     ref_vect = torch.cat((noisevec, rndclassvec), dim=1).detach().clone()\n",
    "        rndclassvec.requires_grad_(True)\n",
    "        noisevec.requires_grad_(True)\n",
    "#         print(rndclassvec.norm().item(), \" \", noisevec.norm().item())\n",
    "        optimizer_cls = optim.Adam([rndclassvec], lr=lr_cls, weight_decay=wd_cls) \n",
    "        optimizer_noise = optim.Adam([noisevec], lr=lr_ns, weight_decay=wd_ns)\n",
    "\n",
    "        for step in range(200):\n",
    "            optimizer_cls.zero_grad()\n",
    "            img = G.visualize(torch.cat((noisevec, rndclassvec), dim=1)) # ref_vect)\n",
    "            obj = objective(preprocess(img))\n",
    "            obj.backward()\n",
    "            optimizer_cls.step()\n",
    "            optimizer_noise.step()\n",
    "            if noisevec.grad.norm() < 1E-6 and rndclassvec.grad.norm() < 1E-6:\n",
    "                print(\"No gradient, Restart optimizer from another spot.\")\n",
    "                trial += 1\n",
    "                break\n",
    "            else:\n",
    "                success = True\n",
    "            if np.mod((step + 1), 20) == 0:\n",
    "                print(\"step %d: %.2f  Norm: Noise %.1f Class %.3f\"%(step, obj.item(), \n",
    "                        noisevec.norm().item(), rndclassvec.norm().item()))\n",
    "                print(\"Grad Amp Ratio Class %.2E, Noise %.2E\"% \n",
    "                ((rndclassvec.grad.abs() / rndclassvec.abs()).median().item(), (noisevec.grad.abs() / noisevec.abs()).median().item()))\n",
    "        if trial > MAXTRY:\n",
    "            break\n",
    "    if not success: \n",
    "        print(\"Optimization failed too many times, have a rest! \")\n",
    "        return np.nan\n",
    "    else:\n",
    "        return obj.detach().cpu().item()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "BigGAN_optim_result(np.array([[-3.0,-4,-3,-4]]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import GPy\n",
    "import GPyOpt\n",
    "from GPyOpt.methods import BayesianOptimization"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import GPy\n",
    "import GPyOpt\n",
    "from GPyOpt.methods import BayesianOptimization\n",
    "mixed_domain =[{'name': 'lr_class', 'type': 'continuous', 'domain': (-4, -1.5),'dimensionality': 1},\n",
    "               {'name': 'wd_class', 'type': 'continuous', 'domain': (-6, -2),'dimensionality': 1},\n",
    "               {'name': 'lr_noise', 'type': 'continuous', 'domain': (-4, -1.5),'dimensionality': 1},\n",
    "               {'name': 'wd_noise', 'type': 'continuous', 'domain': (-6, -2),'dimensionality': 1},]\n",
    "#                {'name': 'var3', 'type': 'discrete', 'domain': (3,8,10),'dimensionality': 1},]\n",
    "#                {'name': 'var4', 'type': 'categorical', 'domain': (0,1,2),'dimensionality': 1},\n",
    "#                {'name': 'var5', 'type': 'continuous', 'domain': (-1,2),'dimensionality': 1}]\n",
    "myBopt = BayesianOptimization(f=optim_result,                     # Objective function       \n",
    "                             domain=mixed_domain,          # Box-constraints of the problem\n",
    "                             initial_design_numdata = 5,   # Number data initial design\n",
    "                             acquisition_optimizer_type='lbfgs',\n",
    "                             acquisition_type='EI',        # Expected Improvement\n",
    "                             exact_feval = False,         # True evaluations, no sample noise\n",
    "                             maximize=False)           "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "max_iter = 50       ## maximum number of iterations\n",
    "max_time = 3600      ## maximum allowed time\n",
    "eps      = 1e-6     ## tolerance, max distance between consicutive evaluations.\n",
    "myBopt.run_optimization(max_iter,eps=0,ver)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "max_iter = 50       ## maximum number of iterations\n",
    "max_time = 3600      ## maximum allowed time\n",
    "eps      = 1e-6     ## tolerance, max distance between consicutive evaluations.\n",
    "myBopt.run_optimization(max_iter,eps=0,ver)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def BigGAN_optim_result(param):\n",
    "    lr_cls = 10**param[0, 0] # 1.5E-3\n",
    "    wd_cls = 10**param[0, 1]\n",
    "    lr_ns = 10**param[0, 2]\n",
    "    wd_ns = 10**param[0, 3]\n",
    "    success=False\n",
    "    trial = 0\n",
    "    MAXTRY = 100\n",
    "    while not success: #  or trial < MAXTRY\n",
    "    #     rndclassvec = torch.randn(1, 128).cuda() / np.sqrt(128) * 0.67\n",
    "        rndclassvec = embed_mat[:, np.random.randint(1000)].unsqueeze(0).clone().cuda()\n",
    "        noisevec = torch.from_numpy(truncated_noise_sample(batch_size=1, dim_z=128, truncation=0.6)).cuda()\n",
    "    #     ref_vect = torch.cat((noisevec, rndclassvec), dim=1).detach().clone()\n",
    "        rndclassvec.requires_grad_(True)\n",
    "        noisevec.requires_grad_(True)\n",
    "#         print(rndclassvec.norm().item(), \" \", noisevec.norm().item())\n",
    "        optimizer_cls = optim.Adam([rndclassvec], lr=lr_cls, weight_decay=wd_cls) \n",
    "        optimizer_noise = optim.Adam([noisevec], lr=lr_ns, weight_decay=wd_ns)\n",
    "\n",
    "        for step in range(200):\n",
    "            optimizer_cls.zero_grad()\n",
    "            img = G.visualize(torch.cat((noisevec, rndclassvec), dim=1)) # ref_vect)\n",
    "            obj = objective(preprocess(img))\n",
    "            obj.backward()\n",
    "            optimizer_cls.step()\n",
    "            optimizer_noise.step()\n",
    "            if noisevec.grad.norm() < 1E-6 and rndclassvec.grad.norm() < 1E-6:\n",
    "                print(\"No gradient, Restart optimizer from another spot.\")\n",
    "                trial += 1\n",
    "                break\n",
    "            else:\n",
    "                success = True\n",
    "            if np.mod((step + 1), 20) == 0:\n",
    "                print(\"step %d: %.2f  Norm: Noise %.1f Class %.3f\"%(step, obj.item(), \n",
    "                        noisevec.norm().item(), rndclassvec.norm().item()))\n",
    "                print(\"Grad Amp Ratio Class %.2E, Noise %.2E\"% \n",
    "                ((rndclassvec.grad.abs() / rndclassvec.abs()).median().item(), (noisevec.grad.abs() / noisevec.abs()).median().item()))\n",
    "        if trial > MAXTRY:\n",
    "            break\n",
    "    if not success: \n",
    "        print(\"Optimization failed too many times, have a rest! \")\n",
    "        return np.nan\n",
    "    else:\n",
    "        return obj.detach().cpu().item()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "BigGAN_optim_result(np.array([[-3.0,-4,-3,-4]]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import GPy\n",
    "import GPyOpt\n",
    "from GPyOpt.methods import BayesianOptimization"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import GPy\n",
    "import GPyOpt\n",
    "from GPyOpt.methods import BayesianOptimization\n",
    "mixed_domain =[{'name': 'lr_class', 'type': 'continuous', 'domain': (-4, -1.5),'dimensionality': 1},\n",
    "               {'name': 'wd_class', 'type': 'continuous', 'domain': (-6, -2),'dimensionality': 1},\n",
    "               {'name': 'lr_noise', 'type': 'continuous', 'domain': (-4, -1.5),'dimensionality': 1},\n",
    "               {'name': 'wd_noise', 'type': 'continuous', 'domain': (-6, -2),'dimensionality': 1},]\n",
    "#                {'name': 'var3', 'type': 'discrete', 'domain': (3,8,10),'dimensionality': 1},]\n",
    "#                {'name': 'var4', 'type': 'categorical', 'domain': (0,1,2),'dimensionality': 1},\n",
    "#                {'name': 'var5', 'type': 'continuous', 'domain': (-1,2),'dimensionality': 1}]\n",
    "myBopt = BayesianOptimization(f=optim_result,                     # Objective function       \n",
    "                             domain=mixed_domain,          # Box-constraints of the problem\n",
    "                             initial_design_numdata = 5,   # Number data initial design\n",
    "                             acquisition_optimizer_type='lbfgs',\n",
    "                             acquisition_type='EI',        # Expected Improvement\n",
    "                             exact_feval = False,         # True evaluations, no sample noise\n",
    "                             maximize=False)           "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "max_iter = 50       ## maximum number of iterations\n",
    "max_time = 3600      ## maximum allowed time\n",
    "eps      = 1e-6     ## tolerance, max distance between consicutive evaluations.\n",
    "myBopt.run_optimization(max_iter,eps=0,ver)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}