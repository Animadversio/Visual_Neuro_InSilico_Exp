{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import caffe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import join\n",
    "import torch\n",
    "import sys\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import sys\n",
    "sys.path.append(r\"/n/home12/binxuwang/Github/pytorch-caffe\")\n",
    "\n",
    "#%%\n",
    "# Depend on 2 packages, you should clone from\n",
    "# https://github.com/Animadversio/pytorch-receptive-field\n",
    "# https://github.com/Animadversio/pytorch-caffe.git\n",
    "# from sys import platform\n",
    "# if platform == \"linux\":  # CHPC cluster\n",
    "#     homedir = Path(os.path.expanduser('~'))\n",
    "#     netsdir = os.path.join(homedir, 'Generate_DB/nets')\n",
    "#     sys.path.append(join(homedir,\"pytorch-caffe\"))\n",
    "#     sys.path.append(join(homedir,\"pytorch-receptive-field\"))\n",
    "#     sys.path.append(join(homedir,\"PerceptualSimilarity\"))  # should be added there!)\n",
    "#     # ckpt_path = {\"vgg16\": \"/scratch/binxu/torch/vgg16-397923af.pth\"}\n",
    "# else:\n",
    "#     if os.environ['COMPUTERNAME'] == 'DESKTOP-9DDE2RH':  # PonceLab-Desktop 3\n",
    "#         sys.path.append(r\"D:\\Github\\pytorch-caffe\")\n",
    "#         sys.path.append(r\"D:\\Github\\pytorch-receptive-field\")\n",
    "#         sys.path.append(r\"D:\\Github\\PerceptualSimilarity\")\n",
    "#         homedir = \"D:/Generator_DB_Windows\"\n",
    "#         netsdir = os.path.join(homedir, 'nets')\n",
    "#     elif os.environ['COMPUTERNAME'] == 'PONCELAB-ML2C':  # PonceLab-Desktop Victoria\n",
    "#         sys.path.append(r\"C:\\Users\\ponce\\Documents\\GitHub\\pytorch-caffe\")\n",
    "#         sys.path.append(r\"C:\\Users\\ponce\\Documents\\GitHub\\pytorch-receptive-field\")\n",
    "#         homedir = r\"C:\\Users\\ponce\\Documents\\Generator_DB_Windows\"\n",
    "#         netsdir = os.path.join(homedir, 'nets')\n",
    "#     elif os.environ['COMPUTERNAME'] == 'DESKTOP-MENSD6S':  # Home_WorkStation\n",
    "#         sys.path.append(r\"E:\\Github_Projects\\pytorch-caffe\")\n",
    "#         sys.path.append(r\"E:\\Github_Projects\\pytorch-receptive-field\")\n",
    "#         sys.path.append(r\"E:\\Github_Projects\\PerceptualSimilarity\")\n",
    "#         homedir = \"E:/Monkey_Data/Generator_DB_Windows\"\n",
    "#         netsdir = os.path.join(homedir, 'nets')\n",
    "#     elif os.environ['COMPUTERNAME'] == 'DESKTOP-9LH02U9':  # Home_WorkStation Victoria\n",
    "#         sys.path.append(r\"C:\\Users\\zhanq\\OneDrive - Washington University in St. Louis\\GitHub\\pytorch-caffe\")\n",
    "#         sys.path.append(r\"C:\\Users\\zhanq\\OneDrive - Washington University in St. Louis\\GitHub\\pytorch-receptive-field\")\n",
    "#         homedir = \"C:/Users/zhanq/OneDrive - Washington University in St. Louis/Generator_DB_Windows\"\n",
    "#         netsdir = os.path.join(homedir, 'nets')\n",
    "#     else:\n",
    "#         sys.path.append(\"D:\\Github\\pytorch-caffe\")\n",
    "#         homedir = os.path.expanduser('~')\n",
    "#         netsdir = os.path.join(homedir, 'Documents/nets')\n",
    "netsdir = \"/n/holylfs06/LABS/kempner_fellow_binxuwang/Users/binxuwang/Projects/ReprInvertNet/DeePSim_orig/\" # release_deepsim_v0\n",
    "\n",
    "def GAN_path(name):\n",
    "    if name == \"fc6\":\n",
    "        save_path = os.path.join(netsdir, r\"upconv/fc6/generator_state_dict.pt\")\n",
    "        protofile = os.path.join(netsdir, r\"upconv/fc6/generator.prototxt\") \n",
    "        weightfile = os.path.join(netsdir, r'upconv/fc6/generator.caffemodel')\n",
    "    elif name == \"fc7\":\n",
    "        save_path = os.path.join(netsdir, r\"upconv/fc7/generator_state_dict.pt\")\n",
    "        protofile = os.path.join(netsdir, r\"upconv/fc7/generator.prototxt\")  \n",
    "        weightfile = os.path.join(netsdir, r'upconv/fc7/generator.caffemodel')  \n",
    "    elif name == \"fc8\":\n",
    "        save_path = os.path.join(netsdir, r\"upconv/fc8/generator_state_dict.pt\")\n",
    "        protofile = os.path.join(netsdir, r\"upconv/fc8/generator.prototxt\") \n",
    "        weightfile = os.path.join(netsdir, r'upconv/fc8/generator.caffemodel')\n",
    "    elif name == \"pool5\":\n",
    "        save_path = os.path.join(netsdir, r\"upconv/pool5/generator_state_dict.pt\")\n",
    "        protofile = os.path.join(netsdir, r\"upconv/pool5/generator.prototxt\") \n",
    "        weightfile = os.path.join(netsdir, r'upconv/pool5/generator.caffemodel')\n",
    "    elif name == \"conv4\":\n",
    "        save_path = os.path.join(netsdir, r\"upconv/conv4/generator_state_dict.pt\")\n",
    "        protofile = os.path.join(netsdir, r\"upconv/conv4/generator.prototxt\") \n",
    "        weightfile = os.path.join(netsdir, r'upconv/conv4/generator.caffemodel')\n",
    "    elif name == \"conv3\":\n",
    "        save_path = os.path.join(netsdir, r\"upconv/conv3/generator_state_dict.pt\")\n",
    "        protofile = os.path.join(netsdir, r\"upconv/conv3/generator.prototxt\") \n",
    "        weightfile = os.path.join(netsdir, r'upconv/conv3/generator.caffemodel')\n",
    "    elif name == \"norm2\":\n",
    "        save_path = os.path.join(netsdir, r\"upconv/norm2/generator_state_dict.pt\")\n",
    "        protofile = os.path.join(netsdir, r\"upconv/norm2/generator.prototxt\")  \n",
    "        weightfile = os.path.join(netsdir, r'upconv/norm2/generator.caffemodel')  \n",
    "    elif name == \"norm1\":\n",
    "        save_path = os.path.join(netsdir, r\"upconv/norm1/generator_state_dict.pt\")\n",
    "        protofile = os.path.join(netsdir, r\"upconv/norm1/generator.prototxt\")  \n",
    "        weightfile = os.path.join(netsdir, r'upconv/norm1/generator.caffemodel')  \n",
    "    elif name == \"caffenet\":\n",
    "        save_path = os.path.join(netsdir, r\"upconv/caffenet/caffenet_state_dict.pt\")\n",
    "        protofile = os.path.join(netsdir, r\"upconv/caffenet/caffenet.prototxt\")  \n",
    "        weightfile = os.path.join(netsdir, r'upconv/caffenet/caffenet.caffemodel')  \n",
    "    else:\n",
    "        raise ValueError(name + 'not defined')\n",
    "    return save_path, protofile, weightfile\n",
    "\n",
    "\n",
    "#%% Prepare PyTorch version of the Caffe networks\n",
    "def load_caffenet():\n",
    "    from caffenet import CaffeNet  # Pytorch-caffe converter\n",
    "    # protofile = join(netsdir, r\"caffenet\\caffenet.prototxt\")  # 'resnet50/deploy.prototxt'\n",
    "    # weightfile = join(netsdir, r'caffenet\\bvlc_reference_caffenet.caffemodel')  # 'resnet50/resnet50.caffemodel'\n",
    "    # save_path = join(netsdir, r\"caffenet\\caffenet_state_dict.pt\")\n",
    "    save_path, protofile, weightfile = GAN_path('caffenet')\n",
    "    net = CaffeNet(protofile)\n",
    "    print(net)\n",
    "    if os.path.exists(save_path):\n",
    "        net.load_state_dict(torch.load(save_path))\n",
    "    else:\n",
    "        net.load_weights(weightfile)\n",
    "        torch.save(net.state_dict(), save_path)\n",
    "    net.eval()\n",
    "    net.verbose = False\n",
    "    net.requires_grad_(requires_grad=False)\n",
    "    for param in net.parameters():\n",
    "        param.requires_grad = False\n",
    "    return net\n",
    "\n",
    "\n",
    "def load_generator(GAN=\"fc6\"):\n",
    "    from caffenet import CaffeNet  # Pytorch-caffe converter\n",
    "    # netsdir = r\"D:/Generator_DB_Windows/nets\"\n",
    "    save_path, protofile, weightfile = GAN_path(GAN)\n",
    "    Generator = CaffeNet(protofile)\n",
    "    print(Generator)\n",
    "    if os.path.exists(save_path):\n",
    "        Generator.load_state_dict(torch.load(save_path))\n",
    "    else:\n",
    "        Generator.load_weights(weightfile)\n",
    "        torch.save(Generator.state_dict(), save_path)  # Generator.\n",
    "    Generator.eval()\n",
    "    Generator.verbose = False\n",
    "    Generator.requires_grad_(requires_grad=False)\n",
    "    for param in Generator.parameters():\n",
    "        param.requires_grad = False\n",
    "    return Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create Rconv6               (  96 x   27 x   27) -> ( 128 x   15 x   15)\n",
      "create Rrelu6               ( 128 x   15 x   15) -> ( 128 x   15 x   15)\n",
      "create Rconv7               ( 128 x   15 x   15) -> ( 128 x   15 x   15)\n",
      "create Rrelu7               ( 128 x   15 x   15) -> ( 128 x   15 x   15)\n",
      "create Rconv8               ( 128 x   15 x   15) -> ( 128 x   15 x   15)\n",
      "create Rrelu8               ( 128 x   15 x   15) -> ( 128 x   15 x   15)\n",
      "create deconv4              ( 128 x   15 x   15) -> ( 128 x   30 x   30)\n",
      "create relu_deconv4         ( 128 x   30 x   30) -> ( 128 x   30 x   30)\n",
      "create conv4_1              ( 128 x   30 x   30) -> ( 128 x   30 x   30)\n",
      "create relu_conv4_1         ( 128 x   30 x   30) -> ( 128 x   30 x   30)\n",
      "create deconv3              ( 128 x   30 x   30) -> (  64 x   60 x   60)\n",
      "create relu_deconv3         (  64 x   60 x   60) -> (  64 x   60 x   60)\n",
      "create conv3_1              (  64 x   60 x   60) -> (  64 x   60 x   60)\n",
      "create relu_conv3_1         (  64 x   60 x   60) -> (  64 x   60 x   60)\n",
      "create deconv2              (  64 x   60 x   60) -> (  32 x  120 x  120)\n",
      "create relu_deconv2         (  32 x  120 x  120) -> (  32 x  120 x  120)\n",
      "create conv2_1              (  32 x  120 x  120) -> (  32 x  120 x  120)\n",
      "create relu_conv2_1         (  32 x  120 x  120) -> (  32 x  120 x  120)\n",
      "create deconv1              (  32 x  120 x  120) -> (  16 x  240 x  240)\n",
      "create conv1_1              (  16 x  240 x  240) -> (   3 x  240 x  240)\n",
      "create tanh                 (   3 x  240 x  240) -> (   3 x  240 x  240)\n",
      "create conv1_1_tanh         (   3 x  240 x  240) -> (   3 x  240 x  240)\n",
      "CaffeNet(\n",
      "  (Rconv6): Conv2d(96, 128, kernel_size=(3, 3), stride=(2, 2), padding=(2, 2))\n",
      "  (Rrelu6): LeakyReLU(negative_slope=0.3, inplace=True)\n",
      "  (Rconv7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (Rrelu7): LeakyReLU(negative_slope=0.3, inplace=True)\n",
      "  (Rconv8): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (Rrelu8): LeakyReLU(negative_slope=0.3, inplace=True)\n",
      "  (deconv4): ConvTranspose2d(128, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  (relu_deconv4): LeakyReLU(negative_slope=0.3, inplace=True)\n",
      "  (conv4_1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu_conv4_1): LeakyReLU(negative_slope=0.3, inplace=True)\n",
      "  (deconv3): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  (relu_deconv3): LeakyReLU(negative_slope=0.3, inplace=True)\n",
      "  (conv3_1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu_conv3_1): LeakyReLU(negative_slope=0.3, inplace=True)\n",
      "  (deconv2): ConvTranspose2d(64, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  (relu_deconv2): LeakyReLU(negative_slope=0.3, inplace=True)\n",
      "  (conv2_1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu_conv2_1): LeakyReLU(negative_slope=0.3, inplace=True)\n",
      "  (deconv1): ConvTranspose2d(32, 16, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  (conv1_1): Conv2d(16, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (tanh): Tanh()\n",
      "  (conv1_1_tanh): Eltwise SUM\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "Generator = load_generator('norm1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create conv1                (   3 x  227 x  227) -> (  96 x   55 x   55)\n",
      "create relu1                (  96 x   55 x   55) -> (  96 x   55 x   55)\n",
      "create pool1                (  96 x   55 x   55) -> (  96 x   27 x   27)\n",
      "create norm1                (  96 x   27 x   27) -> (  96 x   27 x   27)\n",
      "create conv2                (  96 x   27 x   27) -> ( 256 x   27 x   27)\n",
      "create relu2                ( 256 x   27 x   27) -> ( 256 x   27 x   27)\n",
      "create pool2                ( 256 x   27 x   27) -> ( 256 x   13 x   13)\n",
      "create norm2                ( 256 x   13 x   13) -> ( 256 x   13 x   13)\n",
      "create conv3                ( 256 x   13 x   13) -> ( 384 x   13 x   13)\n",
      "create relu3                ( 384 x   13 x   13) -> ( 384 x   13 x   13)\n",
      "create conv4                ( 384 x   13 x   13) -> ( 384 x   13 x   13)\n",
      "create relu4                ( 384 x   13 x   13) -> ( 384 x   13 x   13)\n",
      "create conv5                ( 384 x   13 x   13) -> ( 256 x   13 x   13)\n",
      "create relu5                ( 256 x   13 x   13) -> ( 256 x   13 x   13)\n",
      "create pool5                ( 256 x   13 x   13) -> ( 256 x    6 x    6)\n",
      "create fc6                  ( 256 x    6 x    6) -> (4096 x    1 x    1)\n",
      "create relu6                (4096 x    1 x    1) -> (4096 x    1 x    1)\n",
      "create fc7                  (4096 x    1 x    1) -> (4096 x    1 x    1)\n",
      "create relu7                (4096 x    1 x    1) -> (4096 x    1 x    1)\n",
      "create fc8                  (4096 x    1 x    1) -> (1000 x    1 x    1)\n",
      "CaffeNet(\n",
      "  (conv1): Conv2d(3, 96, kernel_size=(11, 11), stride=(4, 4))\n",
      "  (relu1): ReLU(inplace=True)\n",
      "  (pool1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "  (norm1): LocalResponseNorm(5, alpha=0.0001, beta=0.75, k=1.0)\n",
      "  (conv2): Conv2d(96, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=2)\n",
      "  (relu2): ReLU(inplace=True)\n",
      "  (pool2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "  (norm2): LocalResponseNorm(5, alpha=0.0001, beta=0.75, k=1.0)\n",
      "  (conv3): Conv2d(256, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu3): ReLU(inplace=True)\n",
      "  (conv4): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2)\n",
      "  (relu4): ReLU(inplace=True)\n",
      "  (conv5): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2)\n",
      "  (relu5): ReLU(inplace=True)\n",
      "  (pool5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "  (fc6): Sequential(\n",
      "    (0): view(nB, -1)\n",
      "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
      "  )\n",
      "  (relu6): ReLU(inplace=True)\n",
      "  (fc7): Sequential(\n",
      "    (0): view(nB, -1)\n",
      "    (1): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "  )\n",
      "  (relu7): ReLU(inplace=True)\n",
      "  (fc8): Sequential(\n",
      "    (0): view(nB, -1)\n",
      "    (1): Linear(in_features=4096, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "Generator = load_generator('caffenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create conv1                (   3 x  227 x  227) -> (  96 x   55 x   55)\n",
      "create relu1                (  96 x   55 x   55) -> (  96 x   55 x   55)\n",
      "create pool1                (  96 x   55 x   55) -> (  96 x   27 x   27)\n",
      "create norm1                (  96 x   27 x   27) -> (  96 x   27 x   27)\n",
      "create conv2                (  96 x   27 x   27) -> ( 256 x   27 x   27)\n",
      "create relu2                ( 256 x   27 x   27) -> ( 256 x   27 x   27)\n",
      "create pool2                ( 256 x   27 x   27) -> ( 256 x   13 x   13)\n",
      "create norm2                ( 256 x   13 x   13) -> ( 256 x   13 x   13)\n",
      "create conv3                ( 256 x   13 x   13) -> ( 384 x   13 x   13)\n",
      "create relu3                ( 384 x   13 x   13) -> ( 384 x   13 x   13)\n",
      "create conv4                ( 384 x   13 x   13) -> ( 384 x   13 x   13)\n",
      "create relu4                ( 384 x   13 x   13) -> ( 384 x   13 x   13)\n",
      "create conv5                ( 384 x   13 x   13) -> ( 256 x   13 x   13)\n",
      "create relu5                ( 256 x   13 x   13) -> ( 256 x   13 x   13)\n",
      "create pool5                ( 256 x   13 x   13) -> ( 256 x    6 x    6)\n",
      "create fc6                  ( 256 x    6 x    6) -> (4096 x    1 x    1)\n",
      "create relu6                (4096 x    1 x    1) -> (4096 x    1 x    1)\n",
      "create fc7                  (4096 x    1 x    1) -> (4096 x    1 x    1)\n",
      "create relu7                (4096 x    1 x    1) -> (4096 x    1 x    1)\n",
      "create fc8                  (4096 x    1 x    1) -> (1000 x    1 x    1)\n",
      "CaffeNet(\n",
      "  (conv1): Conv2d(3, 96, kernel_size=(11, 11), stride=(4, 4))\n",
      "  (relu1): ReLU(inplace=True)\n",
      "  (pool1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "  (norm1): LocalResponseNorm(5, alpha=0.0001, beta=0.75, k=1.0)\n",
      "  (conv2): Conv2d(96, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=2)\n",
      "  (relu2): ReLU(inplace=True)\n",
      "  (pool2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "  (norm2): LocalResponseNorm(5, alpha=0.0001, beta=0.75, k=1.0)\n",
      "  (conv3): Conv2d(256, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu3): ReLU(inplace=True)\n",
      "  (conv4): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2)\n",
      "  (relu4): ReLU(inplace=True)\n",
      "  (conv5): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2)\n",
      "  (relu5): ReLU(inplace=True)\n",
      "  (pool5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "  (fc6): Sequential(\n",
      "    (0): view(nB, -1)\n",
      "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
      "  )\n",
      "  (relu6): ReLU(inplace=True)\n",
      "  (fc7): Sequential(\n",
      "    (0): view(nB, -1)\n",
      "    (1): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "  )\n",
      "  (relu7): ReLU(inplace=True)\n",
      "  (fc8): Sequential(\n",
      "    (0): view(nB, -1)\n",
      "    (1): Linear(in_features=4096, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n",
      "Loading caffemodel:  /n/holylfs06/LABS/kempner_fellow_binxuwang/Users/binxuwang/Projects/ReprInvertNet/DeePSim_orig/release_deepsim_v0/caffenet/caffenet.caffemodel\n",
      "Using V1LayerParameter\n",
      "load weights conv1\n",
      "load weights conv2\n",
      "load weights conv3\n",
      "load weights conv4\n",
      "load weights conv5\n",
      "load weights fc6\n",
      "load weights fc7\n",
      "load weights fc8\n"
     ]
    }
   ],
   "source": [
    "Generator = load_generator('caffenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create defc7                (4096 x    1 x    1) -> (4096 x    1 x    1)\n",
      "create relu_defc7           (4096 x    1 x    1) -> (4096 x    1 x    1)\n",
      "create defc6                (4096 x    1 x    1) -> (4096 x    1 x    1)\n",
      "create relu_defc6           (4096 x    1 x    1) -> (4096 x    1 x    1)\n",
      "create defc5                (4096 x    1 x    1) -> (4096 x    1 x    1)\n",
      "create relu_defc5           (4096 x    1 x    1) -> (4096 x    1 x    1)\n",
      "create reshape              (4096 x    1 x    1) -> ( 256 x    4 x    4)\n",
      "create deconv5              ( 256 x    4 x    4) -> ( 256 x    8 x    8)\n",
      "create relu_deconv5         ( 256 x    8 x    8) -> ( 256 x    8 x    8)\n",
      "create conv5_1              ( 256 x    8 x    8) -> ( 512 x    8 x    8)\n",
      "create relu_conv5_1         ( 512 x    8 x    8) -> ( 512 x    8 x    8)\n",
      "create deconv4              ( 512 x    8 x    8) -> ( 256 x   16 x   16)\n",
      "create relu_deconv4         ( 256 x   16 x   16) -> ( 256 x   16 x   16)\n",
      "create conv4_1              ( 256 x   16 x   16) -> ( 256 x   16 x   16)\n",
      "create relu_conv4_1         ( 256 x   16 x   16) -> ( 256 x   16 x   16)\n",
      "create deconv3              ( 256 x   16 x   16) -> ( 128 x   32 x   32)\n",
      "create relu_deconv3         ( 128 x   32 x   32) -> ( 128 x   32 x   32)\n",
      "create conv3_1              ( 128 x   32 x   32) -> ( 128 x   32 x   32)\n",
      "create relu_conv3_1         ( 128 x   32 x   32) -> ( 128 x   32 x   32)\n",
      "create deconv2              ( 128 x   32 x   32) -> (  64 x   64 x   64)\n",
      "create relu_deconv2         (  64 x   64 x   64) -> (  64 x   64 x   64)\n",
      "create deconv1              (  64 x   64 x   64) -> (  32 x  128 x  128)\n",
      "create relu_deconv1         (  32 x  128 x  128) -> (  32 x  128 x  128)\n",
      "create deconv0              (  32 x  128 x  128) -> (   3 x  256 x  256)\n",
      "CaffeNet(\n",
      "  (defc7): Sequential(\n",
      "    (0): view(nB, -1)\n",
      "    (1): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "  )\n",
      "  (relu_defc7): LeakyReLU(negative_slope=0.3, inplace=True)\n",
      "  (defc6): Sequential(\n",
      "    (0): view(nB, -1)\n",
      "    (1): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "  )\n",
      "  (relu_defc6): LeakyReLU(negative_slope=0.3, inplace=True)\n",
      "  (defc5): Sequential(\n",
      "    (0): view(nB, -1)\n",
      "    (1): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "  )\n",
      "  (relu_defc5): LeakyReLU(negative_slope=0.3, inplace=True)\n",
      "  (reshape): Reshape(dims=[64, 256, 4, 4])\n",
      "  (deconv5): ConvTranspose2d(256, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  (relu_deconv5): LeakyReLU(negative_slope=0.3, inplace=True)\n",
      "  (conv5_1): ConvTranspose2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu_conv5_1): LeakyReLU(negative_slope=0.3, inplace=True)\n",
      "  (deconv4): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  (relu_deconv4): LeakyReLU(negative_slope=0.3, inplace=True)\n",
      "  (conv4_1): ConvTranspose2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu_conv4_1): LeakyReLU(negative_slope=0.3, inplace=True)\n",
      "  (deconv3): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  (relu_deconv3): LeakyReLU(negative_slope=0.3, inplace=True)\n",
      "  (conv3_1): ConvTranspose2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu_conv3_1): LeakyReLU(negative_slope=0.3, inplace=True)\n",
      "  (deconv2): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  (relu_deconv2): LeakyReLU(negative_slope=0.3, inplace=True)\n",
      "  (deconv1): ConvTranspose2d(64, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  (relu_deconv1): LeakyReLU(negative_slope=0.3, inplace=True)\n",
      "  (deconv0): ConvTranspose2d(32, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      ")\n",
      "Loading caffemodel:  /n/holylfs06/LABS/kempner_fellow_binxuwang/Users/binxuwang/Projects/ReprInvertNet/DeePSim_orig/upconv/fc6/generator.caffemodel\n",
      "load weights defc7\n",
      "load weights defc6\n",
      "load weights defc5\n",
      "load weights deconv5\n",
      "load weights conv5_1\n",
      "load weights deconv4\n",
      "load weights conv4_1\n",
      "load weights deconv3\n",
      "load weights conv3_1\n",
      "load weights deconv2\n",
      "load weights deconv1\n",
      "load weights deconv0\n",
      "create defc7                (4096 x    1 x    1) -> (4096 x    1 x    1)\n",
      "create relu_defc7           (4096 x    1 x    1) -> (4096 x    1 x    1)\n",
      "create defc6                (4096 x    1 x    1) -> (4096 x    1 x    1)\n",
      "create relu_defc6           (4096 x    1 x    1) -> (4096 x    1 x    1)\n",
      "create defc5                (4096 x    1 x    1) -> (4096 x    1 x    1)\n",
      "create relu_defc5           (4096 x    1 x    1) -> (4096 x    1 x    1)\n",
      "create reshape              (4096 x    1 x    1) -> ( 256 x    4 x    4)\n",
      "create deconv5              ( 256 x    4 x    4) -> ( 256 x    8 x    8)\n",
      "create relu_deconv5         ( 256 x    8 x    8) -> ( 256 x    8 x    8)\n",
      "create conv5_1              ( 256 x    8 x    8) -> ( 512 x    8 x    8)\n",
      "create relu_conv5_1         ( 512 x    8 x    8) -> ( 512 x    8 x    8)\n",
      "create deconv4              ( 512 x    8 x    8) -> ( 256 x   16 x   16)\n",
      "create relu_deconv4         ( 256 x   16 x   16) -> ( 256 x   16 x   16)\n",
      "create conv4_1              ( 256 x   16 x   16) -> ( 256 x   16 x   16)\n",
      "create relu_conv4_1         ( 256 x   16 x   16) -> ( 256 x   16 x   16)\n",
      "create deconv3              ( 256 x   16 x   16) -> ( 128 x   32 x   32)\n",
      "create relu_deconv3         ( 128 x   32 x   32) -> ( 128 x   32 x   32)\n",
      "create conv3_1              ( 128 x   32 x   32) -> ( 128 x   32 x   32)\n",
      "create relu_conv3_1         ( 128 x   32 x   32) -> ( 128 x   32 x   32)\n",
      "create deconv2              ( 128 x   32 x   32) -> (  64 x   64 x   64)\n",
      "create relu_deconv2         (  64 x   64 x   64) -> (  64 x   64 x   64)\n",
      "create deconv1              (  64 x   64 x   64) -> (  32 x  128 x  128)\n",
      "create relu_deconv1         (  32 x  128 x  128) -> (  32 x  128 x  128)\n",
      "create deconv0              (  32 x  128 x  128) -> (   3 x  256 x  256)\n",
      "CaffeNet(\n",
      "  (defc7): Sequential(\n",
      "    (0): view(nB, -1)\n",
      "    (1): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "  )\n",
      "  (relu_defc7): LeakyReLU(negative_slope=0.3, inplace=True)\n",
      "  (defc6): Sequential(\n",
      "    (0): view(nB, -1)\n",
      "    (1): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "  )\n",
      "  (relu_defc6): LeakyReLU(negative_slope=0.3, inplace=True)\n",
      "  (defc5): Sequential(\n",
      "    (0): view(nB, -1)\n",
      "    (1): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "  )\n",
      "  (relu_defc5): LeakyReLU(negative_slope=0.3, inplace=True)\n",
      "  (reshape): Reshape(dims=[64, 256, 4, 4])\n",
      "  (deconv5): ConvTranspose2d(256, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  (relu_deconv5): LeakyReLU(negative_slope=0.3, inplace=True)\n",
      "  (conv5_1): ConvTranspose2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu_conv5_1): LeakyReLU(negative_slope=0.3, inplace=True)\n",
      "  (deconv4): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  (relu_deconv4): LeakyReLU(negative_slope=0.3, inplace=True)\n",
      "  (conv4_1): ConvTranspose2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu_conv4_1): LeakyReLU(negative_slope=0.3, inplace=True)\n",
      "  (deconv3): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  (relu_deconv3): LeakyReLU(negative_slope=0.3, inplace=True)\n",
      "  (conv3_1): ConvTranspose2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu_conv3_1): LeakyReLU(negative_slope=0.3, inplace=True)\n",
      "  (deconv2): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  (relu_deconv2): LeakyReLU(negative_slope=0.3, inplace=True)\n",
      "  (deconv1): ConvTranspose2d(64, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  (relu_deconv1): LeakyReLU(negative_slope=0.3, inplace=True)\n",
      "  (deconv0): ConvTranspose2d(32, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      ")\n",
      "Loading caffemodel:  /n/holylfs06/LABS/kempner_fellow_binxuwang/Users/binxuwang/Projects/ReprInvertNet/DeePSim_orig/upconv/fc7/generator.caffemodel\n",
      "load weights defc7\n",
      "load weights defc6\n",
      "load weights defc5\n",
      "load weights deconv5\n",
      "load weights conv5_1\n",
      "load weights deconv4\n",
      "load weights conv4_1\n",
      "load weights deconv3\n",
      "load weights conv3_1\n",
      "load weights deconv2\n",
      "load weights deconv1\n",
      "load weights deconv0\n",
      "create defc7                (1000 x    1 x    1) -> (4096 x    1 x    1)\n",
      "create relu_defc7           (4096 x    1 x    1) -> (4096 x    1 x    1)\n",
      "create defc6                (4096 x    1 x    1) -> (4096 x    1 x    1)\n",
      "create relu_defc6           (4096 x    1 x    1) -> (4096 x    1 x    1)\n",
      "create defc5                (4096 x    1 x    1) -> (4096 x    1 x    1)\n",
      "create relu_defc5           (4096 x    1 x    1) -> (4096 x    1 x    1)\n",
      "create reshape              (4096 x    1 x    1) -> ( 256 x    4 x    4)\n",
      "create deconv5              ( 256 x    4 x    4) -> ( 256 x    8 x    8)\n",
      "create relu_deconv5         ( 256 x    8 x    8) -> ( 256 x    8 x    8)\n",
      "create conv5_1              ( 256 x    8 x    8) -> ( 512 x    8 x    8)\n",
      "create relu_conv5_1         ( 512 x    8 x    8) -> ( 512 x    8 x    8)\n",
      "create deconv4              ( 512 x    8 x    8) -> ( 256 x   16 x   16)\n",
      "create relu_deconv4         ( 256 x   16 x   16) -> ( 256 x   16 x   16)\n",
      "create conv4_1              ( 256 x   16 x   16) -> ( 256 x   16 x   16)\n",
      "create relu_conv4_1         ( 256 x   16 x   16) -> ( 256 x   16 x   16)\n",
      "create deconv3              ( 256 x   16 x   16) -> ( 128 x   32 x   32)\n",
      "create relu_deconv3         ( 128 x   32 x   32) -> ( 128 x   32 x   32)\n",
      "create conv3_1              ( 128 x   32 x   32) -> ( 128 x   32 x   32)\n",
      "create relu_conv3_1         ( 128 x   32 x   32) -> ( 128 x   32 x   32)\n",
      "create deconv2              ( 128 x   32 x   32) -> (  64 x   64 x   64)\n",
      "create relu_deconv2         (  64 x   64 x   64) -> (  64 x   64 x   64)\n",
      "create deconv1              (  64 x   64 x   64) -> (  32 x  128 x  128)\n",
      "create relu_deconv1         (  32 x  128 x  128) -> (  32 x  128 x  128)\n",
      "create deconv0              (  32 x  128 x  128) -> (   3 x  256 x  256)\n",
      "CaffeNet(\n",
      "  (defc7): Sequential(\n",
      "    (0): view(nB, -1)\n",
      "    (1): Linear(in_features=1000, out_features=4096, bias=True)\n",
      "  )\n",
      "  (relu_defc7): LeakyReLU(negative_slope=0.3, inplace=True)\n",
      "  (defc6): Sequential(\n",
      "    (0): view(nB, -1)\n",
      "    (1): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "  )\n",
      "  (relu_defc6): LeakyReLU(negative_slope=0.3, inplace=True)\n",
      "  (defc5): Sequential(\n",
      "    (0): view(nB, -1)\n",
      "    (1): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "  )\n",
      "  (relu_defc5): LeakyReLU(negative_slope=0.3, inplace=True)\n",
      "  (reshape): Reshape(dims=[64, 256, 4, 4])\n",
      "  (deconv5): ConvTranspose2d(256, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  (relu_deconv5): LeakyReLU(negative_slope=0.3, inplace=True)\n",
      "  (conv5_1): ConvTranspose2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu_conv5_1): LeakyReLU(negative_slope=0.3, inplace=True)\n",
      "  (deconv4): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  (relu_deconv4): LeakyReLU(negative_slope=0.3, inplace=True)\n",
      "  (conv4_1): ConvTranspose2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu_conv4_1): LeakyReLU(negative_slope=0.3, inplace=True)\n",
      "  (deconv3): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  (relu_deconv3): LeakyReLU(negative_slope=0.3, inplace=True)\n",
      "  (conv3_1): ConvTranspose2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu_conv3_1): LeakyReLU(negative_slope=0.3, inplace=True)\n",
      "  (deconv2): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  (relu_deconv2): LeakyReLU(negative_slope=0.3, inplace=True)\n",
      "  (deconv1): ConvTranspose2d(64, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  (relu_deconv1): LeakyReLU(negative_slope=0.3, inplace=True)\n",
      "  (deconv0): ConvTranspose2d(32, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      ")\n",
      "Loading caffemodel:  /n/holylfs06/LABS/kempner_fellow_binxuwang/Users/binxuwang/Projects/ReprInvertNet/DeePSim_orig/upconv/fc8/generator.caffemodel\n",
      "load weights defc7\n",
      "load weights defc6\n",
      "load weights defc5\n",
      "load weights deconv5\n",
      "load weights conv5_1\n",
      "load weights deconv4\n",
      "load weights conv4_1\n",
      "load weights deconv3\n",
      "load weights conv3_1\n",
      "load weights deconv2\n",
      "load weights deconv1\n",
      "load weights deconv0\n"
     ]
    }
   ],
   "source": [
    "Generator = load_generator('fc6')\n",
    "Generator = load_generator('fc7')\n",
    "Generator = load_generator('fc8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create Rconv6               ( 256 x    6 x    6) -> ( 512 x    6 x    6)\n",
      "create Rrelu6               ( 512 x    6 x    6) -> ( 512 x    6 x    6)\n",
      "create Rconv7               ( 512 x    6 x    6) -> ( 512 x    6 x    6)\n",
      "create Rrelu7               ( 512 x    6 x    6) -> ( 512 x    6 x    6)\n",
      "create Rconv8               ( 512 x    6 x    6) -> ( 512 x    4 x    4)\n",
      "create Rrelu8               ( 512 x    4 x    4) -> ( 512 x    4 x    4)\n",
      "create deconv5              ( 512 x    4 x    4) -> ( 256 x    8 x    8)\n",
      "create relu_deconv5         ( 256 x    8 x    8) -> ( 256 x    8 x    8)\n",
      "create conv5_1              ( 256 x    8 x    8) -> ( 512 x    8 x    8)\n",
      "create relu_conv5_1         ( 512 x    8 x    8) -> ( 512 x    8 x    8)\n",
      "create deconv4              ( 512 x    8 x    8) -> ( 256 x   16 x   16)\n",
      "create relu_deconv4         ( 256 x   16 x   16) -> ( 256 x   16 x   16)\n",
      "create conv4_1              ( 256 x   16 x   16) -> ( 256 x   16 x   16)\n",
      "create relu_conv4_1         ( 256 x   16 x   16) -> ( 256 x   16 x   16)\n",
      "create deconv3              ( 256 x   16 x   16) -> ( 128 x   32 x   32)\n",
      "create relu_deconv3         ( 128 x   32 x   32) -> ( 128 x   32 x   32)\n",
      "create conv3_1              ( 128 x   32 x   32) -> ( 128 x   32 x   32)\n",
      "create relu_conv3_1         ( 128 x   32 x   32) -> ( 128 x   32 x   32)\n",
      "create deconv2              ( 128 x   32 x   32) -> (  64 x   64 x   64)\n",
      "create relu_deconv2         (  64 x   64 x   64) -> (  64 x   64 x   64)\n",
      "create deconv1              (  64 x   64 x   64) -> (  32 x  128 x  128)\n",
      "create relu_deconv1         (  32 x  128 x  128) -> (  32 x  128 x  128)\n",
      "create deconv0              (  32 x  128 x  128) -> (   3 x  256 x  256)\n",
      "CaffeNet(\n",
      "  (Rconv6): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (Rrelu6): LeakyReLU(negative_slope=0.3, inplace=True)\n",
      "  (Rconv7): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (Rrelu7): LeakyReLU(negative_slope=0.3, inplace=True)\n",
      "  (Rconv8): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (Rrelu8): LeakyReLU(negative_slope=0.3, inplace=True)\n",
      "  (deconv5): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  (relu_deconv5): LeakyReLU(negative_slope=0.3, inplace=True)\n",
      "  (conv5_1): ConvTranspose2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu_conv5_1): LeakyReLU(negative_slope=0.3, inplace=True)\n",
      "  (deconv4): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  (relu_deconv4): LeakyReLU(negative_slope=0.3, inplace=True)\n",
      "  (conv4_1): ConvTranspose2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu_conv4_1): LeakyReLU(negative_slope=0.3, inplace=True)\n",
      "  (deconv3): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  (relu_deconv3): LeakyReLU(negative_slope=0.3, inplace=True)\n",
      "  (conv3_1): ConvTranspose2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu_conv3_1): LeakyReLU(negative_slope=0.3, inplace=True)\n",
      "  (deconv2): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  (relu_deconv2): LeakyReLU(negative_slope=0.3, inplace=True)\n",
      "  (deconv1): ConvTranspose2d(64, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  (relu_deconv1): LeakyReLU(negative_slope=0.3, inplace=True)\n",
      "  (deconv0): ConvTranspose2d(32, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      ")\n",
      "Loading caffemodel:  /n/holylfs06/LABS/kempner_fellow_binxuwang/Users/binxuwang/Projects/ReprInvertNet/DeePSim_orig/upconv/pool5/generator.caffemodel\n",
      "load weights Rconv6\n",
      "load weights Rconv7\n",
      "load weights Rconv8\n",
      "load weights deconv5\n",
      "load weights conv5_1\n",
      "load weights deconv4\n",
      "load weights conv4_1\n",
      "load weights deconv3\n",
      "load weights conv3_1\n",
      "load weights deconv2\n",
      "load weights deconv1\n",
      "load weights deconv0\n"
     ]
    }
   ],
   "source": [
    "Generator = load_generator('pool5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build CaffeNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create conv1                (   3 x  227 x  227) -> (  96 x   55 x   55)\n",
      "create relu1                (  96 x   55 x   55) -> (  96 x   55 x   55)\n",
      "create pool1                (  96 x   55 x   55) -> (  96 x   27 x   27)\n",
      "create norm1                (  96 x   27 x   27) -> (  96 x   27 x   27)\n",
      "create conv2                (  96 x   27 x   27) -> ( 256 x   27 x   27)\n",
      "create relu2                ( 256 x   27 x   27) -> ( 256 x   27 x   27)\n",
      "create pool2                ( 256 x   27 x   27) -> ( 256 x   13 x   13)\n",
      "create norm2                ( 256 x   13 x   13) -> ( 256 x   13 x   13)\n",
      "create conv3                ( 256 x   13 x   13) -> ( 384 x   13 x   13)\n",
      "create relu3                ( 384 x   13 x   13) -> ( 384 x   13 x   13)\n",
      "create conv4                ( 384 x   13 x   13) -> ( 384 x   13 x   13)\n",
      "create relu4                ( 384 x   13 x   13) -> ( 384 x   13 x   13)\n",
      "create conv5                ( 384 x   13 x   13) -> ( 256 x   13 x   13)\n",
      "create relu5                ( 256 x   13 x   13) -> ( 256 x   13 x   13)\n",
      "create pool5                ( 256 x   13 x   13) -> ( 256 x    6 x    6)\n",
      "create fc6                  ( 256 x    6 x    6) -> (4096 x    1 x    1)\n",
      "create relu6                (4096 x    1 x    1) -> (4096 x    1 x    1)\n",
      "create fc7                  (4096 x    1 x    1) -> (4096 x    1 x    1)\n",
      "create relu7                (4096 x    1 x    1) -> (4096 x    1 x    1)\n",
      "create fc8                  (4096 x    1 x    1) -> (1000 x    1 x    1)\n",
      "CaffeNet(\n",
      "  (conv1): Conv2d(3, 96, kernel_size=(11, 11), stride=(4, 4))\n",
      "  (relu1): ReLU(inplace=True)\n",
      "  (pool1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "  (norm1): LocalResponseNorm(5, alpha=0.0001, beta=0.75, k=1.0)\n",
      "  (conv2): Conv2d(96, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=2)\n",
      "  (relu2): ReLU(inplace=True)\n",
      "  (pool2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "  (norm2): LocalResponseNorm(5, alpha=0.0001, beta=0.75, k=1.0)\n",
      "  (conv3): Conv2d(256, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu3): ReLU(inplace=True)\n",
      "  (conv4): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2)\n",
      "  (relu4): ReLU(inplace=True)\n",
      "  (conv5): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2)\n",
      "  (relu5): ReLU(inplace=True)\n",
      "  (pool5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "  (fc6): Sequential(\n",
      "    (0): view(nB, -1)\n",
      "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
      "  )\n",
      "  (relu6): ReLU(inplace=True)\n",
      "  (fc7): Sequential(\n",
      "    (0): view(nB, -1)\n",
      "    (1): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "  )\n",
      "  (relu7): ReLU(inplace=True)\n",
      "  (fc8): Sequential(\n",
      "    (0): view(nB, -1)\n",
      "    (1): Linear(in_features=4096, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n",
      "Loading caffemodel:  /n/holylfs06/LABS/kempner_fellow_binxuwang/Users/binxuwang/Projects/ReprInvertNet/DeePSim_orig/upconv/caffenet/caffenet.caffemodel\n",
      "Using V1LayerParameter\n",
      "load weights conv1\n",
      "load weights conv2\n",
      "load weights conv3\n",
      "load weights conv4\n",
      "load weights conv5\n",
      "load weights fc6\n",
      "load weights fc7\n",
      "load weights fc8\n"
     ]
    }
   ],
   "source": [
    "CNN = load_caffenet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "caffenet_th = nn.Sequential(OrderedDict([\n",
    "    # Layer 1\n",
    "    ('conv1', nn.Conv2d(3, 96, kernel_size=(11, 11), stride=(4, 4))),\n",
    "    ('relu1', nn.ReLU(inplace=True)),\n",
    "    ('pool1', nn.MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)),\n",
    "    ('norm1', nn.LocalResponseNorm(size=5, alpha=0.0001, beta=0.75, k=1.0)),\n",
    "    # Layer 2\n",
    "    ('conv2', nn.Conv2d(96, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=2)),\n",
    "    ('relu2', nn.ReLU(inplace=True)),\n",
    "    ('pool2', nn.MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)),\n",
    "    ('norm2', nn.LocalResponseNorm(size=5, alpha=0.0001, beta=0.75, k=1.0)),\n",
    "    # Layer 3\n",
    "    ('conv3', nn.Conv2d(256, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))),\n",
    "    ('relu3', nn.ReLU(inplace=True)),\n",
    "    # Layer 4\n",
    "    ('conv4', nn.Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2)),\n",
    "    ('relu4', nn.ReLU(inplace=True)),\n",
    "    # Layer 5\n",
    "    ('conv5', nn.Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2)),\n",
    "    ('relu5', nn.ReLU(inplace=True)),\n",
    "    ('pool5', nn.MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)),\n",
    "    # Fully connected layers\n",
    "    ('flatten', nn.Flatten()),\n",
    "    ('fc6', nn.Linear(9216, 4096)),\n",
    "    ('relu6', nn.ReLU(inplace=True)),\n",
    "    ('fc7', nn.Linear(4096, 4096)),\n",
    "    ('relu7', nn.ReLU(inplace=True)),\n",
    "    ('fc8', nn.Linear(4096, 1000))\n",
    "]))\n",
    "state_dict = {}\n",
    "for k, v in CNN.state_dict().items():\n",
    "    if '.1.' in k:\n",
    "        state_dict[k.replace('.1.', '.')] = v\n",
    "    else:\n",
    "        state_dict[k] = v.cpu()\n",
    "caffenet_th.load_state_dict(state_dict)\n",
    "latent_shape = (3, 227, 227)\n",
    "latents = torch.randn(1, *latent_shape)\n",
    "out = CNN(latents)\n",
    "# out[\"generated\"]\n",
    "out_th = caffenet_th(latents)\n",
    "assert torch.allclose(out[\"fc8\"], out_th)\n",
    "# For the Eltwise SUM operation, a custom module or function should be added outside of Sequential."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(caffenet_th.state_dict(), \"/n/holylfs06/LABS/kempner_fellow_binxuwang/Users/binxuwang/Projects/ReprInvertNet/DeePSim_orig/upconv/caffenet/caffenet_simple.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build generators for norm1-4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### norm1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create Rconv6               (  96 x   27 x   27) -> ( 128 x   15 x   15)\n",
      "create Rrelu6               ( 128 x   15 x   15) -> ( 128 x   15 x   15)\n",
      "create Rconv7               ( 128 x   15 x   15) -> ( 128 x   15 x   15)\n",
      "create Rrelu7               ( 128 x   15 x   15) -> ( 128 x   15 x   15)\n",
      "create Rconv8               ( 128 x   15 x   15) -> ( 128 x   15 x   15)\n",
      "create Rrelu8               ( 128 x   15 x   15) -> ( 128 x   15 x   15)\n",
      "create deconv4              ( 128 x   15 x   15) -> ( 128 x   30 x   30)\n",
      "create relu_deconv4         ( 128 x   30 x   30) -> ( 128 x   30 x   30)\n",
      "create conv4_1              ( 128 x   30 x   30) -> ( 128 x   30 x   30)\n",
      "create relu_conv4_1         ( 128 x   30 x   30) -> ( 128 x   30 x   30)\n",
      "create deconv3              ( 128 x   30 x   30) -> (  64 x   60 x   60)\n",
      "create relu_deconv3         (  64 x   60 x   60) -> (  64 x   60 x   60)\n",
      "create conv3_1              (  64 x   60 x   60) -> (  64 x   60 x   60)\n",
      "create relu_conv3_1         (  64 x   60 x   60) -> (  64 x   60 x   60)\n",
      "create deconv2              (  64 x   60 x   60) -> (  32 x  120 x  120)\n",
      "create relu_deconv2         (  32 x  120 x  120) -> (  32 x  120 x  120)\n",
      "create conv2_1              (  32 x  120 x  120) -> (  32 x  120 x  120)\n",
      "create relu_conv2_1         (  32 x  120 x  120) -> (  32 x  120 x  120)\n",
      "create deconv1              (  32 x  120 x  120) -> (  16 x  240 x  240)\n",
      "create conv1_1              (  16 x  240 x  240) -> (   3 x  240 x  240)\n",
      "create tanh                 (   3 x  240 x  240) -> (   3 x  240 x  240)\n",
      "create conv1_1_tanh         (   3 x  240 x  240) -> (   3 x  240 x  240)\n",
      "CaffeNet(\n",
      "  (Rconv6): Conv2d(96, 128, kernel_size=(3, 3), stride=(2, 2), padding=(2, 2))\n",
      "  (Rrelu6): LeakyReLU(negative_slope=0.3, inplace=True)\n",
      "  (Rconv7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (Rrelu7): LeakyReLU(negative_slope=0.3, inplace=True)\n",
      "  (Rconv8): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (Rrelu8): LeakyReLU(negative_slope=0.3, inplace=True)\n",
      "  (deconv4): ConvTranspose2d(128, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  (relu_deconv4): LeakyReLU(negative_slope=0.3, inplace=True)\n",
      "  (conv4_1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu_conv4_1): LeakyReLU(negative_slope=0.3, inplace=True)\n",
      "  (deconv3): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  (relu_deconv3): LeakyReLU(negative_slope=0.3, inplace=True)\n",
      "  (conv3_1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu_conv3_1): LeakyReLU(negative_slope=0.3, inplace=True)\n",
      "  (deconv2): ConvTranspose2d(64, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  (relu_deconv2): LeakyReLU(negative_slope=0.3, inplace=True)\n",
      "  (conv2_1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu_conv2_1): LeakyReLU(negative_slope=0.3, inplace=True)\n",
      "  (deconv1): ConvTranspose2d(32, 16, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  (conv1_1): Conv2d(16, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (tanh): Tanh()\n",
      "  (conv1_1_tanh): Eltwise SUM\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "Generator = load_generator('norm1')\n",
    "model_th = nn.Sequential(OrderedDict([\n",
    "    ('Rconv6', nn.Conv2d(96, 128, kernel_size=(3, 3), stride=(2, 2), padding=(2, 2))),\n",
    "    ('Rrelu6', nn.LeakyReLU(negative_slope=0.3, inplace=True)),\n",
    "    ('Rconv7', nn.Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))),\n",
    "    ('Rrelu7', nn.LeakyReLU(negative_slope=0.3, inplace=True)),\n",
    "    ('Rconv8', nn.Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))),\n",
    "    ('Rrelu8', nn.LeakyReLU(negative_slope=0.3, inplace=True)),\n",
    "    ('deconv4', nn.ConvTranspose2d(128, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))),\n",
    "    ('relu_deconv4', nn.LeakyReLU(negative_slope=0.3, inplace=True)),\n",
    "    ('conv4_1', nn.Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))),\n",
    "    ('relu_conv4_1', nn.LeakyReLU(negative_slope=0.3, inplace=True)),\n",
    "    ('deconv3', nn.ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))),\n",
    "    ('relu_deconv3', nn.LeakyReLU(negative_slope=0.3, inplace=True)),\n",
    "    ('conv3_1', nn.Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))),\n",
    "    ('relu_conv3_1', nn.LeakyReLU(negative_slope=0.3, inplace=True)),\n",
    "    ('deconv2', nn.ConvTranspose2d(64, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))),\n",
    "    ('relu_deconv2', nn.LeakyReLU(negative_slope=0.3, inplace=True)),\n",
    "    ('conv2_1', nn.Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))),\n",
    "    ('relu_conv2_1', nn.LeakyReLU(negative_slope=0.3, inplace=True)),\n",
    "    ('deconv1', nn.ConvTranspose2d(32, 16, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))),\n",
    "    ('conv1_1', nn.Conv2d(16, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))),\n",
    "    ('tanh', nn.Tanh())\n",
    "]))\n",
    "model_th.load_state_dict(Generator.state_dict())\n",
    "latent_shape = (96, 27, 27)\n",
    "latents = torch.randn(1, *latent_shape)\n",
    "out = Generator(latents)\n",
    "# out[\"generated\"]\n",
    "out_th = model_th(latents)\n",
    "assert torch.allclose(out[\"generated\"], out_th)\n",
    "# For the Eltwise SUM operation, a custom module or function should be added outside of Sequential."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### norm2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create Rconv6               ( 256 x   13 x   13) -> ( 256 x   15 x   15)\n",
      "create Rrelu6               ( 256 x   15 x   15) -> ( 256 x   15 x   15)\n",
      "create Rconv7               ( 256 x   15 x   15) -> ( 128 x   15 x   15)\n",
      "create Rrelu7               ( 128 x   15 x   15) -> ( 128 x   15 x   15)\n",
      "create Rconv8               ( 128 x   15 x   15) -> ( 128 x   15 x   15)\n",
      "create Rrelu8               ( 128 x   15 x   15) -> ( 128 x   15 x   15)\n",
      "create deconv4              ( 128 x   15 x   15) -> ( 128 x   30 x   30)\n",
      "create relu_deconv4         ( 128 x   30 x   30) -> ( 128 x   30 x   30)\n",
      "create conv4_1              ( 128 x   30 x   30) -> ( 128 x   30 x   30)\n",
      "create relu_conv4_1         ( 128 x   30 x   30) -> ( 128 x   30 x   30)\n",
      "create deconv3              ( 128 x   30 x   30) -> (  64 x   60 x   60)\n",
      "create relu_deconv3         (  64 x   60 x   60) -> (  64 x   60 x   60)\n",
      "create conv3_1              (  64 x   60 x   60) -> (  64 x   60 x   60)\n",
      "create relu_conv3_1         (  64 x   60 x   60) -> (  64 x   60 x   60)\n",
      "create deconv2              (  64 x   60 x   60) -> (  32 x  120 x  120)\n",
      "create relu_deconv2         (  32 x  120 x  120) -> (  32 x  120 x  120)\n",
      "create conv2_1              (  32 x  120 x  120) -> (  32 x  120 x  120)\n",
      "create relu_conv2_1         (  32 x  120 x  120) -> (  32 x  120 x  120)\n",
      "create deconv1              (  32 x  120 x  120) -> (  16 x  240 x  240)\n",
      "create conv1_1              (  16 x  240 x  240) -> (   3 x  240 x  240)\n",
      "create tanh                 (   3 x  240 x  240) -> (   3 x  240 x  240)\n",
      "create conv1_1_tanh         (   3 x  240 x  240) -> (   3 x  240 x  240)\n",
      "CaffeNet(\n",
      "  (Rconv6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
      "  (Rrelu6): LeakyReLU(negative_slope=0.3, inplace=True)\n",
      "  (Rconv7): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (Rrelu7): LeakyReLU(negative_slope=0.3, inplace=True)\n",
      "  (Rconv8): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (Rrelu8): LeakyReLU(negative_slope=0.3, inplace=True)\n",
      "  (deconv4): ConvTranspose2d(128, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  (relu_deconv4): LeakyReLU(negative_slope=0.3, inplace=True)\n",
      "  (conv4_1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu_conv4_1): LeakyReLU(negative_slope=0.3, inplace=True)\n",
      "  (deconv3): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  (relu_deconv3): LeakyReLU(negative_slope=0.3, inplace=True)\n",
      "  (conv3_1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu_conv3_1): LeakyReLU(negative_slope=0.3, inplace=True)\n",
      "  (deconv2): ConvTranspose2d(64, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  (relu_deconv2): LeakyReLU(negative_slope=0.3, inplace=True)\n",
      "  (conv2_1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu_conv2_1): LeakyReLU(negative_slope=0.3, inplace=True)\n",
      "  (deconv1): ConvTranspose2d(32, 16, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  (conv1_1): Conv2d(16, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (tanh): Tanh()\n",
      "  (conv1_1_tanh): Eltwise SUM\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "Generator = load_generator('norm2')\n",
    "model_th = nn.Sequential(OrderedDict([\n",
    "    ('Rconv6', nn.Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))),\n",
    "    ('Rrelu6', nn.LeakyReLU(negative_slope=0.3, inplace=True)),\n",
    "    ('Rconv7', nn.Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))),\n",
    "    ('Rrelu7', nn.LeakyReLU(negative_slope=0.3, inplace=True)),\n",
    "    ('Rconv8', nn.Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))),\n",
    "    ('Rrelu8', nn.LeakyReLU(negative_slope=0.3, inplace=True)),\n",
    "    ('deconv4', nn.ConvTranspose2d(128, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))),\n",
    "    ('relu_deconv4', nn.LeakyReLU(negative_slope=0.3, inplace=True)),\n",
    "    ('conv4_1', nn.Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))),\n",
    "    ('relu_conv4_1', nn.LeakyReLU(negative_slope=0.3, inplace=True)),\n",
    "    ('deconv3', nn.ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))),\n",
    "    ('relu_deconv3', nn.LeakyReLU(negative_slope=0.3, inplace=True)),\n",
    "    ('conv3_1', nn.Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))),\n",
    "    ('relu_conv3_1', nn.LeakyReLU(negative_slope=0.3, inplace=True)),\n",
    "    ('deconv2', nn.ConvTranspose2d(64, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))),\n",
    "    ('relu_deconv2', nn.LeakyReLU(negative_slope=0.3, inplace=True)),\n",
    "    ('conv2_1', nn.Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))),\n",
    "    ('relu_conv2_1', nn.LeakyReLU(negative_slope=0.3, inplace=True)),\n",
    "    ('deconv1', nn.ConvTranspose2d(32, 16, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))),\n",
    "    ('conv1_1', nn.Conv2d(16, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))),\n",
    "    ('tanh', nn.Tanh())\n",
    "]))\n",
    "model_th.load_state_dict(Generator.state_dict())\n",
    "latent_shape = (256, 13, 13)\n",
    "latents = torch.randn(1, *latent_shape)\n",
    "out = Generator(latents)\n",
    "# out[\"generated\"]\n",
    "out_th = model_th(latents)\n",
    "assert torch.allclose(out[\"generated\"], out_th)\n",
    "# For the Eltwise SUM operation, a custom module or function should be added outside of Sequential."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### conv3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create Rconv6               ( 384 x   13 x   13) -> ( 384 x   11 x   11)\n",
      "create Rrelu6               ( 384 x   11 x   11) -> ( 384 x   11 x   11)\n",
      "create Rconv7               ( 384 x   11 x   11) -> ( 512 x    9 x    9)\n",
      "create Rrelu7               ( 512 x    9 x    9) -> ( 512 x    9 x    9)\n",
      "create Rconv8               ( 512 x    9 x    9) -> ( 512 x    8 x    8)\n",
      "create Rrelu8               ( 512 x    8 x    8) -> ( 512 x    8 x    8)\n",
      "create deconv5              ( 512 x    8 x    8) -> ( 256 x   16 x   16)\n",
      "create relu_deconv5         ( 256 x   16 x   16) -> ( 256 x   16 x   16)\n",
      "create conv5_1              ( 256 x   16 x   16) -> ( 256 x   16 x   16)\n",
      "create relu_conv5_1         ( 256 x   16 x   16) -> ( 256 x   16 x   16)\n",
      "create deconv4              ( 256 x   16 x   16) -> ( 128 x   32 x   32)\n",
      "create relu_deconv4         ( 128 x   32 x   32) -> ( 128 x   32 x   32)\n",
      "create conv4_1              ( 128 x   32 x   32) -> ( 128 x   32 x   32)\n",
      "create relu_conv4_1         ( 128 x   32 x   32) -> ( 128 x   32 x   32)\n",
      "create deconv3              ( 128 x   32 x   32) -> ( 128 x   64 x   64)\n",
      "create relu_deconv3         ( 128 x   64 x   64) -> ( 128 x   64 x   64)\n",
      "create conv3_1              ( 128 x   64 x   64) -> ( 128 x   64 x   64)\n",
      "create relu_conv3_1         ( 128 x   64 x   64) -> ( 128 x   64 x   64)\n",
      "create deconv2              ( 128 x   64 x   64) -> (  64 x  128 x  128)\n",
      "create relu_deconv2         (  64 x  128 x  128) -> (  64 x  128 x  128)\n",
      "create conv2_1              (  64 x  128 x  128) -> (  32 x  128 x  128)\n",
      "create relu_conv2_1         (  32 x  128 x  128) -> (  32 x  128 x  128)\n",
      "create deconv1              (  32 x  128 x  128) -> (  16 x  256 x  256)\n",
      "create relu_deconv1         (  16 x  256 x  256) -> (  16 x  256 x  256)\n",
      "create conv1_1              (  16 x  256 x  256) -> (   3 x  256 x  256)\n",
      "create tanh                 (   3 x  256 x  256) -> (   3 x  256 x  256)\n",
      "create conv1_1_tanh         (   3 x  256 x  256) -> (   3 x  256 x  256)\n",
      "CaffeNet(\n",
      "  (Rconv6): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (Rrelu6): LeakyReLU(negative_slope=0.3, inplace=True)\n",
      "  (Rconv7): Conv2d(384, 512, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (Rrelu7): LeakyReLU(negative_slope=0.3, inplace=True)\n",
      "  (Rconv8): Conv2d(512, 512, kernel_size=(2, 2), stride=(1, 1))\n",
      "  (Rrelu8): LeakyReLU(negative_slope=0.3, inplace=True)\n",
      "  (deconv5): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  (relu_deconv5): LeakyReLU(negative_slope=0.3, inplace=True)\n",
      "  (conv5_1): ConvTranspose2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu_conv5_1): LeakyReLU(negative_slope=0.3, inplace=True)\n",
      "  (deconv4): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  (relu_deconv4): LeakyReLU(negative_slope=0.3, inplace=True)\n",
      "  (conv4_1): ConvTranspose2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu_conv4_1): LeakyReLU(negative_slope=0.3, inplace=True)\n",
      "  (deconv3): ConvTranspose2d(128, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  (relu_deconv3): LeakyReLU(negative_slope=0.3, inplace=True)\n",
      "  (conv3_1): ConvTranspose2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu_conv3_1): LeakyReLU(negative_slope=0.3, inplace=True)\n",
      "  (deconv2): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  (relu_deconv2): LeakyReLU(negative_slope=0.3, inplace=True)\n",
      "  (conv2_1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu_conv2_1): LeakyReLU(negative_slope=0.3, inplace=True)\n",
      "  (deconv1): ConvTranspose2d(32, 16, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  (relu_deconv1): LeakyReLU(negative_slope=0.3, inplace=True)\n",
      "  (conv1_1): Conv2d(16, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (tanh): Tanh()\n",
      "  (conv1_1_tanh): Eltwise SUM\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "Generator = load_generator('conv3')\n",
    "model_th = nn.Sequential(OrderedDict([\n",
    "    ('Rconv6', nn.Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1))),\n",
    "    ('Rrelu6', nn.LeakyReLU(negative_slope=0.3, inplace=True)),\n",
    "    ('Rconv7', nn.Conv2d(384, 512, kernel_size=(3, 3), stride=(1, 1))),\n",
    "    ('Rrelu7', nn.LeakyReLU(negative_slope=0.3, inplace=True)),\n",
    "    ('Rconv8', nn.Conv2d(512, 512, kernel_size=(2, 2), stride=(1, 1))),\n",
    "    ('Rrelu8', nn.LeakyReLU(negative_slope=0.3, inplace=True)),\n",
    "    ('deconv5', nn.ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))),\n",
    "    ('relu_deconv5', nn.LeakyReLU(negative_slope=0.3, inplace=True)),\n",
    "    ('conv5_1', nn.ConvTranspose2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))),\n",
    "    ('relu_conv5_1', nn.LeakyReLU(negative_slope=0.3, inplace=True)),\n",
    "    ('deconv4', nn.ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))),\n",
    "    ('relu_deconv4', nn.LeakyReLU(negative_slope=0.3, inplace=True)),\n",
    "    ('conv4_1', nn.ConvTranspose2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))),\n",
    "    ('relu_conv4_1', nn.LeakyReLU(negative_slope=0.3, inplace=True)),\n",
    "    ('deconv3', nn.ConvTranspose2d(128, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))),\n",
    "    ('relu_deconv3', nn.LeakyReLU(negative_slope=0.3, inplace=True)),\n",
    "    ('conv3_1', nn.ConvTranspose2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))),\n",
    "    ('relu_conv3_1', nn.LeakyReLU(negative_slope=0.3, inplace=True)),\n",
    "    ('deconv2', nn.ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))),\n",
    "    ('relu_deconv2', nn.LeakyReLU(negative_slope=0.3, inplace=True)),\n",
    "    ('conv2_1', nn.Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))),\n",
    "    ('relu_conv2_1', nn.LeakyReLU(negative_slope=0.3, inplace=True)),\n",
    "    ('deconv1', nn.ConvTranspose2d(32, 16, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))),\n",
    "    ('relu_deconv1', nn.LeakyReLU(negative_slope=0.3, inplace=True)),\n",
    "    ('conv1_1', nn.Conv2d(16, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))),\n",
    "    ('tanh', nn.Tanh())\n",
    "]))\n",
    "model_th.load_state_dict(Generator.state_dict())\n",
    "latent_shape = (384, 13, 13)\n",
    "latents = torch.randn(1, *latent_shape)\n",
    "out = Generator(latents)\n",
    "# out[\"generated\"]\n",
    "out_th = model_th(latents)\n",
    "assert torch.allclose(out[\"generated\"], out_th)\n",
    "# For the Eltwise SUM operation, a custom module or function should be added outside of Sequential."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### conv4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create Rconv6               ( 384 x   13 x   13) -> ( 384 x   11 x   11)\n",
      "create Rrelu6               ( 384 x   11 x   11) -> ( 384 x   11 x   11)\n",
      "create Rconv7               ( 384 x   11 x   11) -> ( 512 x    9 x    9)\n",
      "create Rrelu7               ( 512 x    9 x    9) -> ( 512 x    9 x    9)\n",
      "create Rconv8               ( 512 x    9 x    9) -> ( 512 x    8 x    8)\n",
      "create Rrelu8               ( 512 x    8 x    8) -> ( 512 x    8 x    8)\n",
      "create deconv5              ( 512 x    8 x    8) -> ( 256 x   16 x   16)\n",
      "create relu_deconv5         ( 256 x   16 x   16) -> ( 256 x   16 x   16)\n",
      "create conv5_1              ( 256 x   16 x   16) -> ( 256 x   16 x   16)\n",
      "create relu_conv5_1         ( 256 x   16 x   16) -> ( 256 x   16 x   16)\n",
      "create deconv4              ( 256 x   16 x   16) -> ( 128 x   32 x   32)\n",
      "create relu_deconv4         ( 128 x   32 x   32) -> ( 128 x   32 x   32)\n",
      "create conv4_1              ( 128 x   32 x   32) -> ( 128 x   32 x   32)\n",
      "create relu_conv4_1         ( 128 x   32 x   32) -> ( 128 x   32 x   32)\n",
      "create deconv3              ( 128 x   32 x   32) -> ( 128 x   64 x   64)\n",
      "create relu_deconv3         ( 128 x   64 x   64) -> ( 128 x   64 x   64)\n",
      "create conv3_1              ( 128 x   64 x   64) -> ( 128 x   64 x   64)\n",
      "create relu_conv3_1         ( 128 x   64 x   64) -> ( 128 x   64 x   64)\n",
      "create deconv2              ( 128 x   64 x   64) -> (  64 x  128 x  128)\n",
      "create relu_deconv2         (  64 x  128 x  128) -> (  64 x  128 x  128)\n",
      "create conv2_1              (  64 x  128 x  128) -> (  32 x  128 x  128)\n",
      "create relu_conv2_1         (  32 x  128 x  128) -> (  32 x  128 x  128)\n",
      "create deconv1              (  32 x  128 x  128) -> (  16 x  256 x  256)\n",
      "create relu_deconv1         (  16 x  256 x  256) -> (  16 x  256 x  256)\n",
      "create conv1_1              (  16 x  256 x  256) -> (   3 x  256 x  256)\n",
      "create tanh                 (   3 x  256 x  256) -> (   3 x  256 x  256)\n",
      "create conv1_1_tanh         (   3 x  256 x  256) -> (   3 x  256 x  256)\n",
      "CaffeNet(\n",
      "  (Rconv6): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (Rrelu6): LeakyReLU(negative_slope=0.3, inplace=True)\n",
      "  (Rconv7): Conv2d(384, 512, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (Rrelu7): LeakyReLU(negative_slope=0.3, inplace=True)\n",
      "  (Rconv8): Conv2d(512, 512, kernel_size=(2, 2), stride=(1, 1))\n",
      "  (Rrelu8): LeakyReLU(negative_slope=0.3, inplace=True)\n",
      "  (deconv5): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  (relu_deconv5): LeakyReLU(negative_slope=0.3, inplace=True)\n",
      "  (conv5_1): ConvTranspose2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu_conv5_1): LeakyReLU(negative_slope=0.3, inplace=True)\n",
      "  (deconv4): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  (relu_deconv4): LeakyReLU(negative_slope=0.3, inplace=True)\n",
      "  (conv4_1): ConvTranspose2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu_conv4_1): LeakyReLU(negative_slope=0.3, inplace=True)\n",
      "  (deconv3): ConvTranspose2d(128, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  (relu_deconv3): LeakyReLU(negative_slope=0.3, inplace=True)\n",
      "  (conv3_1): ConvTranspose2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu_conv3_1): LeakyReLU(negative_slope=0.3, inplace=True)\n",
      "  (deconv2): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  (relu_deconv2): LeakyReLU(negative_slope=0.3, inplace=True)\n",
      "  (conv2_1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu_conv2_1): LeakyReLU(negative_slope=0.3, inplace=True)\n",
      "  (deconv1): ConvTranspose2d(32, 16, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  (relu_deconv1): LeakyReLU(negative_slope=0.3, inplace=True)\n",
      "  (conv1_1): Conv2d(16, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (tanh): Tanh()\n",
      "  (conv1_1_tanh): Eltwise SUM\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "Generator = load_generator('conv4')\n",
    "model_th = nn.Sequential(OrderedDict([\n",
    "    ('Rconv6', nn.Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1))),\n",
    "    ('Rrelu6', nn.LeakyReLU(negative_slope=0.3, inplace=True)),\n",
    "    ('Rconv7', nn.Conv2d(384, 512, kernel_size=(3, 3), stride=(1, 1))),\n",
    "    ('Rrelu7', nn.LeakyReLU(negative_slope=0.3, inplace=True)),\n",
    "    ('Rconv8', nn.Conv2d(512, 512, kernel_size=(2, 2), stride=(1, 1))),\n",
    "    ('Rrelu8', nn.LeakyReLU(negative_slope=0.3, inplace=True)),\n",
    "    ('deconv5', nn.ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))),\n",
    "    ('relu_deconv5', nn.LeakyReLU(negative_slope=0.3, inplace=True)),\n",
    "    ('conv5_1', nn.ConvTranspose2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))),\n",
    "    ('relu_conv5_1', nn.LeakyReLU(negative_slope=0.3, inplace=True)),\n",
    "    ('deconv4', nn.ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))),\n",
    "    ('relu_deconv4', nn.LeakyReLU(negative_slope=0.3, inplace=True)),\n",
    "    ('conv4_1', nn.ConvTranspose2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))),\n",
    "    ('relu_conv4_1', nn.LeakyReLU(negative_slope=0.3, inplace=True)),\n",
    "    ('deconv3', nn.ConvTranspose2d(128, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))),\n",
    "    ('relu_deconv3', nn.LeakyReLU(negative_slope=0.3, inplace=True)),\n",
    "    ('conv3_1', nn.ConvTranspose2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))),\n",
    "    ('relu_conv3_1', nn.LeakyReLU(negative_slope=0.3, inplace=True)),\n",
    "    ('deconv2', nn.ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))),\n",
    "    ('relu_deconv2', nn.LeakyReLU(negative_slope=0.3, inplace=True)),\n",
    "    ('conv2_1', nn.Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))),\n",
    "    ('relu_conv2_1', nn.LeakyReLU(negative_slope=0.3, inplace=True)),\n",
    "    ('deconv1', nn.ConvTranspose2d(32, 16, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))),\n",
    "    ('relu_deconv1', nn.LeakyReLU(negative_slope=0.3, inplace=True)),\n",
    "    ('conv1_1', nn.Conv2d(16, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))),\n",
    "    ('tanh', nn.Tanh())\n",
    "]))\n",
    "model_th.load_state_dict(Generator.state_dict())\n",
    "latent_shape = (384, 13, 13)\n",
    "latents = torch.randn(1, *latent_shape)\n",
    "out = Generator(latents)\n",
    "# out[\"generated\"]\n",
    "out_th = model_th(latents)\n",
    "assert torch.allclose(out[\"generated\"], out_th)\n",
    "# For the Eltwise SUM operation, a custom module or function should be added outside of Sequential."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create Rconv6               (  96 x   27 x   27) -> ( 128 x   15 x   15)\n",
      "create Rrelu6               ( 128 x   15 x   15) -> ( 128 x   15 x   15)\n",
      "create Rconv7               ( 128 x   15 x   15) -> ( 128 x   15 x   15)\n",
      "create Rrelu7               ( 128 x   15 x   15) -> ( 128 x   15 x   15)\n",
      "create Rconv8               ( 128 x   15 x   15) -> ( 128 x   15 x   15)\n",
      "create Rrelu8               ( 128 x   15 x   15) -> ( 128 x   15 x   15)\n",
      "create deconv4              ( 128 x   15 x   15) -> ( 128 x   30 x   30)\n",
      "create relu_deconv4         ( 128 x   30 x   30) -> ( 128 x   30 x   30)\n",
      "create conv4_1              ( 128 x   30 x   30) -> ( 128 x   30 x   30)\n",
      "create relu_conv4_1         ( 128 x   30 x   30) -> ( 128 x   30 x   30)\n",
      "create deconv3              ( 128 x   30 x   30) -> (  64 x   60 x   60)\n",
      "create relu_deconv3         (  64 x   60 x   60) -> (  64 x   60 x   60)\n",
      "create conv3_1              (  64 x   60 x   60) -> (  64 x   60 x   60)\n",
      "create relu_conv3_1         (  64 x   60 x   60) -> (  64 x   60 x   60)\n",
      "create deconv2              (  64 x   60 x   60) -> (  32 x  120 x  120)\n",
      "create relu_deconv2         (  32 x  120 x  120) -> (  32 x  120 x  120)\n",
      "create conv2_1              (  32 x  120 x  120) -> (  32 x  120 x  120)\n",
      "create relu_conv2_1         (  32 x  120 x  120) -> (  32 x  120 x  120)\n",
      "create deconv1              (  32 x  120 x  120) -> (  16 x  240 x  240)\n",
      "create conv1_1              (  16 x  240 x  240) -> (   3 x  240 x  240)\n",
      "create tanh                 (   3 x  240 x  240) -> (   3 x  240 x  240)\n",
      "create conv1_1_tanh         (   3 x  240 x  240) -> (   3 x  240 x  240)\n",
      "CaffeNet(\n",
      "  (Rconv6): Conv2d(96, 128, kernel_size=(3, 3), stride=(2, 2), padding=(2, 2))\n",
      "  (Rrelu6): LeakyReLU(negative_slope=0.3, inplace=True)\n",
      "  (Rconv7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (Rrelu7): LeakyReLU(negative_slope=0.3, inplace=True)\n",
      "  (Rconv8): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (Rrelu8): LeakyReLU(negative_slope=0.3, inplace=True)\n",
      "  (deconv4): ConvTranspose2d(128, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  (relu_deconv4): LeakyReLU(negative_slope=0.3, inplace=True)\n",
      "  (conv4_1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu_conv4_1): LeakyReLU(negative_slope=0.3, inplace=True)\n",
      "  (deconv3): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  (relu_deconv3): LeakyReLU(negative_slope=0.3, inplace=True)\n",
      "  (conv3_1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu_conv3_1): LeakyReLU(negative_slope=0.3, inplace=True)\n",
      "  (deconv2): ConvTranspose2d(64, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  (relu_deconv2): LeakyReLU(negative_slope=0.3, inplace=True)\n",
      "  (conv2_1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu_conv2_1): LeakyReLU(negative_slope=0.3, inplace=True)\n",
      "  (deconv1): ConvTranspose2d(32, 16, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  (conv1_1): Conv2d(16, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (tanh): Tanh()\n",
      "  (conv1_1_tanh): Eltwise SUM\n",
      ")\n",
      "create Rconv6               ( 256 x   13 x   13) -> ( 256 x   15 x   15)\n",
      "create Rrelu6               ( 256 x   15 x   15) -> ( 256 x   15 x   15)\n",
      "create Rconv7               ( 256 x   15 x   15) -> ( 128 x   15 x   15)\n",
      "create Rrelu7               ( 128 x   15 x   15) -> ( 128 x   15 x   15)\n",
      "create Rconv8               ( 128 x   15 x   15) -> ( 128 x   15 x   15)\n",
      "create Rrelu8               ( 128 x   15 x   15) -> ( 128 x   15 x   15)\n",
      "create deconv4              ( 128 x   15 x   15) -> ( 128 x   30 x   30)\n",
      "create relu_deconv4         ( 128 x   30 x   30) -> ( 128 x   30 x   30)\n",
      "create conv4_1              ( 128 x   30 x   30) -> ( 128 x   30 x   30)\n",
      "create relu_conv4_1         ( 128 x   30 x   30) -> ( 128 x   30 x   30)\n",
      "create deconv3              ( 128 x   30 x   30) -> (  64 x   60 x   60)\n",
      "create relu_deconv3         (  64 x   60 x   60) -> (  64 x   60 x   60)\n",
      "create conv3_1              (  64 x   60 x   60) -> (  64 x   60 x   60)\n",
      "create relu_conv3_1         (  64 x   60 x   60) -> (  64 x   60 x   60)\n",
      "create deconv2              (  64 x   60 x   60) -> (  32 x  120 x  120)\n",
      "create relu_deconv2         (  32 x  120 x  120) -> (  32 x  120 x  120)\n",
      "create conv2_1              (  32 x  120 x  120) -> (  32 x  120 x  120)\n",
      "create relu_conv2_1         (  32 x  120 x  120) -> (  32 x  120 x  120)\n",
      "create deconv1              (  32 x  120 x  120) -> (  16 x  240 x  240)\n",
      "create conv1_1              (  16 x  240 x  240) -> (   3 x  240 x  240)\n",
      "create tanh                 (   3 x  240 x  240) -> (   3 x  240 x  240)\n",
      "create conv1_1_tanh         (   3 x  240 x  240) -> (   3 x  240 x  240)\n",
      "CaffeNet(\n",
      "  (Rconv6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
      "  (Rrelu6): LeakyReLU(negative_slope=0.3, inplace=True)\n",
      "  (Rconv7): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (Rrelu7): LeakyReLU(negative_slope=0.3, inplace=True)\n",
      "  (Rconv8): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (Rrelu8): LeakyReLU(negative_slope=0.3, inplace=True)\n",
      "  (deconv4): ConvTranspose2d(128, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  (relu_deconv4): LeakyReLU(negative_slope=0.3, inplace=True)\n",
      "  (conv4_1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu_conv4_1): LeakyReLU(negative_slope=0.3, inplace=True)\n",
      "  (deconv3): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  (relu_deconv3): LeakyReLU(negative_slope=0.3, inplace=True)\n",
      "  (conv3_1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu_conv3_1): LeakyReLU(negative_slope=0.3, inplace=True)\n",
      "  (deconv2): ConvTranspose2d(64, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  (relu_deconv2): LeakyReLU(negative_slope=0.3, inplace=True)\n",
      "  (conv2_1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu_conv2_1): LeakyReLU(negative_slope=0.3, inplace=True)\n",
      "  (deconv1): ConvTranspose2d(32, 16, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  (conv1_1): Conv2d(16, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (tanh): Tanh()\n",
      "  (conv1_1_tanh): Eltwise SUM\n",
      ")\n",
      "Loading caffemodel:  /n/holylfs06/LABS/kempner_fellow_binxuwang/Users/binxuwang/Projects/ReprInvertNet/DeePSim_orig/upconv/norm2/generator.caffemodel\n",
      "load weights Rconv6\n",
      "load weights Rconv7\n",
      "load weights Rconv8\n",
      "load weights deconv4\n",
      "load weights conv4_1\n",
      "load weights deconv3\n",
      "load weights conv3_1\n",
      "load weights deconv2\n",
      "load weights conv2_1\n",
      "load weights deconv1\n",
      "load weights conv1_1\n",
      "create Rconv6               ( 384 x   13 x   13) -> ( 384 x   11 x   11)\n",
      "create Rrelu6               ( 384 x   11 x   11) -> ( 384 x   11 x   11)\n",
      "create Rconv7               ( 384 x   11 x   11) -> ( 512 x    9 x    9)\n",
      "create Rrelu7               ( 512 x    9 x    9) -> ( 512 x    9 x    9)\n",
      "create Rconv8               ( 512 x    9 x    9) -> ( 512 x    8 x    8)\n",
      "create Rrelu8               ( 512 x    8 x    8) -> ( 512 x    8 x    8)\n",
      "create deconv5              ( 512 x    8 x    8) -> ( 256 x   16 x   16)\n",
      "create relu_deconv5         ( 256 x   16 x   16) -> ( 256 x   16 x   16)\n",
      "create conv5_1              ( 256 x   16 x   16) -> ( 256 x   16 x   16)\n",
      "create relu_conv5_1         ( 256 x   16 x   16) -> ( 256 x   16 x   16)\n",
      "create deconv4              ( 256 x   16 x   16) -> ( 128 x   32 x   32)\n",
      "create relu_deconv4         ( 128 x   32 x   32) -> ( 128 x   32 x   32)\n",
      "create conv4_1              ( 128 x   32 x   32) -> ( 128 x   32 x   32)\n",
      "create relu_conv4_1         ( 128 x   32 x   32) -> ( 128 x   32 x   32)\n",
      "create deconv3              ( 128 x   32 x   32) -> ( 128 x   64 x   64)\n",
      "create relu_deconv3         ( 128 x   64 x   64) -> ( 128 x   64 x   64)\n",
      "create conv3_1              ( 128 x   64 x   64) -> ( 128 x   64 x   64)\n",
      "create relu_conv3_1         ( 128 x   64 x   64) -> ( 128 x   64 x   64)\n",
      "create deconv2              ( 128 x   64 x   64) -> (  64 x  128 x  128)\n",
      "create relu_deconv2         (  64 x  128 x  128) -> (  64 x  128 x  128)\n",
      "create conv2_1              (  64 x  128 x  128) -> (  32 x  128 x  128)\n",
      "create relu_conv2_1         (  32 x  128 x  128) -> (  32 x  128 x  128)\n",
      "create deconv1              (  32 x  128 x  128) -> (  16 x  256 x  256)\n",
      "create relu_deconv1         (  16 x  256 x  256) -> (  16 x  256 x  256)\n",
      "create conv1_1              (  16 x  256 x  256) -> (   3 x  256 x  256)\n",
      "create tanh                 (   3 x  256 x  256) -> (   3 x  256 x  256)\n",
      "create conv1_1_tanh         (   3 x  256 x  256) -> (   3 x  256 x  256)\n",
      "CaffeNet(\n",
      "  (Rconv6): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (Rrelu6): LeakyReLU(negative_slope=0.3, inplace=True)\n",
      "  (Rconv7): Conv2d(384, 512, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (Rrelu7): LeakyReLU(negative_slope=0.3, inplace=True)\n",
      "  (Rconv8): Conv2d(512, 512, kernel_size=(2, 2), stride=(1, 1))\n",
      "  (Rrelu8): LeakyReLU(negative_slope=0.3, inplace=True)\n",
      "  (deconv5): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  (relu_deconv5): LeakyReLU(negative_slope=0.3, inplace=True)\n",
      "  (conv5_1): ConvTranspose2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu_conv5_1): LeakyReLU(negative_slope=0.3, inplace=True)\n",
      "  (deconv4): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  (relu_deconv4): LeakyReLU(negative_slope=0.3, inplace=True)\n",
      "  (conv4_1): ConvTranspose2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu_conv4_1): LeakyReLU(negative_slope=0.3, inplace=True)\n",
      "  (deconv3): ConvTranspose2d(128, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  (relu_deconv3): LeakyReLU(negative_slope=0.3, inplace=True)\n",
      "  (conv3_1): ConvTranspose2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu_conv3_1): LeakyReLU(negative_slope=0.3, inplace=True)\n",
      "  (deconv2): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  (relu_deconv2): LeakyReLU(negative_slope=0.3, inplace=True)\n",
      "  (conv2_1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu_conv2_1): LeakyReLU(negative_slope=0.3, inplace=True)\n",
      "  (deconv1): ConvTranspose2d(32, 16, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  (relu_deconv1): LeakyReLU(negative_slope=0.3, inplace=True)\n",
      "  (conv1_1): Conv2d(16, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (tanh): Tanh()\n",
      "  (conv1_1_tanh): Eltwise SUM\n",
      ")\n",
      "Loading caffemodel:  /n/holylfs06/LABS/kempner_fellow_binxuwang/Users/binxuwang/Projects/ReprInvertNet/DeePSim_orig/upconv/conv3/generator.caffemodel\n",
      "load weights Rconv6\n",
      "load weights Rconv7\n",
      "load weights Rconv8\n",
      "load weights deconv5\n",
      "load weights conv5_1\n",
      "load weights deconv4\n",
      "load weights conv4_1\n",
      "load weights deconv3\n",
      "load weights conv3_1\n",
      "load weights deconv2\n",
      "load weights conv2_1\n",
      "load weights deconv1\n",
      "load weights conv1_1\n",
      "create Rconv6               ( 384 x   13 x   13) -> ( 384 x   11 x   11)\n",
      "create Rrelu6               ( 384 x   11 x   11) -> ( 384 x   11 x   11)\n",
      "create Rconv7               ( 384 x   11 x   11) -> ( 512 x    9 x    9)\n",
      "create Rrelu7               ( 512 x    9 x    9) -> ( 512 x    9 x    9)\n",
      "create Rconv8               ( 512 x    9 x    9) -> ( 512 x    8 x    8)\n",
      "create Rrelu8               ( 512 x    8 x    8) -> ( 512 x    8 x    8)\n",
      "create deconv5              ( 512 x    8 x    8) -> ( 256 x   16 x   16)\n",
      "create relu_deconv5         ( 256 x   16 x   16) -> ( 256 x   16 x   16)\n",
      "create conv5_1              ( 256 x   16 x   16) -> ( 256 x   16 x   16)\n",
      "create relu_conv5_1         ( 256 x   16 x   16) -> ( 256 x   16 x   16)\n",
      "create deconv4              ( 256 x   16 x   16) -> ( 128 x   32 x   32)\n",
      "create relu_deconv4         ( 128 x   32 x   32) -> ( 128 x   32 x   32)\n",
      "create conv4_1              ( 128 x   32 x   32) -> ( 128 x   32 x   32)\n",
      "create relu_conv4_1         ( 128 x   32 x   32) -> ( 128 x   32 x   32)\n",
      "create deconv3              ( 128 x   32 x   32) -> ( 128 x   64 x   64)\n",
      "create relu_deconv3         ( 128 x   64 x   64) -> ( 128 x   64 x   64)\n",
      "create conv3_1              ( 128 x   64 x   64) -> ( 128 x   64 x   64)\n",
      "create relu_conv3_1         ( 128 x   64 x   64) -> ( 128 x   64 x   64)\n",
      "create deconv2              ( 128 x   64 x   64) -> (  64 x  128 x  128)\n",
      "create relu_deconv2         (  64 x  128 x  128) -> (  64 x  128 x  128)\n",
      "create conv2_1              (  64 x  128 x  128) -> (  32 x  128 x  128)\n",
      "create relu_conv2_1         (  32 x  128 x  128) -> (  32 x  128 x  128)\n",
      "create deconv1              (  32 x  128 x  128) -> (  16 x  256 x  256)\n",
      "create relu_deconv1         (  16 x  256 x  256) -> (  16 x  256 x  256)\n",
      "create conv1_1              (  16 x  256 x  256) -> (   3 x  256 x  256)\n",
      "create tanh                 (   3 x  256 x  256) -> (   3 x  256 x  256)\n",
      "create conv1_1_tanh         (   3 x  256 x  256) -> (   3 x  256 x  256)\n",
      "CaffeNet(\n",
      "  (Rconv6): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (Rrelu6): LeakyReLU(negative_slope=0.3, inplace=True)\n",
      "  (Rconv7): Conv2d(384, 512, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (Rrelu7): LeakyReLU(negative_slope=0.3, inplace=True)\n",
      "  (Rconv8): Conv2d(512, 512, kernel_size=(2, 2), stride=(1, 1))\n",
      "  (Rrelu8): LeakyReLU(negative_slope=0.3, inplace=True)\n",
      "  (deconv5): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  (relu_deconv5): LeakyReLU(negative_slope=0.3, inplace=True)\n",
      "  (conv5_1): ConvTranspose2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu_conv5_1): LeakyReLU(negative_slope=0.3, inplace=True)\n",
      "  (deconv4): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  (relu_deconv4): LeakyReLU(negative_slope=0.3, inplace=True)\n",
      "  (conv4_1): ConvTranspose2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu_conv4_1): LeakyReLU(negative_slope=0.3, inplace=True)\n",
      "  (deconv3): ConvTranspose2d(128, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  (relu_deconv3): LeakyReLU(negative_slope=0.3, inplace=True)\n",
      "  (conv3_1): ConvTranspose2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu_conv3_1): LeakyReLU(negative_slope=0.3, inplace=True)\n",
      "  (deconv2): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  (relu_deconv2): LeakyReLU(negative_slope=0.3, inplace=True)\n",
      "  (conv2_1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu_conv2_1): LeakyReLU(negative_slope=0.3, inplace=True)\n",
      "  (deconv1): ConvTranspose2d(32, 16, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  (relu_deconv1): LeakyReLU(negative_slope=0.3, inplace=True)\n",
      "  (conv1_1): Conv2d(16, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (tanh): Tanh()\n",
      "  (conv1_1_tanh): Eltwise SUM\n",
      ")\n",
      "Loading caffemodel:  /n/holylfs06/LABS/kempner_fellow_binxuwang/Users/binxuwang/Projects/ReprInvertNet/DeePSim_orig/upconv/conv4/generator.caffemodel\n",
      "load weights Rconv6\n",
      "load weights Rconv7\n",
      "load weights Rconv8\n",
      "load weights deconv5\n",
      "load weights conv5_1\n",
      "load weights deconv4\n",
      "load weights conv4_1\n",
      "load weights deconv3\n",
      "load weights conv3_1\n",
      "load weights deconv2\n",
      "load weights conv2_1\n",
      "load weights deconv1\n",
      "load weights conv1_1\n"
     ]
    }
   ],
   "source": [
    "Generator = load_generator('norm1')\n",
    "Generator = load_generator('norm2')\n",
    "Generator = load_generator('conv3')\n",
    "Generator = load_generator('conv4')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class upconvGAN(nn.Module):\n",
    "    def __init__(self, name=\"fc6\", pretrained=True, shuffled=False):\n",
    "        super(upconvGAN, self).__init__()\n",
    "        self.name = name\n",
    "        if name == \"fc6\" or name == \"fc7\":\n",
    "            self.G = nn.Sequential(OrderedDict([\n",
    "        ('defc7', nn.Linear(in_features=4096, out_features=4096, bias=True)),\n",
    "        ('relu_defc7', nn.LeakyReLU(negative_slope=0.3, inplace=True)),\n",
    "        ('defc6', nn.Linear(in_features=4096, out_features=4096, bias=True)),\n",
    "        ('relu_defc6', nn.LeakyReLU(negative_slope=0.3, inplace=True)),\n",
    "        ('defc5', nn.Linear(in_features=4096, out_features=4096, bias=True)),\n",
    "        ('relu_defc5', nn.LeakyReLU(negative_slope=0.3, inplace=True)),\n",
    "        ('reshape', View((-1, 256, 4, 4))),\n",
    "        ('deconv5', nn.ConvTranspose2d(256, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))),\n",
    "        ('relu_deconv5', nn.LeakyReLU(negative_slope=0.3, inplace=True)),\n",
    "        ('conv5_1', nn.ConvTranspose2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))),\n",
    "        ('relu_conv5_1', nn.LeakyReLU(negative_slope=0.3, inplace=True)),\n",
    "        ('deconv4', nn.ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))),\n",
    "        ('relu_deconv4', nn.LeakyReLU(negative_slope=0.3, inplace=True)),\n",
    "        ('conv4_1', nn.ConvTranspose2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))),\n",
    "        ('relu_conv4_1', nn.LeakyReLU(negative_slope=0.3, inplace=True)),\n",
    "        ('deconv3', nn.ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))),\n",
    "        ('relu_deconv3', nn.LeakyReLU(negative_slope=0.3, inplace=True)),\n",
    "        ('conv3_1', nn.ConvTranspose2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))),\n",
    "        ('relu_conv3_1', nn.LeakyReLU(negative_slope=0.3, inplace=True)),\n",
    "        ('deconv2', nn.ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))),\n",
    "        ('relu_deconv2', nn.LeakyReLU(negative_slope=0.3, inplace=True)),\n",
    "        ('deconv1', nn.ConvTranspose2d(64, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))),\n",
    "        ('relu_deconv1', nn.LeakyReLU(negative_slope=0.3, inplace=True)),\n",
    "        ('deconv0', nn.ConvTranspose2d(32, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))),\n",
    "            ]))\n",
    "            self.codelen = self.G[0].in_features\n",
    "        elif name == \"fc8\":\n",
    "            self.G = nn.Sequential(OrderedDict([\n",
    "  (\"defc7\", nn.Linear(in_features=1000, out_features=4096, bias=True)),\n",
    "  (\"relu_defc7\", nn.LeakyReLU(negative_slope=0.3, inplace=True)),\n",
    "  (\"defc6\", nn.Linear(in_features=4096, out_features=4096, bias=True)),\n",
    "  (\"relu_defc6\", nn.LeakyReLU(negative_slope=0.3, inplace=True)),\n",
    "  (\"defc5\", nn.Linear(in_features=4096, out_features=4096, bias=True)),\n",
    "  (\"relu_defc5\", nn.LeakyReLU(negative_slope=0.3, inplace=True)),\n",
    "  (\"reshape\", View((-1, 256, 4, 4))),\n",
    "  (\"deconv5\", nn.ConvTranspose2d(256, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))),\n",
    "  (\"relu_deconv5\", nn.LeakyReLU(negative_slope=0.3, inplace=True)),\n",
    "  (\"conv5_1\", nn.ConvTranspose2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))),\n",
    "  (\"relu_conv5_1\", nn.LeakyReLU(negative_slope=0.3, inplace=True)),\n",
    "  (\"deconv4\", nn.ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))),\n",
    "  (\"relu_deconv4\", nn.LeakyReLU(negative_slope=0.3, inplace=True)),\n",
    "  (\"conv4_1\", nn.ConvTranspose2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))),\n",
    "  (\"relu_conv4_1\", nn.LeakyReLU(negative_slope=0.3, inplace=True)),\n",
    "  (\"deconv3\", nn.ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))),\n",
    "  (\"relu_deconv3\", nn.LeakyReLU(negative_slope=0.3, inplace=True)),\n",
    "  (\"conv3_1\", nn.ConvTranspose2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))),\n",
    "  (\"relu_conv3_1\", nn.LeakyReLU(negative_slope=0.3, inplace=True)),\n",
    "  (\"deconv2\", nn.ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))),\n",
    "  (\"relu_deconv2\", nn.LeakyReLU(negative_slope=0.3, inplace=True)),\n",
    "  (\"deconv1\", nn.ConvTranspose2d(64, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))),\n",
    "  (\"relu_deconv1\", nn.LeakyReLU(negative_slope=0.3, inplace=True)),\n",
    "  (\"deconv0\", nn.ConvTranspose2d(32, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))),\n",
    "  ]))\n",
    "            self.codelen = self.G[0].in_features\n",
    "        elif name == \"pool5\":\n",
    "            self.G = nn.Sequential(OrderedDict([\n",
    "        ('Rconv6', nn.Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))),\n",
    "        ('Rrelu6', nn.LeakyReLU(negative_slope=0.3, inplace=True)),\n",
    "        ('Rconv7', nn.Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))),\n",
    "        ('Rrelu7', nn.LeakyReLU(negative_slope=0.3, inplace=True)),\n",
    "        ('Rconv8', nn.Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1))),\n",
    "        ('Rrelu8', nn.LeakyReLU(negative_slope=0.3, inplace=True)),\n",
    "        ('deconv5', nn.ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))),\n",
    "        ('relu_deconv5', nn.LeakyReLU(negative_slope=0.3, inplace=True)),\n",
    "        ('conv5_1', nn.ConvTranspose2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))),\n",
    "        ('relu_conv5_1', nn.LeakyReLU(negative_slope=0.3, inplace=True)),\n",
    "        ('deconv4', nn.ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))),\n",
    "        ('relu_deconv4', nn.LeakyReLU(negative_slope=0.3, inplace=True)),\n",
    "        ('conv4_1', nn.ConvTranspose2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))),\n",
    "        ('relu_conv4_1', nn.LeakyReLU(negative_slope=0.3, inplace=True)),\n",
    "        ('deconv3', nn.ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))),\n",
    "        ('relu_deconv3', nn.LeakyReLU(negative_slope=0.3, inplace=True)),\n",
    "        ('conv3_1', nn.ConvTranspose2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))),\n",
    "        ('relu_conv3_1', nn.LeakyReLU(negative_slope=0.3, inplace=True)),\n",
    "        ('deconv2', nn.ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))),\n",
    "        ('relu_deconv2', nn.LeakyReLU(negative_slope=0.3, inplace=True)),\n",
    "        ('deconv1', nn.ConvTranspose2d(64, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))),\n",
    "        ('relu_deconv1', nn.LeakyReLU(negative_slope=0.3, inplace=True)),\n",
    "        ('deconv0', nn.ConvTranspose2d(32, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))), ]))\n",
    "            self.codelen = self.G[0].in_channels\n",
    "            self.latent_shape = (256, 4, 4)\n",
    "        elif name == \"conv4\":\n",
    "            self.G = nn.Sequential(OrderedDict([\n",
    "                ('Rconv6', nn.Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1))),\n",
    "                ('Rrelu6', nn.LeakyReLU(negative_slope=0.3, inplace=True)),\n",
    "                ('Rconv7', nn.Conv2d(384, 512, kernel_size=(3, 3), stride=(1, 1))),\n",
    "                ('Rrelu7', nn.LeakyReLU(negative_slope=0.3, inplace=True)),\n",
    "                ('Rconv8', nn.Conv2d(512, 512, kernel_size=(2, 2), stride=(1, 1))),\n",
    "                ('Rrelu8', nn.LeakyReLU(negative_slope=0.3, inplace=True)),\n",
    "                ('deconv5', nn.ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))),\n",
    "                ('relu_deconv5', nn.LeakyReLU(negative_slope=0.3, inplace=True)),\n",
    "                ('conv5_1', nn.ConvTranspose2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))),\n",
    "                ('relu_conv5_1', nn.LeakyReLU(negative_slope=0.3, inplace=True)),\n",
    "                ('deconv4', nn.ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))),\n",
    "                ('relu_deconv4', nn.LeakyReLU(negative_slope=0.3, inplace=True)),\n",
    "                ('conv4_1', nn.ConvTranspose2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))),\n",
    "                ('relu_conv4_1', nn.LeakyReLU(negative_slope=0.3, inplace=True)),\n",
    "                ('deconv3', nn.ConvTranspose2d(128, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))),\n",
    "                ('relu_deconv3', nn.LeakyReLU(negative_slope=0.3, inplace=True)),\n",
    "                ('conv3_1', nn.ConvTranspose2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))),\n",
    "                ('relu_conv3_1', nn.LeakyReLU(negative_slope=0.3, inplace=True)),\n",
    "                ('deconv2', nn.ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))),\n",
    "                ('relu_deconv2', nn.LeakyReLU(negative_slope=0.3, inplace=True)),\n",
    "                ('conv2_1', nn.Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))),\n",
    "                ('relu_conv2_1', nn.LeakyReLU(negative_slope=0.3, inplace=True)),\n",
    "                ('deconv1', nn.ConvTranspose2d(32, 16, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))),\n",
    "                ('relu_deconv1', nn.LeakyReLU(negative_slope=0.3, inplace=True)),\n",
    "                ('conv1_1', nn.Conv2d(16, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))),\n",
    "                ('tanh', nn.Tanh())\n",
    "            ]))\n",
    "            self.latent_shape = (384, 13, 13)\n",
    "        # load pre-trained weight from online or local folders\n",
    "        if pretrained:\n",
    "            if load_urls:\n",
    "                SDnew = load_statedict_from_online(name)\n",
    "            else:\n",
    "                savepath = {\"fc6\": join(netsdir, r\"upconv/fc6/generator_state_dict.pt\"),\n",
    "                            \"fc7\": join(netsdir, r\"upconv/fc7/generator_state_dict.pt\"),\n",
    "                            \"fc8\": join(netsdir, r\"upconv/fc8/generator_state_dict.pt\"),\n",
    "                            \"pool5\": join(netsdir, r\"upconv/pool5/generator_state_dict.pt\")}\n",
    "                SD = torch.load(savepath[name])\n",
    "                SDnew = OrderedDict()\n",
    "                for name, W in SD.items():  # discard this inconsistency\n",
    "                    name = name.replace(\".1.\", \".\")\n",
    "                    SDnew[name] = W\n",
    "            self.G.load_state_dict(SDnew)\n",
    "        # if shuffled:\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.G(x)[:, [2, 1, 0], :, :]\n",
    "\n",
    "    def visualize(self, x, scale=1.0):\n",
    "        raw = self.G(x)\n",
    "        return torch.clamp(raw[:, [2, 1, 0], :, :] + RGB_mean.to(raw.device), 0, 255.0) / 255.0 * scale\n",
    "\n",
    "    def visualize_batch(self, x_arr, scale=1.0, B=42, ):\n",
    "        coden = x_arr.shape[0]\n",
    "        img_all = []\n",
    "        csr = 0  # if really want efficiency, we should use minibatch processing.\n",
    "        with torch.no_grad():\n",
    "            while csr < coden:\n",
    "                csr_end = min(csr + B, coden)\n",
    "                imgs = self.visualize(x_arr[csr:csr_end, :].cuda(), scale).cpu()\n",
    "                img_all.append(imgs)\n",
    "                csr = csr_end\n",
    "        img_all = torch.cat(img_all, dim=0)\n",
    "        return img_all\n",
    "\n",
    "    def render(self, x, scale=1.0, B=42):  # add batch processing to avoid memory over flow for batch too large\n",
    "        coden = x.shape[0]\n",
    "        img_all = []\n",
    "        csr = 0  # if really want efficiency, we should use minibatch processing.\n",
    "        while csr < coden:\n",
    "            csr_end = min(csr + B, coden)\n",
    "            with torch.no_grad():\n",
    "                imgs = self.visualize(torch.from_numpy(x[csr:csr_end, :]).float().cuda(), scale).permute(2,3,1,0).cpu().numpy()\n",
    "            img_all.extend([imgs[:, :, :, imgi] for imgi in range(imgs.shape[3])])\n",
    "            csr = csr_end\n",
    "        return img_all\n",
    "\n",
    "    def visualize_batch_np(self, codes_all_arr, scale=1.0, B=42, verbose=False):\n",
    "        coden = codes_all_arr.shape[0]\n",
    "        img_all = None\n",
    "        csr = 0  # if really want efficiency, we should use minibatch processing.\n",
    "        with torch.no_grad():\n",
    "            while csr < coden:\n",
    "                csr_end = min(csr + B, coden)\n",
    "                imgs = self.visualize(torch.from_numpy(codes_all_arr[csr:csr_end, :]).float().cuda(), scale).cpu()\n",
    "                img_all = imgs if img_all is None else torch.cat((img_all, imgs), dim=0)\n",
    "                csr = csr_end\n",
    "                if verbose:\n",
    "                    clear_output(wait=True)\n",
    "                    progress_bar(csr_end, coden, \"ploting row of page: %d of %d\" % (csr_end, coden))\n",
    "        return img_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['feat',\n",
       " 'Rconv6',\n",
       " 'Rconv7',\n",
       " 'Rconv8',\n",
       " 'deconv4',\n",
       " 'conv4_1',\n",
       " 'deconv3',\n",
       " 'conv3_1',\n",
       " 'deconv2',\n",
       " 'conv2_1',\n",
       " 'deconv1',\n",
       " 'conv1_1',\n",
       " 'conv1_1_tanh',\n",
       " 'generated']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 1.5243e-04,  3.0583e-04,  4.4513e-06,  ...,  4.0827e-04,\n",
       "           -1.3420e-04, -5.0331e-04],\n",
       "          [ 3.1363e-04,  5.4964e-04,  7.0502e-04,  ..., -7.4048e-04,\n",
       "           -8.3837e-04, -1.5165e-04],\n",
       "          [ 1.5197e-04,  5.9897e-04,  7.0622e-04,  ..., -5.1032e-04,\n",
       "           -3.3032e-04, -1.5532e-04],\n",
       "          ...,\n",
       "          [-3.8437e-04, -6.4759e-04, -6.8077e-04,  ..., -2.8786e-04,\n",
       "           -4.3881e-04, -1.3633e-04],\n",
       "          [-2.7306e-04, -3.3358e-04, -5.4119e-04,  ..., -3.2097e-04,\n",
       "           -1.1874e-04, -5.5010e-04],\n",
       "          [ 2.7541e-05, -2.3222e-04, -4.3750e-04,  ..., -2.1435e-04,\n",
       "           -1.6358e-05, -2.9488e-04]],\n",
       "\n",
       "         [[-3.5753e-04,  3.6441e-04, -2.3151e-04,  ...,  5.2989e-04,\n",
       "            2.3138e-05, -5.2995e-04],\n",
       "          [ 1.3873e-04,  1.9303e-04,  3.0827e-04,  ..., -5.7088e-04,\n",
       "           -8.4425e-04,  1.3354e-04],\n",
       "          [-1.0346e-04,  5.7335e-04,  1.3125e-04,  ..., -2.4151e-04,\n",
       "           -2.6299e-04, -1.4248e-04],\n",
       "          ...,\n",
       "          [-3.8259e-04, -4.9709e-04, -3.8390e-04,  ...,  3.0304e-04,\n",
       "           -7.1610e-05,  2.1977e-05],\n",
       "          [-3.2382e-04, -2.1248e-04, -1.3479e-04,  ...,  1.3132e-05,\n",
       "            3.8767e-05, -4.0137e-04],\n",
       "          [-1.5361e-04, -3.7382e-04, -4.1469e-04,  ..., -7.5589e-06,\n",
       "            1.4465e-05, -3.2684e-04]],\n",
       "\n",
       "         [[-5.1918e-04, -3.6377e-04, -8.6059e-04,  ..., -1.4704e-05,\n",
       "           -1.9995e-04, -7.3874e-04],\n",
       "          [-3.2652e-04, -4.1928e-04, -6.6782e-04,  ..., -9.6721e-04,\n",
       "           -1.0997e-03, -2.9573e-04],\n",
       "          [-5.7214e-04, -5.3668e-04, -9.8755e-04,  ..., -9.5830e-04,\n",
       "           -5.4210e-04, -4.7684e-04],\n",
       "          ...,\n",
       "          [-2.2082e-04, -6.7075e-04, -5.7892e-04,  ..., -2.2410e-04,\n",
       "           -4.2676e-04, -1.1496e-04],\n",
       "          [-2.4732e-04, -4.1878e-04, -5.8478e-04,  ..., -1.8145e-04,\n",
       "            1.1162e-04, -2.6294e-04],\n",
       "          [-8.1640e-06, -4.3118e-04, -3.0419e-04,  ..., -2.0142e-04,\n",
       "            1.2053e-04, -2.5390e-04]]]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ffcv-ssl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
